<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[App启动流程]]></title>
    <url>%2F2018%2F02%2F24%2FApp%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言作为Android用户，我们会点击桌面图标，然后一个app就启动了了，在这个过程中到底发生了什么呢？换句话说Android app是怎么启动的呢？如果和我有一样的好奇，我们来一起走进代码的细节中了解一下。 桌面app我们平时都不会管Framework层，自然也不会去写桌面app。那我给大家看一看系统带的桌面Activity是怎么启动我们的Activity的. 1234567Intent intent = new Intent(mIntent);ListItem item = mActivitiesList.get(position);intent.setClassName(item.packageName, item.className);if (item.extras != null) &#123; intent.putExtras(item.extras);&#125;startActivity(intent); 原来也是调用startActivity，不过是隐式调用，通过包名和类名来启动对应的Activity，可是，这时候还没有Application呢，怎么能启动Activity呢？看过我前一篇文章的读者们会想到，这个过程中启动了Application，那我们就来看看这是如何启动的。 启动Application上篇Activity启动流程中的文章中提到，在流程图中，有一个方法很重要，它是startSpecificActivityLocked，因为上一篇讲的是Activity启动流程，所以这里和App启动相关的地方就略过没讲，既然上一篇画了流程图，这一篇我们就细细讲一下App的启动。 先看一下startSpecificActivityLocked引出的启动App进程。这个方法我就不贴代码了，简单来说，如果进程存在，就启动Activity，若不存在，调用下面的方法启动进程。我们就直接讲启动进程的方法。 ActivityManagerService startProcessLocked1234567boolean isActivityProcess = (entryPoint == null);if (entryPoint == null) entryPoint = "android.app.ActivityThread";Process.ProcessStartResult startResult = Process.start(entryPoint, app.processName, uid, uid, gids, debugFlags, mountExternal, app.info.targetSdkVersion, app.info.seinfo, requiredAbi, instructionSet, app.info.dataDir, entryPointArgs); 这里是这个方法的核心过程， 调用Process.start方法启动一个进程。 看到这里，相信能解决不少开发者拥有的共同疑惑：为什么看到某些博客会说ActivityThread的main方法是application启动的时候调用的main方法呢？原来调用Process.start的时候指定了entryPoint为android.app.ActivityThread，所以，这里启动之后就会调用ActivityThread的main方法。 这里就像我们平时写Java程序一样，启动一个程序，会分配一个单独的Java Runtime，从main方法开始执行。 那么我们就继续跟入，Process.start就是调用了startViaZygote方法，这个方法的注释是 12// Starts a new process via the zygote mechanism通过zygote机制启动新进程 这个方法忽视掉增加参数的过程之后，这里也就一个函数 1return zygoteSendArgsAndGetResult(openZygoteSocketIfNeeded(abi), argsForZygote); 看看函数名openZygoteSocketIfNeeded，openZygoteSocket，嗯，代码跟进去就像函数名说的，通过Socket和Zygote交互，将需要的参数通过socket传给Zygote，它就会创建好我们需要的App进程。这样就返回了一个新进程，ActivityThread的main方法就要开始执行了。 ActivityThread main12345678910111213141516171819202122public static void main(String[] args) &#123; Environment.initForCurrentUser(); AndroidKeyStoreProvider.install(); // Make sure TrustedCertificateStore looks in the right place for CA certificates final File configDir = Environment.getUserConfigDirectory(UserHandle.myUserId()); TrustedCertificateStore.setDefaultUserDirectory(configDir); Process.setArgV0("&lt;pre-initialized&gt;"); Looper.prepareMainLooper(); // 初始化不允许退出的MainLoop ActivityThread thread = new ActivityThread(); thread.attach(false); if (sMainThreadHandler == null) &#123; sMainThreadHandler = thread.getHandler(); &#125; // 使用liunx epoll开始死循环等待消息 // 大家有兴趣的话看MessageQueue的nativePollOnce方法 // 对应的c++代码 android_os_MessageQueue.cpp Looper.loop(); throw new RuntimeException("Main thread loop unexpectedly exited");&#125; 这个代码相信大家在很多博客都见过，在这篇文章中不重要的代码解析放在了代码的注释中。下面我们来看看这个重要的方法thread.attach(false); ActivityThread attach123456789101112131415161718192021222324252627final IActivityManager mgr = ActivityManagerNative.getDefault();try &#123; mgr.attachApplication(mAppThread);&#125; catch (RemoteException ex) &#123; // Ignore&#125;// Watch for getting close to heap limit.BinderInternal.addGcWatcher(new Runnable() &#123; @Override public void run() &#123; if (!mSomeActivitiesChanged) &#123; return; &#125; Runtime runtime = Runtime.getRuntime(); long dalvikMax = runtime.maxMemory(); long dalvikUsed = runtime.totalMemory() - runtime.freeMemory(); if (dalvikUsed &gt; ((3*dalvikMax)/4)) &#123; if (DEBUG_MEMORY_TRIM) Slog.d(TAG, "Dalvik max=" + (dalvikMax/1024) + " total=" + (runtime.totalMemory()/1024) + " used=" + (dalvikUsed/1024)); mSomeActivitiesChanged = false; try &#123; mgr.releaseSomeActivities(mAppThread); &#125; catch (RemoteException e) &#123; &#125; &#125; &#125;&#125;); 这里重要方法就是mgr.attachApplication(mAppThread);，但是多复制了一些代码，为了提一下GC，什么时候虚拟机进行GC呢？这里给了我们答案，在使用超过3/4最大内存的时候。 继续回来跟代码，和前面一样，这里使用的是ActivityManagerService作为IActivityManager，mgr.attachApplication(mAppThread)这个方法就是调用了attachApplicationLocked方法。 1234567891011121314 ensurePackageDexOpt(app.instrumentationInfo != null ? app.instrumentationInfo.packageName : app.info.packageName);if (app.instrumentationClass != null) &#123; ensurePackageDexOpt(app.instrumentationClass.getPackageName());&#125;thread.bindApplication(processName, appInfo, providers, app.instrumentationClass, profilerInfo, app.instrumentationArguments, app.instrumentationWatcher, app.instrumentationUiAutomationConnection, testMode, enableOpenGlTrace, isRestrictedBackupMode || !normalMode, app.persistent, new Configuration(mConfiguration), app.compat, getCommonServicesLocked(app.isolated), mCoreSettingsObserver.getCoreSettingsLocked()); 这里主要是两段，第一段就是单纯为了解惑dexOpt是什么时候生成的呢？就是这个时候。 后面是一个方法: ActivityThread的bindApplication方法。 在忽视bindApplication方法中的一些初始化之后，就做了一件事，给H这个Handler发送BIND_APPLICATION消息，然后H会调用handleBindApplication方法。 ActivityThread handleBindApplication1234567891011121314151617181920212223242526272829// If the app is Honeycomb MR1 or earlier, switch its AsyncTask// implementation to use the pool executor. Normally, we use the// serialized executor as the default. This has to happen in the// main thread so the main looper is set right.if (data.appInfo.targetSdkVersion &lt;= android.os.Build.VERSION_CODES.HONEYCOMB_MR1) &#123; AsyncTask.setDefaultExecutor(AsyncTask.THREAD_POOL_EXECUTOR);&#125;Message.updateCheckRecycle(data.appInfo.targetSdkVersion);if ((data.appInfo.flags&amp;ApplicationInfo.FLAG_LARGE_HEAP) != 0) &#123; dalvik.system.VMRuntime.getRuntime().clearGrowthLimit();&#125; else &#123; // Small heap, clamp to the current growth limit and let the heap release // pages after the growth limit to the non growth limit capacity. b/18387825 dalvik.system.VMRuntime.getRuntime().clampGrowthLimit();&#125; // a restricted environment with the base application class.Application app = data.info.makeApplication(data.restrictedBackupMode, null);List&lt;ProviderInfo&gt; providers = data.providers;if (providers != null) &#123; installContentProviders(app, providers); // For process that contains content providers, we want to // ensure that the JIT is enabled "at some point". mH.sendEmptyMessageDelayed(H.ENABLE_JIT, 10*1000);&#125; mInstrumentation.callApplicationOnCreate(app); 这里放这些代码，但是只会详解生成Application的函数data.info.makeApplication(data.restrictedBackupMode, null)。 剩下的我们就提以下几点: AsyncTask在不同的targetSdkVersion中行为不同，为什么呢，不止AsyncTask代码的不同，还因为这里修改了线程池的实现。 targetSdkVersion是app运行时拿到的sdk版本信息之一，另一个是minSdkVersion，所以，Google对app的限制就全加在了targetSdkVersion上。 有些app会设置FLAG_LARGE_HEAP属性，这个属性具体做了什么呢？从这里就是线索。 ContentProvider的初始化原来是在Application的onCreate之前attachBaseContext之后。 Application的生命周期也是由Instrumentation来控制的 看完了上面这几点，我们详细看一下生成Application的函数: LoadedApk makeApplication12345678910String appClass = mApplicationInfo.className;if (forceDefaultAppClass || (appClass == null)) &#123; appClass = "android.app.Application";&#125;java.lang.ClassLoader cl = getClassLoader();ContextImpl appContext = ContextImpl.createAppContext(mActivityThread, this);app = mActivityThread.mInstrumentation.newApplication( cl, appClass, appContext); 这就是我们需要关注的这个方法的内容。 你没有声明自己的Application的话，将会使用系统默认的android.app.Application。 Application的初始化依旧是反射，通过clazz.newInstance()来生成，这也就说明了，为什么我们不能写带参数的构造函数。 其次，生成Application的时候还会回调attachBaseContext方法，这里也就成为了一个App最早执行代码的位置。这样，一个Application就生成并启动了。 到这里，ActivityThread的bindApplication方法就告一段落了。也就意味着整个Application的启动完成了。 总结这样，我们就大概了解了一个App从点击桌面icon，到Application完全启动的过程。 了解这个过程，首先让我们对Manifest中各种属性有了更深的了解；其次，了解了Android代码的执行过程，以写Java程序的视角来看Android程序就不再那么奇怪了；最后，有了对源码的了解，你才能写出更好的代码。]]></content>
      <tags>
        <tag>android</tag>
        <tag>app</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Activity启动流程]]></title>
    <url>%2F2018%2F01%2F21%2FActivity%E7%9A%84%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言作为Android开发，我们经常会写startActivity方法，这样我们就可以启动Activity了，在这个过程中到底发生了什么呢？换句话说Activity是怎么启动的呢？如果和我有一样的好奇，我们来一起走进代码的细节中了解一下。 启动Activity查看源码可以知道，startActivity()方法最终是调用了startActivityForResult()方法来执行的。 startActivityForResult123456789Instrumentation.ActivityResult ar = mInstrumentation.execStartActivity( this, mMainThread.getApplicationThread(), mToken, this, intent, requestCode, options);if (ar != null) &#123; mMainThread.sendActivityResult( mToken, mEmbeddedID, requestCode, ar.getResultCode(), ar.getResultData());&#125; 这里的主要就是这个方法:mInstrumentation.execStartActivity()。 这里的流程很复杂，我们来看流程图。 在最后的handleLaunchActivity方法中，调用了performLaunchActivity生成Activity，调用handleResumeActivity让Activity进入Resume生命周期。 这里也留下一个伏笔，后面写Android App的启动流程的时候还是在这个流程中，尤其是startSpecificActivityLocked方法。 performLaunchActivity12java.lang.ClassLoader cl = r.packageInfo.getClassLoader();activity = mInstrumentation.newActivity(cl, component.getClassName(), r.intent) 生成Activity的核心就这两句代码，通过Instrumentation的newActivity方法生成。 这里要记住Instrumentation，它很重要，但是先放着，我们继续来看Activity的启动流程。 callActivityOnResumehandleResumeActivity经过多层调用，最终调用了Instrumentation的callActivityOnResume方法 1234 public void callActivityOnResume(Activity activity) &#123; activity.mResumed = true; activity.onResume();&#125; 这样Activity的onResume方法就会被调用。也就意味着Activity生命周期走到Resume的状态，这样的Activity算是启动完成了。 总结我们可以看到，从startActivity到Activity进入Resume的生命周期，有一个类的身影若隐若现，那就是Instrumentation, 这个类负责管理Application的创建和启动，负责Activity的创建和生命周期的管理。所以，一旦你操纵这个类，你能做的事情就有很多。比如，在Activity生命周期的过程中添加一些消息。 经过我的总结，Activity的生命周期是有一个套路在的，这个套路就是: scheduleXXXActivity-&gt;handleXXXActivity-&gt;performXXActivity-&gt;CallActivitiyXXX—&gt;Activity.XXX scheduleXXXActivity负责发消息给Handler(H)发对应的消息。接着就和之前文章中提到的内容类似，每个生命周期都要经过这样一个过程来调度。 到这里，我们就大概浏览了一下Activity的启动流程，希望你在遇到这方面的问题的时候，能把这个博客当作一个目录，知道去哪里找对应的源码，思考对应的解决方案。]]></content>
      <tags>
        <tag>android</tag>
        <tag>activity</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidPlugin源码解析(九)]]></title>
    <url>%2F2017%2F10%2F08%2FAndroidPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B9%9D)%2F</url>
    <content type="text"><![CDATA[前言前面我们分了8篇讲解整个Android Apk的打包过程，可以说我们中间几篇文章都是只见树木不见森林，研究了其中的细节，但缺少对这个过程的整体把握，这篇文章就是要填充缺少的整体图。 综述到目前为止，Android的打包框架从Ant&amp;ADT渐渐转移到了Gradle : Build Tools 19.0.0 之前，Ant&amp;ADT作为最主要的框架 Build Tools 19.0.0以后，开始使用Gradle作为打包过程的框架 Android编译源码的方案从最初的Java Tool Chain新加了Jack &amp; Jill Tool Chain，现在又准备废弃Jack &amp; Jill Tool Chain了。 Build Tools version 21.1.1之后，加入了Jack &amp; Jill Tool Chain 已经准备废弃Jack &amp; Jill Tool Chain，未来通过javac和dx工具的修改提供Java8的支持。 经典打包过程图: 步骤如下: 通过aapt打包res资源文件，生成R.java、resources.arsc和res文件（二进制 &amp; 非二进制如res/raw和pic保持原样） 处理.aidl文件，生成对应的Java接口文件 通过Java Compiler编译R.java、Java接口文件、Java源文件，生成.class文件 通过dex命令，将.class文件和第三方库中的.class文件处理生成classes.dex 通过apkbuilder工具，将aapt生成的resources.arsc和res文件、assets文件和classes.dex一起打包生成apk 通过JarSigner工具，对上面的apk进行debug或release签名 通过zipalign工具，将签名后的apk进行对齐处理。 使用Gradle后这就是我们前面重点讲的内容，先看一下图 打包过程图: 使用Gradle后最详细的打包图:本图来源 这幅图中，我们没有分析llvm-rs-cc，AIDL，NDK周边的文件，剩下的我们都有提到。 看完前面的过程再来看这幅图，不得不说这个图画的真的好，尤其注意对应左下角的图示说明，就可以看出Google是如何对这样一个打包过程进行分层的，把哪些工作交给哪部分去做。 这对我们整体去设计一个大型的程序也很有帮助，将某些工作交给更合适的工具去做，而不是一个工具做所有的工作。 Jack &amp; JillJack &amp; Jill Tool Chain 只在Gradle框架中存在，但是因为看到Google打算废弃Jack消息，这就是我不在前面的文章中分析Jack &amp; Jill的原因了，放两张图，稍微看一下就好。 Proguard最后，两张图来了解一下proguard在这两个Tool Chain中在哪一步执行。 对javac之后执行proguard的图： Jack &amp; Jill Proguard执行流程: 看完了这个流程整体架构图，下面我们就看看gradle需要做哪些工作来把apk安装到手机上。 Task执行依赖之前在Gradle学习博客中，我们可以知道，对于gradle来说，整个Tasks是一个图，执行某一个Task的时候会先执行它的依赖，所以我们打包的时候只要调用install Task即可， 123456789101112131415161718192021installTask.dependsOn(tasks, variantScope.getAssembleTask());variantOutputScope.getAssembleTask().dependsOn(tasks, zipAlignTask);zipAlignTask.dependsOn(tasks, packageApp);packageApp.dependsOn(tasks, stream.getDependencies());packageApp.dependsOn(tasks, validateSigningTask);packageApp.dependsOn(tasks, variantScope.getMergeAssetsTask());packageApp.dependsOn(tasks, variantOutputScope.getProcessResourcesTask());packageApp.optionalDependsOn( tasks, variantOutputScope.getShrinkResourcesTask(), variantOutputScope.getVariantScope().getJavaCompilerTask(), javacTask, variantOutputData.packageSplitResourcesTask, variantOutputData.packageSplitAbiTask);javacTask.dependsOn(tasks, javacIncrementalSafeguard);variantOutputScope.getProcessResourcesTask().dependsOn(tasks, scope.getMergeResourcesTask());generateBuildConfigTask.dependsOn(tasks, scope.getCheckManifestTask());scope.getSourceGenTask().dependsOn(tasks, generateBuildConfigTask.getName());mergeResourcesTask.dependsOn(tasks, scope.getPrepareDependenciesTask(), scope.getResourceGenTask());scope.getResourceGenTask().dependsOn(tasks, generateResValuesTask); 从这里粘贴的各个dependsOn方法可以看出，scope.getSourceGenTask()和installTask只有依赖其他Task，没有被其他Task依赖。installTask就不讲了，这就是应该我们开发完成后主动触发的。那么scope.getSourceGenTask()是什么时候被触发的呢？ 原来，是我们在AS中点击sync的时候触发的，这个时候会执行[:app:generateDebugSources]，这样就触发了scope.getSourceGenTask()，因为它依赖generateBuildConfigTask，所以这个时候也会生成我们最终使用的BuildConfig.java文件，也会检测Manifest的合法性 所以，我们可以通过调用installTask，让这个Task帮我们调用所有它依赖的Task，来完成整个Apk的打包签名安装工作，不过AS的gradle并不是只调用installTask而已，我觉得应该在installTask中途做了一个hook，加入了GUI，否则正常调用installTask的话，不会出现那个选择安装到哪个手机的对话框的。 这样我们整个打包流程点和面都齐全了，这个系列的文章暂时就告一段落了，接下来有空会选择填前面文章中留下的坑，比如classes如何变成dex的，aapt是如何处理那些资源的等…]]></content>
      <tags>
        <tag>AndroidPlugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidPlugin源码解析(八)]]></title>
    <url>%2F2017%2F09%2F30%2FAndroidPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E5%85%AB)%2F</url>
    <content type="text"><![CDATA[这篇文章我们就来看看打包过程中最后一个方法createPackagingTask createPackagingTask123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225public void createPackagingTask(@NonNull TaskFactory tasks, @NonNull VariantScope variantScope, boolean publishApk, @Nullable AndroidTask&lt;InstantRunWrapperTask&gt; fullBuildInfoGeneratorTask) &#123; GlobalScope globalScope = variantScope.getGlobalScope(); ApkVariantData variantData = (ApkVariantData) variantScope.getVariantData(); boolean signedApk = variantData.isSigned(); // signingConfig配置不为null，且正确配置 boolean multiOutput = variantData.getOutputs().size() &gt; 1; // 这里由于忽视split，所以暂时认为这个值为false GradleVariantConfiguration variantConfiguration = variantScope.getVariantConfiguration(); /** * PrePackaging step class that will look if the packaging of the main APK split is * necessary when running in InstantRun mode. In InstantRun mode targeting an api 23 or * above device, resources are packaged in the main split APK. However when a warm swap is * possible, it is not necessary to produce immediately the new main SPLIT since the runtime * use the resources.ap_ file directly. However, as soon as an incompatible change forcing a * cold swap is triggered, the main APK must be rebuilt (even if the resources were changed * in a previous build). */ IncrementalMode incrementalMode = getIncrementalMode(variantConfiguration); List&lt;ApkVariantOutputData&gt; outputDataList = variantData.getOutputs(); // loop on all outputs. The only difference will be the name of the task, and location // of the generated data. for (final ApkVariantOutputData variantOutputData : outputDataList) &#123; final VariantOutputScope variantOutputScope = variantOutputData.getScope(); final String outputName = variantOutputData.getFullName(); InstantRunPatchingPolicy patchingPolicy = variantScope.getInstantRunBuildContext().getPatchingPolicy(); DefaultGradlePackagingScope packagingScope = new DefaultGradlePackagingScope(variantOutputScope); AndroidTask&lt;PackageApplication&gt; packageApp = androidTasks.create( tasks, new PackageApplication.StandardConfigAction( packagingScope, patchingPolicy)); packageApp.configure( tasks, task -&gt; variantOutputData.packageAndroidArtifactTask = task); TransformManager transformManager = variantScope.getTransformManager(); // Common code for both packaging tasks. Consumer&lt;AndroidTask&lt;PackageApplication&gt;&gt; configureResourcesAndAssetsDependencies = task -&gt; &#123; task.dependsOn(tasks, variantScope.getMergeAssetsTask()); task.dependsOn(tasks, variantOutputScope.getProcessResourcesTask()); transformManager .getStreams(StreamFilter.RESOURCES) .forEach(stream -&gt; task.dependsOn(tasks, stream.getDependencies())); &#125;; configureResourcesAndAssetsDependencies.accept(packageApp); CoreSigningConfig signingConfig = packagingScope.getSigningConfig(); //noinspection VariableNotUsedInsideIf - we use the whole packaging scope below. if (signingConfig != null) &#123; ValidateSigningTask.ConfigAction configAction = new ValidateSigningTask.ConfigAction(packagingScope); AndroidTask&lt;?&gt; validateSigningTask = androidTasks.get(configAction.getName()); if (validateSigningTask == null) &#123; validateSigningTask = androidTasks.create(tasks, configAction); &#125; packageApp.dependsOn(tasks, validateSigningTask); &#125; packageApp.optionalDependsOn( tasks, variantOutputScope.getShrinkResourcesTask(), // TODO: When Jack is converted, add activeDexTask to VariantScope. variantOutputScope.getVariantScope().getJavaCompilerTask(), // TODO: Remove when Jack is converted to AndroidTask. variantData.javaCompilerTask, variantOutputData.packageSplitResourcesTask, variantOutputData.packageSplitAbiTask); for (TransformStream stream : transformManager.getStreams(StreamFilter.DEX)) &#123; // TODO Optimize to avoid creating too many actions packageApp.dependsOn(tasks, stream.getDependencies()); &#125; for (TransformStream stream : transformManager.getStreams(StreamFilter.NATIVE_LIBS)) &#123; // TODO Optimize to avoid creating too many actions packageApp.dependsOn(tasks, stream.getDependencies()); &#125; variantScope.setPackageApplicationTask(packageApp); AndroidTask&lt;?&gt; appTask = packageApp; if (signedApk) &#123; /* * There may be a zip align task in the variant output scope, even if we don't * need one for this because we're using new packaging. */ if (variantData.getZipAlignEnabled() &amp;&amp; variantOutputScope.getSplitZipAlignTask() != null) &#123; appTask.dependsOn(tasks, variantOutputScope.getSplitZipAlignTask()); &#125; &#125; // single output variantOutputScope.setAssembleTask(variantScope.getAssembleTask()); variantOutputData.assembleTask = variantData.assembleVariantTask; variantOutputScope.getAssembleTask().dependsOn(tasks, appTask); if (publishApk) &#123; final String projectBaseName = globalScope.getProjectBaseName(); // if this variant is the default publish config or we also should publish non // defaults, proceed with declaring our artifacts. if (getExtension().getDefaultPublishConfig().equals(outputName)) &#123; appTask.configure(tasks, packageTask -&gt; project.getArtifacts().add("default", new ApkPublishArtifact( projectBaseName, null, (FileSupplier) packageTask))); for (FileSupplier outputFileProvider : variantOutputData.getSplitOutputFileSuppliers()) &#123; project.getArtifacts().add("default", new ApkPublishArtifact(projectBaseName, null, outputFileProvider)); &#125; try &#123; if (variantOutputData.getMetadataFile() != null) &#123; project.getArtifacts().add( "default" + VariantDependencies.CONFIGURATION_METADATA, new MetadataPublishArtifact(projectBaseName, null, variantOutputData.getMetadataFile())); &#125; &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; if (variantData.getMappingFileProvider() != null) &#123; project.getArtifacts().add( "default" + VariantDependencies.CONFIGURATION_MAPPING, new MappingPublishArtifact(projectBaseName, null, variantData.getMappingFileProvider())); &#125; &#125; if (getExtension().getPublishNonDefault()) &#123; appTask.configure(tasks, packageTask -&gt; project.getArtifacts().add( variantData.getVariantDependency().getPublishConfiguration().getName(), new ApkPublishArtifact( projectBaseName, null, (FileSupplier) packageTask))); for (FileSupplier outputFileProvider : variantOutputData.getSplitOutputFileSuppliers()) &#123; project.getArtifacts().add( variantData.getVariantDependency().getPublishConfiguration().getName(), new ApkPublishArtifact( projectBaseName, null, outputFileProvider)); &#125; try &#123; if (variantOutputData.getMetadataFile() != null) &#123; project.getArtifacts().add( variantData.getVariantDependency().getMetadataConfiguration().getName(), new MetadataPublishArtifact( projectBaseName, null, variantOutputData.getMetadataFile())); &#125; &#125; catch (IOException e) &#123; throw new RuntimeException(e); &#125; if (variantData.getMappingFileProvider() != null) &#123; project.getArtifacts().add( variantData.getVariantDependency().getMappingConfiguration().getName(), new MappingPublishArtifact( projectBaseName, null, variantData.getMappingFileProvider())); &#125; if (variantData.classesJarTask != null) &#123; project.getArtifacts().add( variantData.getVariantDependency().getClassesConfiguration().getName(), variantData.classesJarTask); &#125; &#125; &#125; &#125; // create install task for the variant Data. This will deal with finding the // right output if there are more than one. // Add a task to install the application package if (signedApk) &#123; AndroidTask&lt;InstallVariantTask&gt; installTask = androidTasks.create( tasks, new InstallVariantTask.ConfigAction(variantScope)); installTask.dependsOn(tasks, variantScope.getAssembleTask()); &#125; if (getExtension().getLintOptions().isCheckReleaseBuilds() &amp;&amp; (incrementalMode == IncrementalMode.NONE)) &#123; createLintVitalTask(tasks, variantData); &#125; // add an uninstall task final AndroidTask&lt;UninstallTask&gt; uninstallTask = androidTasks.create( tasks, new UninstallTask.ConfigAction(variantScope)); tasks.named(UNINSTALL_ALL, uninstallAll -&gt; uninstallAll.dependsOn(uninstallTask.getName()));&#125; 这个方法很长，我们挑重点来看。 先看AndroidTask&lt;PackageApplication&gt;这个Task，这个Task具体做哪些事情呢？ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@Overrideprotected void doFullTaskAction() throws IOException &#123; /* * Clear the cache to make sure we have do not do an incremental build. */ cacheByPath.clear(); /* * Also clear the intermediate build directory. We don't know if anything is in there and * since this is a full build, we don't want to get any interference from previous state. */ // build/intermediates/incremental/ FileUtils.deleteDirectoryContents(getIncrementalFolder()); Set&lt;File&gt; androidResources = new HashSet&lt;&gt;(); // build/intermediates/res/resources-$&#123;buildType&#125;.ap_ // 开启shrinkResources build/intermediates/res/resources-$&#123;buildType&#125;-stripped.ap_ File androidResourceFile = getResourceFile(); if (androidResourceFile != null) &#123; androidResources.add(androidResourceFile); &#125; /* * Additionally, make sure we have no previous package, if it exists. */ // build/outpus/apk/ getOutputFile().delete(); ImmutableMap&lt;RelativeFile, FileStatus&gt; updatedDex = IncrementalRelativeFileSets.fromZipsAndDirectories(getDexFolders()); ImmutableMap&lt;RelativeFile, FileStatus&gt; updatedJavaResources = IncrementalRelativeFileSets.fromZipsAndDirectories(getJavaResourceFiles()); ImmutableMap&lt;RelativeFile, FileStatus&gt; updatedAssets = IncrementalRelativeFileSets.fromZipsAndDirectories( Collections.singleton(getAssets())); ImmutableMap&lt;RelativeFile, FileStatus&gt; updatedAndroidResources = IncrementalRelativeFileSets.fromZipsAndDirectories(androidResources); ImmutableMap&lt;RelativeFile, FileStatus&gt; updatedJniResources= IncrementalRelativeFileSets.fromZipsAndDirectories(getJniFolders()); doTask( updatedDex, updatedJavaResources, updatedAssets, updatedAndroidResources, updatedJniResources); &#125; 这段代码里关键代码执行路径都写在了注释里，发现这段代码调用了doTask方法，我们看看这个方法做了什么: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private void doTask( @NonNull ImmutableMap&lt;RelativeFile, FileStatus&gt; changedDex, @NonNull ImmutableMap&lt;RelativeFile, FileStatus&gt; changedJavaResources, @NonNull ImmutableMap&lt;RelativeFile, FileStatus&gt; changedAssets, @NonNull ImmutableMap&lt;RelativeFile, FileStatus&gt; changedAndroidResources, @NonNull ImmutableMap&lt;RelativeFile, FileStatus&gt; changedNLibs) throws IOException &#123; PrivateKey key; X509Certificate certificate; boolean v1SigningEnabled; boolean v2SigningEnabled; try &#123; if (signingConfig != null &amp;&amp; signingConfig.isSigningReady()) &#123; CertificateInfo certificateInfo = KeystoreHelper.getCertificateInfo( signingConfig.getStoreType(), checkNotNull(signingConfig.getStoreFile()), checkNotNull(signingConfig.getStorePassword()), checkNotNull(signingConfig.getKeyPassword()), checkNotNull(signingConfig.getKeyAlias())); key = certificateInfo.getKey(); certificate = certificateInfo.getCertificate(); v1SigningEnabled = signingConfig.isV1SigningEnabled(); v2SigningEnabled = signingConfig.isV2SigningEnabled(); &#125; else &#123; key = null; certificate = null; v1SigningEnabled = false; v2SigningEnabled = false; &#125; ApkCreatorFactory.CreationData creationData = new ApkCreatorFactory.CreationData( getOutputFile(), key, certificate, v1SigningEnabled, v2SigningEnabled, null, // BuiltBy getBuilder().getCreatedBy(), getMinSdkVersion(), PackagingUtils.getNativeLibrariesLibrariesPackagingMode(manifest), getNoCompressPredicate()::apply); try (IncrementalPackager packager = createPackager(creationData)) &#123; packager.updateDex(changedDex); packager.updateJavaResources(changedJavaResources); packager.updateAssets(changedAssets); packager.updateAndroidResources(changedAndroidResources); packager.updateNativeLibraries(changedNLibs); &#125; &#125; catch (PackagerException | KeytoolException e) &#123; throw new RuntimeException(e); &#125; /* * Save all used zips in the cache. */ // cache相关代码，忽视掉&#125; 看到这些参数v1SigningEnabled, v2SigningEnabled不知道你会联想到什么，没错，就是和apk签名相关。 这里的核心就是这段代码: 123456IncrementalPackager packager = createPackager(creationData))packager.updateDex(changedDex);packager.updateJavaResources(changedJavaResources);packager.updateAssets(changedAssets);packager.updateAndroidResources(changedAndroidResources);packager.updateNativeLibraries(changedNLibs); 创建Packager对象这里就不看了，在下面的方法中用到这里面的参数的时候再来讲讲对应参数的含义。也就是看一下接下来的5个方法: 1234packager.updateDex(changedDex);packager.updateJavaResources(changedJavaResources);packager.updateAssets(changedAssets);packager.updateAndroidResources(changedAndroidResources); 后面这5个方法最终全部是调用updateFiles方法，这个方法的主要执行的都是mApkCreator对象的方法，所以先讲一下ApkCreator这个对象，讲完之后再来看一看这个方法: 对于ApkZFileCreator的构造函数来说，主要是构造了一个ZFile文件，我们直接看那个方法: ZFiles apk1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859public static ZFile apk( @NonNull File f, @NonNull ZFileOptions options, @Nullable PrivateKey key, @Nullable X509Certificate certificate, boolean v1SigningEnabled, boolean v2SigningEnabled, @Nullable String builtBy, @Nullable String createdBy, int minSdkVersion) throws IOException &#123; ZFile zfile = apk(f, options); // 根据我们的代码分析过程，这里是null if (builtBy == null) &#123; builtBy = DEFAULT_BUILD_BY; &#125; if (createdBy == null) &#123; createdBy = DEFAULT_CREATED_BY; &#125; ManifestGenerationExtension manifestExt = new ManifestGenerationExtension(builtBy, createdBy); manifestExt.register(zfile); if (key != null &amp;&amp; certificate != null) &#123; if (v1SigningEnabled) &#123; String apkSignedHeaderValue = (v2SigningEnabled) ? SignatureExtension .SIGNATURE_ANDROID_APK_SIGNER_VALUE_WHEN_V2_SIGNED : null; SignatureExtension jarSignatureSchemeExt = new SignatureExtension(manifestExt, minSdkVersion, certificate, key, apkSignedHeaderValue); jarSignatureSchemeExt.register(); &#125; if (v2SigningEnabled) &#123; FullApkSignExtension apkSignatureSchemeV2Ext = new FullApkSignExtension( zfile, minSdkVersion, certificate, key); apkSignatureSchemeV2Ext.register(); &#125; if (!v1SigningEnabled) &#123; // Remove v1 signature files from the APK for (StoredEntry entry : zfile.entries()) &#123; if (SignatureExtension.isIgnoredFile( entry.getCentralDirectoryHeader().getName())) &#123; entry.delete(); &#125; &#125; &#125; &#125; return zfile;&#125; 首先，这个方法通过apk(f, options)生成了ZFile文件，这个方法设置了ZFile的对齐规则，然后，调用ZFile的构造函数生成ZFile，也就是空的最终生成的Apk文件，生成之后，我们继续往下看，可以看到，这里有几个Extension, 分别为ManifestGenerationExtension, SignatureExtension, FullApkSignExtension, 我们来看看这三个类的作用是什么: ManifestGenerationExtension register12345678910111213141516public void register(@NonNull ZFile zFile) throws IOException &#123; Preconditions.checkState(mExtension == null, "register() has already been invoked."); mZFile = zFile; rebuildManifest(); mExtension = new ZFileExtension() &#123; @Nullable @Override public IOExceptionRunnable beforeUpdate() &#123; return ManifestGenerationExtension.this::updateManifest; &#125; &#125;; mZFile.addZFileExtension(mExtension);&#125; 这个方法的核心在mZFile.addZFileExtension(mExtension);，这个ZFileExtension的作用是在ZFile对应状态的时候通知该Extensions执行操作。在最终的Apk中，反编译一下，META-INF/MANIFEST.MF这个文件就是这里生成的。 SignatureExtension register12345678910111213141516171819202122232425262728293031323334353637383940414243444546public void register() throws IOException &#123; Preconditions.checkState(mExtension == null, "register() already invoked"); mExtension = new ZFileExtension() &#123; @Nullable @Override public IOExceptionRunnable beforeUpdate() &#123; return SignatureExtension.this::updateSignatureIfNeeded; &#125; @Nullable @Override public IOExceptionRunnable added(@NonNull final StoredEntry entry, @Nullable final StoredEntry replaced) &#123; if (replaced != null) &#123; Preconditions.checkArgument(entry.getCentralDirectoryHeader().getName().equals( replaced.getCentralDirectoryHeader().getName())); &#125; if (isIgnoredFile(entry.getCentralDirectoryHeader().getName())) &#123; return null; &#125; return () -&gt; &#123; if (replaced != null) &#123; SignatureExtension.this.removed(replaced); &#125; SignatureExtension.this.added(entry); &#125;; &#125; @Nullable @Override public IOExceptionRunnable removed(@NonNull final StoredEntry entry) &#123; if (isIgnoredFile(entry.getCentralDirectoryHeader().getName())) &#123; return null; &#125; return () -&gt; SignatureExtension.this.removed(entry); &#125; &#125;; mManifestExtension.zFile().addZFileExtension(mExtension); readSignatureFile();&#125; 这里也是一样，注册了一个ZFileExtension，作用就是在后面写入文件的时候进行签名，这个签名文件的位置是META-INF/CERT.SF这里是V1签名的实现，如果允许V2签名，则在该文件的前几行的存在X-Android-APK-Signed: 2这个声明，否则的话说明没开启V2签名。V2签名的register实现我们就不看了，和这个类似，如果想研究V2签名的细节，这里很重要，但是你要了解Zip文件格式再来看会很有帮助。 好了，这些讲完之后我们就可以看updateFiles方法了，记得每次ZFile文件改变状态的时候，都会回调上面的这些Extension。 IncrementalPackager updateFiles1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071private void updateFiles(@NonNull Set&lt;PackagedFileUpdate&gt; updates) throws IOException &#123; Preconditions.checkNotNull(mApkCreator, "mApkCreator == null"); // 这个的意思是拿到状态为`FileStatus.REMOVED`的文件，接下来拿到文件名 Iterable&lt;String&gt; deletedPaths = Iterables.transform( Iterables.filter( updates, Predicates.compose( Predicates.equalTo(FileStatus.REMOVED), PackagedFileUpdate.EXTRACT_STATUS)), PackagedFileUpdate.EXTRACT_NAME); for (String deletedPath : deletedPaths) &#123; mApkCreator.deleteFile(deletedPath); &#125; // 状态为FileStatus.NEW或者FileStatus.CHANGED的PackagedFileUpdate断言 Predicate&lt;PackagedFileUpdate&gt; isNewOrChanged = Predicates.compose( Predicates.or( Predicates.equalTo(FileStatus.NEW), Predicates.equalTo(FileStatus.CHANGED)), PackagedFileUpdate.EXTRACT_STATUS); // Source为Base的文件，source的类型为`build/intermediates/incremental/package$&#123;buildType&#125;/dex-renamer-state.txt` Function&lt;PackagedFileUpdate, File&gt; extractBaseFile = Functions.compose( RelativeFile.EXTRACT_BASE, PackagedFileUpdate.EXTRACT_SOURCE); Iterable&lt;PackagedFileUpdate&gt; newOrChangedNonArchiveFiles = Iterables.filter( updates, Predicates.and( isNewOrChanged, Predicates.compose( Files.isDirectory(), extractBaseFile))); for (PackagedFileUpdate rf : newOrChangedNonArchiveFiles) &#123; mApkCreator.writeFile(rf.getSource().getFile(), rf.getName()); &#125; Iterable&lt;PackagedFileUpdate&gt; newOrChangedArchiveFiles = Iterables.filter( updates, Predicates.and( isNewOrChanged, Predicates.compose( Files.isFile(), extractBaseFile))); Iterable&lt;File&gt; archives = Iterables.transform(newOrChangedArchiveFiles, extractBaseFile); Set&lt;String&gt; names = Sets.newHashSet( Iterables.transform( newOrChangedArchiveFiles, PackagedFileUpdate.EXTRACT_NAME)); /* * Build the name map. The name of the file in the filesystem (or zip file) may not * match the name we want to package it as. See PackagedFileUpdate for more information. */ Map&lt;String, String&gt; pathNameMap = Maps.newHashMap(); for (PackagedFileUpdate archiveUpdate : newOrChangedArchiveFiles) &#123; pathNameMap.put(archiveUpdate.getSource().getOsIndependentRelativePath(), archiveUpdate.getName()); &#125; for (File arch : Sets.newHashSet(archives)) &#123; mApkCreator.writeZip(arch, pathNameMap::get, name -&gt; !names.contains(name)); &#125;&#125; 首先通过各种条件过滤出符合条件的文件列表，然后通过mApkCreator.writeFile mApkCreator.writeZip这两个方法将文件写入apk中。 这里就不详细讲了，因为这些方法最终还是调用ZFile对象的方法，想了解这些方法的具体实现，请先了解Zip文件格式，或者等我之后的文章。 这样，就把所有的Dex, JavaResources, Assets, AndroidResources, JniResources，写入Apk文件中，并进行了签名。 回到createPackagingTask方法继续往下看，可以看到有ValidateSigningTask这个Task。 这个Task我们就不详细解释了，因为代码很容易理解，就是检测keystore文件是否存在，不存在的话检测默认的debug.keystore。 因为packageApp.dependsOn(tasks, validateSigningTask);这个方法，我们知道，先验证签名后打包Apk。 好了，继续往下看，可以看到一个ZipAlign的Task，这个Task的任务就是执行zipalign，也就是将文件进行4位对齐。 这个Task构造了zipalign的命令行参数，执行的命令为${zipalignPath}/zipalign -f -p 4 ${inputFile} ${outputFile} 下面就是if (publishApk)这个if条件了，里面的内容就是增加最终输出的文件的个数，每个Artifact代表一个最终的文件。我们这个系列的文章主要是apk的流程，所以这里就不详细分析了。 前面完成了打包Task，后面就可以安装到手机里了，安装到手机由InstallVariantTask这个任务完成。 这个任务使用adb，将文件传入手机中，并使用pm命令安装apk。原先我还以为直接使用adb install -r ${apkFile}来实现的，原来不是我理解的啊。 最后，添加Lint任务，加入卸载Apk的任务，这样，整个Apk打包流程就结束了。]]></content>
      <tags>
        <tag>AndroidPlugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidPlugin源码解析(七)]]></title>
    <url>%2F2017%2F09%2F10%2FAndroidPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%83)%2F</url>
    <content type="text"><![CDATA[忽视了Aidl, Shader, Ndk, Jni, Jack, DataBinding, StripNativeLibrary, Split, InstantRun, Lint这些Task之后，我们就只剩下面三个重要的Task了： createJavacTask(tasks, variantScope); createPostCompilationTasks(tasks, variantScope); createPackagingTask(tasks, variantScope, true /publishApk/, fullBuildInfoGeneratorTask); 这篇文章我们来分析前面两个Task createJavacTask这个Task的方法为: 123456789101112131415161718192021222324252627public AndroidTask&lt;? extends JavaCompile&gt; createJavacTask( @NonNull final TaskFactory tasks, @NonNull final VariantScope scope) &#123; final BaseVariantData&lt;? extends BaseVariantOutputData&gt; variantData = scope.getVariantData(); // 这是AndroidJavaCompileTask的前置Task，如果生成的源码有变动，则清空AndroidJavaCompile的输出目录，强制重新编译 // 这个文件为 build/intermediates/incremental-safeguard/tag.txt AndroidTask&lt;IncrementalSafeguard&gt; javacIncrementalSafeguard = androidTasks.create(tasks, new IncrementalSafeguard.ConfigAction(scope)); final AndroidTask&lt;? extends JavaCompile&gt; javacTask = androidTasks.create(tasks, new JavaCompileConfigAction(scope)); scope.setJavacTask(javacTask); javacTask.dependsOn(tasks, javacIncrementalSafeguard); setupCompileTaskDependencies(tasks, scope, javacTask); // Create jar task for uses by external modules. // 还没遇见过，暂时忽视 // 生成的文件路径在 build/intermediates/classes-jar/$&#123;buildType&#125;/class.jar if (variantData.getVariantDependency().getClassesConfiguration() != null) &#123; AndroidTask&lt;Jar&gt; packageJarArtifact = androidTasks.create(tasks, new PackageJarArtifactConfigAction(scope)); packageJarArtifact.dependsOn(tasks, javacTask); &#125; return javacTask;&#125; 看到这里相当于存在3个Task，但是我们只要关心javacTask即可， 第一个javacIncrementalSafeguard,就是类似标识位的东东， 最后一个packageJarArtifact，因为我还没遇到使用外部modules的情况，所以也忽略， 大家如果在打包完成的build路径下看到我提到的路径，就可以在这里查看情况。 好的，那么我们来仔细看一下javacTask 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public void execute(@NonNull final AndroidJavaCompile javacTask) &#123; scope.getVariantData().javacTask = javacTask; // compileSdkVersion &gt;= 24，需要用JDK 1.8及以上版本 javacTask.compileSdkVersion = scope.getGlobalScope().getExtension().getCompileSdkVersion(); javacTask.mBuildContext = scope.getInstantRunBuildContext(); // We can't just pass the collection directly, as the instanceof check in the incremental // compile doesn't work recursively currently, so every ConfigurableFileTree needs to be // directly in the source array. for (ConfigurableFileTree fileTree : scope.getVariantData().getJavaSources()) &#123; javacTask.source(fileTree); &#125; // Set boot classpath if we don't need to keep the default. Otherwise, this is added as // normal classpath. javacTask.getOptions().setBootClasspath( Joiner.on(File.pathSeparator).join( scope.getGlobalScope().getAndroidBuilder() .getBootClasspathAsStrings(false))); javacTask.setDestinationDir(scope.getJavaOutputDir()); // build/intermediates/classes/ javacTask.setDependencyCacheDir(scope.getJavaDependencyCache()); // build/intermediates/dependency-cache/ CompileOptions compileOptions = scope.getGlobalScope().getExtension().getCompileOptions(); AbstractCompilesUtil.configureLanguageLevel( javacTask, compileOptions, scope.getGlobalScope().getExtension().getCompileSdkVersion(), scope.getVariantConfiguration().getJackOptions().isEnabled()); javacTask.getOptions().setEncoding(compileOptions.getEncoding()); GlobalScope globalScope = scope.getGlobalScope(); Project project = scope.getGlobalScope().getProject(); CoreAnnotationProcessorOptions annotationProcessorOptions = scope.getVariantConfiguration().getJavaCompileOptions() .getAnnotationProcessorOptions(); checkNotNull(annotationProcessorOptions.getIncludeCompileClasspath()); Collection&lt;File&gt; processorPath = Lists.newArrayList( scope.getVariantData().getVariantDependency() .resolveAndGetAnnotationProcessorClassPath( annotationProcessorOptions.getIncludeCompileClasspath(), scope.getGlobalScope().getAndroidBuilder().getErrorReporter())); if (!processorPath.isEmpty()) &#123; if (Boolean.TRUE.equals(annotationProcessorOptions.getIncludeCompileClasspath())) &#123; processorPath.addAll(javacTask.getClasspath().getFiles()); &#125; javacTask.getOptions().getCompilerArgs().add("-processorpath"); javacTask.getOptions().getCompilerArgs().add(FileUtils.joinFilePaths(processorPath)); &#125; if (!annotationProcessorOptions.getClassNames().isEmpty()) &#123; javacTask.getOptions().getCompilerArgs().add("-processor"); javacTask.getOptions().getCompilerArgs().add( Joiner.on(',').join(annotationProcessorOptions.getClassNames())); &#125; if (!annotationProcessorOptions.getArguments().isEmpty()) &#123; for (Map.Entry&lt;String, String&gt; arg : annotationProcessorOptions.getArguments().entrySet()) &#123; javacTask.getOptions().getCompilerArgs().add( "-A" + arg.getKey() + "=" + arg.getValue()); &#125; &#125; // Create directory for output of annotation processor. javacTask.doFirst(task -&gt; &#123; FileUtils.mkdirs(scope.getAnnotationProcessorOutputDir()); // build/generated/source/apt &#125;); javacTask.getOptions().getCompilerArgs().add("-s"); javacTask.getOptions().getCompilerArgs().add( scope.getAnnotationProcessorOutputDir().getAbsolutePath());&#125; 看下来这个代码，这里就是在给javac命令添加参数，看到setDestinationDir()方法，说明javac之后生成的代码路径为build/intermediates/classes/。先往回看代码: 1234javacTask.getOptions().setBootClasspath( Joiner.on(File.pathSeparator).join( scope.getGlobalScope().getAndroidBuilder() .getBootClasspathAsStrings(false))); 这个方法就是设置一些很基础的jar包的classpath，比如android.jar。 这个代码通过查找Sdk location来获取这些jar包的位置，至于使用的是哪个版本，则由compileSdkVersion决定， 所以，升级compileSdkVersion，就能使用最新的android.jar的sdk， 还有，如果你想使用暴露隐藏方法的android.jar，替换对应compileSdkVersion的android.jar即可。具体路径在${sdkVersion}/platforms/android-${compileSdkVersion}。 往下继续看代码，可以看到一个叫做processorPath的列表，processorPath这个列表是怎么来的呢？就是我们在build.gradle里面dependencies里面声明的annotationProcessor。 假设你的项目里有butterknife之类的东东，所以这个列表不会为空，所以会为javac添加如下参数-processorpath ${processorPath}, 继续看，发现又添加了具体的apt处理类的参数: -processor ${processorClassName1,processorClassName2...}， 最后，如果你为某个annotationProcessor设置了参数，就会为javac再加入新的参数-A ${key}=${value}, 为某个annotationProcessor设置了参数的方式为(以butterknife为例) javaCompileOptions.annotationProcessorOptions.arguments[&#39;butterknife.debuggable&#39;] = &#39;false&#39; 所以，这个地方给javac添加的参数类似-A butterknife.debuggable=false。 最后，要在执行javac之前做一些处理，我们可以看到，就是创建build/generated/source/apt这个文件夹，如果存在，删除之后再重新创建。创建好此文件夹后，就可以加入-s ${annotationProcessorOutputDir}, 这样，无论是需要apt生成的代码，还是最终需要javac生成的代码都配置好了，如果想知道每个参数的具体含义，请参考javac -help 剩下的就是调用javac命令来执行了，因为这个属于JavaCompile task，这个Task是gradle自带的，所以到这里createJavacTask方法就结束了。 接下来这个Task并不是打包过程的一步，放在这里是因为如果你需要打包一个Jar包给别人，那么这里是最合适执行此Task的地方，因为这个Task要依赖javacTask。 这个Task的任务就是把Javac生成的那些文件，R文件，BuildConfig文件打包，所以这里也没有写出这个Task的名字，就直接创建了， 创建代码为:getAndroidTasks().create(tasks, new AndroidJarTask.JarClassesConfigAction(variantScope));， 这个Task执行结果放在build/intermediates/packaged/${buildType}/classes.jar。 不过，这里只是包含当前lib生成的class文件，不包含依赖的class文件。 了解到这里，我们就可以继续往下看了。 createPostCompilationTasks123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118/** * Creates the post-compilation tasks for the given Variant. * * These tasks create the dex file from the .class files, plus optional intermediary steps like * proguard and jacoco * */public void createPostCompilationTasks( @NonNull TaskFactory tasks, @NonNull final VariantScope variantScope) &#123; checkNotNull(variantScope.getJavacTask()); final BaseVariantData&lt;? extends BaseVariantOutputData&gt; variantData = variantScope.getVariantData(); final GradleVariantConfiguration config = variantData.getVariantConfiguration(); TransformManager transformManager = variantScope.getTransformManager(); // ---- Code Coverage first ----- // 如果有单元测试代码，且testCoverageEnabled，则执行JacocoTansform boolean isTestCoverageEnabled = config.getBuildType().isTestCoverageEnabled() &amp;&amp; !config.getType().isForTesting() &amp;&amp; getIncrementalMode(variantScope.getVariantConfiguration()) == IncrementalMode.NONE; if (isTestCoverageEnabled) &#123; createJacocoTransform(tasks, variantScope); &#125; boolean isMinifyEnabled = isMinifyEnabled(variantScope); boolean isMultiDexEnabled = config.isMultiDexEnabled(); // Switch to native multidex if possible when using instant run. boolean isLegacyMultiDexMode = isLegacyMultidexMode(variantScope); AndroidConfig extension = variantScope.getGlobalScope().getExtension(); // ----- External Transforms ----- // apply all the external transforms. List&lt;Transform&gt; customTransforms = extension.getTransforms(); List&lt;List&lt;Object&gt;&gt; customTransformsDependencies = extension.getTransformsDependencies(); for (int i = 0, count = customTransforms.size() ; i &lt; count ; i++) &#123; Transform transform = customTransforms.get(i); AndroidTask&lt;TransformTask&gt; task = transformManager .addTransform(tasks, variantScope, transform); // task could be null if the transform is invalid. if (task != null) &#123; List&lt;Object&gt; deps = customTransformsDependencies.get(i); if (!deps.isEmpty()) &#123; task.dependsOn(tasks, deps); &#125; // if the task is a no-op then we make assemble task depend on it. if (transform.getScopes().isEmpty()) &#123; variantScope.getAssembleTask().dependsOn(tasks, task); &#125; &#125; &#125; // ----- Minify next ----- if (isMinifyEnabled) &#123; boolean outputToJarFile = isMultiDexEnabled &amp;&amp; isLegacyMultiDexMode; createMinifyTransform(tasks, variantScope, outputToJarFile); &#125; // ----- Multi-Dex support AndroidTask&lt;TransformTask&gt; multiDexClassListTask = null; // non Library test are running as native multi-dex if (isMultiDexEnabled &amp;&amp; isLegacyMultiDexMode) &#123; if (!variantData.getVariantConfiguration().getBuildType().isUseProguard()) &#123; throw new IllegalStateException( "Build-in class shrinker and multidex are not supported yet."); &#125; // ---------- // create a transform to jar the inputs into a single jar. if (!isMinifyEnabled) &#123; // merge the classes only, no need to package the resources since they are // not used during the computation. JarMergingTransform jarMergingTransform = new JarMergingTransform( TransformManager.SCOPE_FULL_PROJECT); variantScope.addColdSwapBuildTask( transformManager.addTransform(tasks, variantScope, jarMergingTransform)); &#125; // --------- // create the transform that's going to take the code and the proguard keep list // from above and compute the main class list. MultiDexTransform multiDexTransform = new MultiDexTransform( variantScope, extension.getDexOptions(), null); multiDexClassListTask = transformManager.addTransform( tasks, variantScope, multiDexTransform); multiDexClassListTask.optionalDependsOn(tasks, manifestKeepListTask); variantScope.addColdSwapBuildTask(multiDexClassListTask); &#125; // create dex transform DefaultDexOptions dexOptions = DefaultDexOptions.copyOf(extension.getDexOptions()); DexTransform dexTransform = new DexTransform( dexOptions, config.getBuildType().isDebuggable(), isMultiDexEnabled, isMultiDexEnabled &amp;&amp; isLegacyMultiDexMode ? variantScope.getMainDexListFile() : null, variantScope.getPreDexOutputDir(), variantScope.getGlobalScope().getAndroidBuilder(), getLogger(), variantScope.getInstantRunBuildContext(), AndroidGradleOptions.getBuildCache(variantScope.getGlobalScope().getProject())); AndroidTask&lt;TransformTask&gt; dexTask = transformManager.addTransform( tasks, variantScope, dexTransform); // need to manually make dex task depend on MultiDexTransform since there's no stream // consumption making this automatic dexTask.optionalDependsOn(tasks, multiDexClassListTask);&#125; 看到最外层的注释，这里就是把class文件转化为dex文件的地方。那我们来详细跟踪一下代码。 这里应该有很多熟悉的参数名称，比如minifyEnabled,multiDexEnabled等，这些参数之后接下来就获取customTransforms这样一个Transform对象列表，这样一个列表是怎么来的呢？ 就是通过Android Plugin的extension的registerTransform注册的transfrom。 这个Transform是个什么东东呢？如果你写过Gradle插件，对这个应该不陌生， 这个就是Android Plugin暴露的Hook Api，让你可以自定义操作参与打包过程之中。 从这里也可以看出，gradle plugin引入的顺序，影响plugin的Transform被调用的顺序。 这些Transform就会被加入到TransformManager中，按顺序执行。 跳过这个将Transfrom加入TransformManager的过程，下面就轮到了// ----- Minify next -----， 看这个方法名createMinifyTransform，应该是创建Minify这个Transform，并加入TransformManager中。接下来我们跟进去看看细节。 简单几层跟进之后，如果useProguard属性设置为true,则执行如下两个方法: 123// createJarFile是bool值，Application中是true，Library中是falsecreateProguardTransform(taskFactory, variantScope, mappingConfiguration, createJarFile);createShrinkResourcesTransform(taskFactory, variantScope); 我们来一一查看，先看 createProguardTransform1234567891011121314151617181920212223242526272829303132private void createProguardTransform( @NonNull TaskFactory taskFactory, @NonNull VariantScope variantScope, @Nullable Configuration mappingConfiguration, boolean createJarFile) &#123; final BaseVariantData&lt;? extends BaseVariantOutputData&gt; variantData = variantScope .getVariantData(); final GradleVariantConfiguration variantConfig = variantData.getVariantConfiguration(); final BaseVariantData testedVariantData = variantScope.getTestedVariantData(); ProGuardTransform transform = new ProGuardTransform(variantScope, createJarFile); applyProguardConfig(transform, variantData); AndroidTask&lt;?&gt; task = variantScope.getTransformManager().addTransform(taskFactory, variantScope, transform, (proGuardTransform, proGuardTask) -&gt; variantData.mappingFileProviderTask = new FileSupplier() &#123; @NonNull @Override public Task getTask() &#123; return proGuardTask; &#125; @Override public File get() &#123; return proGuardTransform.getMappingFile(); &#125; &#125;);&#125; 这里最重要的就是两个语句， 一个是初始化ProGuardTransform并将其加入TransformManager中， 第二个是给ProGuardTransform设置配置， 在这里我们关注的是流程，所以ProGuardTransform是如何执行的就不在这里细讲了， 如果你熟悉Transform Api，那么就会知道这里执行的是ProGuardTransform里的transform方法，如果你有兴趣，看这个方法了解ProGuard执行的细节。 好了，那我们来看一看applyProguardConfig方法 applyProguardConfig12345678910111213141516171819final GradleVariantConfiguration variantConfig = variantData.getVariantConfiguration();transform.setConfigurationFiles(() -&gt; &#123; Set&lt;File&gt; proguardFiles = variantConfig.getProguardFiles( true, Collections.singletonList(ProguardFiles.getDefaultProguardFile( TaskManager.DEFAULT_PROGUARD_CONFIG_FILE, project))); // use the first output when looking for the proguard rule output of // the aapt task. The different outputs are not different in a way that // makes this rule file different per output. BaseVariantOutputData outputData = variantData.getOutputs().get(0); proguardFiles.add(outputData.processResourcesTask.getProguardOutputFile()); return proguardFiles;&#125;);if (variantData.getType() == LIBRARY) &#123; transform.keep("class **.R"); transform.keep("class **.R$*");&#125; 不知道你们有没有过好奇，我们在新建项目的时候，build.gradle文件中会有这么一行配置proguardFiles getDefaultProguardFile(&#39;proguard-android.txt&#39;)，这个文件在哪里呢，会不会可以改名字呢？这个的答案就在这里就可以找到。 就是下面这行代码 1ProguardFiles.getDefaultProguardFile(TaskManager.DEFAULT_PROGUARD_CONFIG_FILE, project)) 首先，它会检测参数值是否为”proguard-android.txt”或”proguard-android-optimize.txt”，也就说明了，getDefaultProguardFile只能填这两个参数。 接下来就是返回这个文件的具体路径在根目录的build文件夹下，在build/intermediates/proguard-files/这个目录下，文件名最后为当前gradle plugin的版本，这两个文件最初的位置在哪里呢？原来是${sdkPath}/tools/proguard/这个目录下的那两个文件. 还有，是不是好奇为什么出现在layout和Manifest里的东东都不会混淆，就是因为这行代码 1proguardFiles.add(outputData.processResourcesTask.getProguardOutputFile()); 这个就是给proguardFiles加入build.intermediates/proguard-rules/${buildType}/aapt_rules.txt，这个文件就是在前面的过程中生成的proguard的规则。 最后就是为Library单独配置的规则了，如果是Library，不混淆它的R文件。 到这里createProguardTransform方法就结束了。继续看下一个方法createShrinkResourcesTransform createShrinkResourcesTransform12345678910111213141516171819202122232425262728private void createShrinkResourcesTransform( @NonNull TaskFactory taskFactory, @NonNull VariantScope scope) &#123; CoreBuildType buildType = scope.getVariantConfiguration().getBuildType(); if (!buildType.isShrinkResources()) &#123; // The user didn't enable resource shrinking, silently move on. return; &#125; // if resources are shrink, insert a no-op transform per variant output // to transform the res package into a stripped res package for (final BaseVariantOutputData variantOutputData : scope.getVariantData().getOutputs()) &#123; VariantOutputScope variantOutputScope = variantOutputData.getScope(); ShrinkResourcesTransform shrinkResTransform = new ShrinkResourcesTransform( variantOutputData, variantOutputScope.getProcessResourcePackageOutputFile(), variantOutputScope.getShrinkedResourcesFile(), androidBuilder, logger); AndroidTask&lt;TransformTask&gt; shrinkTask = scope.getTransformManager() .addTransform(taskFactory, variantOutputScope, shrinkResTransform); // need to record this task since the package task will not depend // on it through the transform manager. variantOutputScope.setShrinkResourcesTask(shrinkTask); &#125;&#125; 这个方法很简短，老规矩，不分析这个Transform到底是怎么做的，这里将两点: shrinkResources默认是false，如果没有在buildType中主动声明为true，则此方法会直接返回。 这个shrinkResTransform是在ProGuardTransform之后加入的，也就意味着在最后处理代码的时候，先执行ProGuard,后执行ShrinkResources。 这个方法要讲的就这么多，我们再返回createPostCompilationTasks方法继续看下去。 接下里分析// ----- Multi-Dex support这一段代码 12345678910111213141516171819202122232425262728AndroidTask&lt;TransformTask&gt; multiDexClassListTask = null;// non Library test are running as native multi-dexif (isMultiDexEnabled &amp;&amp; isLegacyMultiDexMode) &#123; // ---------- // create a transform to jar the inputs into a single jar. if (!isMinifyEnabled) &#123; // merge the classes only, no need to package the resources since they are // not used during the computation. // 把所有的.class打包成一个combined.jar JarMergingTransform jarMergingTransform = new JarMergingTransform( TransformManager.SCOPE_FULL_PROJECT); variantScope.addColdSwapBuildTask( transformManager.addTransform(tasks, variantScope, jarMergingTransform)); &#125; // --------- // create the transform that's going to take the code and the proguard keep list // from above and compute the main class list. MultiDexTransform multiDexTransform = new MultiDexTransform( variantScope, extension.getDexOptions(), null); multiDexClassListTask = transformManager.addTransform( tasks, variantScope, multiDexTransform); multiDexClassListTask.optionalDependsOn(tasks, manifestKeepListTask); variantScope.addColdSwapBuildTask(multiDexClassListTask);&#125; 可以看到，这里的重点就是两个Transform: JarMergingTransform MultiDexTransform 虽然如此，但是JarMergingTransform本身的任务很简单，就是将class文件打成jar包，这里就不仔细分析了， 熟悉Transform Api的话很容易就能看懂，这个的最终结果是:build/intermediates/transform/${outputTypes}/${scope}/combined.jar这样一个jar包，对着结果来理解应该会更容易了。 好了，这样我们来仔细关注MultiDexTransform，我们来看看它的transform方法 MultiDexTransform transform1234//校验referencedInputs只能有一个，要么是jar，要么是directoryFile input = verifyInputs(invocation.getReferencedInputs()); shrinkWithProguard(input);computeList(input); 看起来就三个方法，第一个方法就是做一个校验；但是后面两个比较复杂，我们仔细研究一下。 MultiDexTransform shrinkWithProguard123456789101112131415161718192021222324252627282930313233343536private void shrinkWithProguard(@NonNull File input) throws IOException, ParseException &#123; dontobfuscate(); // 设置obfuscate = false dontoptimize(); // 设置 optimize = false dontpreverify(); // 设置 preverify = false dontwarn(); // 设置 warn = Lists.newArrayList("**") dontnote(); // 设置 note = Lists.newArrayList("**") forceprocessing(); // 设置 lastModified = Long.MAX_VALUE applyConfigurationFile(manifestKeepListProguardFile); if (userMainDexKeepProguard != null) &#123; applyConfigurationFile(userMainDexKeepProguard); &#125; // add a couple of rules that cannot be easily parsed from the manifest. keep("public class * extends android.app.Instrumentation &#123; &lt;init&gt;(); &#125;"); keep("public class * extends android.app.Application &#123; " + " &lt;init&gt;(); " + " void attachBaseContext(android.content.Context);" + "&#125;"); keep("public class * extends android.app.backup.BackupAgent &#123; &lt;init&gt;(); &#125;"); keep("public class * extends java.lang.annotation.Annotation &#123; *;&#125;"); keep("class com.android.tools.fd.** &#123;*;&#125;"); // Instant run. // handle inputs libraryJar(findShrinkedAndroidJar()); inJar(input); // outputs. outJar(variantScope.getProguardComponentsJarFile()); printconfiguration(configFileOut); // run proguard runProguard();&#125; 看到最后一个方法runProguard()，先猜测一下这个方法前面的过程是给Proguard设置参数的过程。经过分析，确实如此。 这里就点几点，userMainDexKeepProguard != null， 这个在什么情况下不为null呢？在bulidType中设置过这个参数multiDexKeepProguard的情况下不为null。 作为librayJar的参数到底是哪个Jar呢？是 build-tools/${buildToolsVersion}/lib/shrinkedAndroid.jar这个Jar。 outJar的最终位置在哪里呢？在build/intermediates/multi-dex/${buildType}/componentClasses.jar， 好了，最后一个这个配置的输出是在build/intermediates/multi-dex/${buildType}/components.flags，看这个文件的内容，就是这里的配置。 配置完成了，接下来就是跑Proguard输出componentClasses.jar的过程，这个过程是Proguard的任务，就不在我们流程之中了。详细了解这个过程，请参考Proguard的源码。 然后我们就可以看transform方法内的第三个方法了。 MultiDexTransform computeList123456789101112131415161718private void computeList(File _allClassesJarFile) throws ProcessException, IOException &#123; // manifest components plus immediate dependencies must be in the main dex. Set&lt;String&gt; mainDexClasses = callDx( _allClassesJarFile, variantScope.getProguardComponentsJarFile()); if (userMainDexKeepFile != null) &#123; mainDexClasses = ImmutableSet.&lt;String&gt;builder() .addAll(mainDexClasses) .addAll(Files.readLines(userMainDexKeepFile, Charsets.UTF_8)) .build(); &#125; String fileContent = Joiner.on(System.getProperty("line.separator")).join(mainDexClasses); Files.write(fileContent, mainDexListFile, Charsets.UTF_8);&#125; 这个最难的方法是callDx方法，大概讲一下这个方法的流程： 这个方法最终会调用AndroidBuilder的createMainDexList方法，此方法是调用build-tools/${buildToolsVersion}/lib/dx.jar的com.android.multidex.ClassReferenceListBuilder这个类的main方法，生成需要放入主dex的class集合； 接下来判断userMainDexKeepFile这个值，这个值的设置在哪里呢？是在bulidType中的参数multiDexKeepFile决定的。如果存在这样一个文件，就把这个文件里的内容也作为一个集合加入其中。 最后，将前面那个集合的内容写入maindexlist.txt这个文件中，这个文件位于build/intermediates/multi-dex/${buildType}/目录下。 到这里，MultiDexTransform的处理逻辑就分析完了，也就意味着，我们可以再返回createPostCompilationTasks方法继续看下去了。 接下来就是这个方法的最后一部分，dex处理部分。 123456789101112131415161718DefaultDexOptions dexOptions = DefaultDexOptions.copyOf(extension.getDexOptions());DexTransform dexTransform = new DexTransform( dexOptions, config.getBuildType().isDebuggable(), isMultiDexEnabled, isMultiDexEnabled &amp;&amp; isLegacyMultiDexMode ? variantScope.getMainDexListFile() : null, variantScope.getPreDexOutputDir(), variantScope.getGlobalScope().getAndroidBuilder(), getLogger(), variantScope.getInstantRunBuildContext(), AndroidGradleOptions.getBuildCache(variantScope.getGlobalScope().getProject()));AndroidTask&lt;TransformTask&gt; dexTask = transformManager.addTransform( tasks, variantScope, dexTransform);// need to manually make dex task depend on MultiDexTransform since there's no stream// consumption making this automaticdexTask.optionalDependsOn(tasks, multiDexClassListTask);variantScope.addColdSwapBuildTask(dexTask); 浏览了这部分源码过后，重点也是一个Transform的执行过程， 那么我们就来看看这个DexTransform DexTransform transform123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200public void transform(@NonNull TransformInvocation transformInvocation) throws TransformException, IOException, InterruptedException &#123; TransformOutputProvider outputProvider = transformInvocation.getOutputProvider(); // Gather a full list of all inputs. List&lt;JarInput&gt; jarInputs = Lists.newArrayList(); List&lt;DirectoryInput&gt; directoryInputs = Lists.newArrayList(); for (TransformInput input : transformInvocation.getInputs()) &#123; jarInputs.addAll(input.getJarInputs()); directoryInputs.addAll(input.getDirectoryInputs()); &#125; ProcessOutputHandler outputHandler = new ParsingProcessOutputHandler( new ToolOutputParser(new DexParser(), Message.Kind.ERROR, logger), new ToolOutputParser(new DexParser(), logger), androidBuilder.getErrorReporter()); outputProvider.deleteAll(); try &#123; // if only one scope or no per-scope dexing, just do a single pass that // runs dx on everything. if ((jarInputs.size() + directoryInputs.size()) == 1 || !dexOptions.getPreDexLibraries()) &#123; File outputDir = outputProvider.getContentLocation("main", getOutputTypes(), getScopes(), Format.DIRECTORY); FileUtils.mkdirs(outputDir); // first delete the output folder where the final dex file(s) will be. FileUtils.cleanOutputDir(outputDir); // gather the inputs. This mode is always non incremental, so just // gather the top level folders/jars final List&lt;File&gt; inputFiles = Stream.concat( jarInputs.stream().map(JarInput::getFile), directoryInputs.stream().map(DirectoryInput::getFile)) .collect(Collectors.toList()); androidBuilder.convertByteCode( inputFiles, outputDir, multiDex, mainDexListFile, dexOptions, getOptimize(), outputHandler); &#125; else &#123; // Figure out if we need to do a dx merge. // The ony case we don't need it is in native multi-dex mode when doing debug // builds. This saves build time at the expense of too many dex files which is fine. // FIXME dx cannot receive dex files to merge inside a folder. They have to be in a // jar. Need to fix in dx. boolean needMerge = !multiDex || mainDexListFile != null;// || !debugMode; // where we write the pre-dex depends on whether we do the merge after. // If needMerge changed from one build to another, we'll be in non incremental // mode, so we don't have to deal with changing folder in incremental mode. File perStreamDexFolder = null; if (needMerge) &#123; perStreamDexFolder = intermediateFolder; FileUtils.deletePath(perStreamDexFolder); &#125; // dex all the different streams separately, then merge later (maybe) // hash to detect duplicate jars (due to isse with library and tests) final Set&lt;String&gt; hashs = Sets.newHashSet(); // input files to output file map final Map&lt;File, File&gt; inputFiles = Maps.newHashMap(); // set of input files that are external libraries final Set&lt;File&gt; externalLibs = Sets.newHashSet(); // stuff to delete. Might be folders. final List&lt;File&gt; deletedFiles = Lists.newArrayList(); // first gather the different inputs to be dexed separately. for (DirectoryInput directoryInput : directoryInputs) &#123; File rootFolder = directoryInput.getFile(); // The incremental mode only detect file level changes. // It does not handle removed root folders. However the transform // task will add the TransformInput right after it's removed so that it // can be detected by the transform. if (!rootFolder.exists()) &#123; // if the root folder is gone we need to remove the previous // output File preDexedFile = getPreDexFile( outputProvider, needMerge, perStreamDexFolder, directoryInput); if (preDexedFile.exists()) &#123; deletedFiles.add(preDexedFile); &#125; &#125; else if (!isIncremental || !directoryInput.getChangedFiles().isEmpty()) &#123; // add the folder for re-dexing only if we're not in incremental // mode or if it contains changed files. logger.info("Changed file for %s are %s", directoryInput.getFile().getAbsolutePath(), Joiner.on(",").join(directoryInput.getChangedFiles().entrySet())); File preDexFile = getPreDexFile( outputProvider, needMerge, perStreamDexFolder, directoryInput); inputFiles.put(rootFolder, preDexFile); if (isExternalLibrary(directoryInput)) &#123; externalLibs.add(rootFolder); &#125; &#125; &#125; for (JarInput jarInput : jarInputs) &#123; switch (jarInput.getStatus()) &#123; case NOTCHANGED: // intended fall-through case CHANGED: case ADDED: &#123; File preDexFile = getPreDexFile( outputProvider, needMerge, perStreamDexFolder, jarInput); inputFiles.put(jarInput.getFile(), preDexFile); if (isExternalLibrary(jarInput)) &#123; externalLibs.add(jarInput.getFile()); &#125; break; &#125; case REMOVED: &#123; File preDexedFile = getPreDexFile( outputProvider, needMerge, perStreamDexFolder, jarInput); if (preDexedFile.exists()) &#123; deletedFiles.add(preDexedFile); &#125; break; &#125; &#125; &#125; WaitableExecutor&lt;Void&gt; executor = WaitableExecutor.useGlobalSharedThreadPool(); for (Map.Entry&lt;File, File&gt; entry : inputFiles.entrySet()) &#123; Callable&lt;Void&gt; action = new PreDexTask( entry.getKey(), entry.getValue(), hashs, outputHandler, externalLibs.contains(entry.getKey()) ? buildCache : FileCache.NO_CACHE); logger.info("Adding PreDexTask for %s : %s", entry.getKey(), action); executor.execute(action); &#125; for (final File file : deletedFiles) &#123; executor.execute(() -&gt; &#123; FileUtils.deletePath(file); return null; &#125;); &#125; executor.waitForTasksWithQuickFail(false); logger.info("Done with all dexing"); if (needMerge) &#123; File outputDir = outputProvider.getContentLocation("main", TransformManager.CONTENT_DEX, getScopes(), Format.DIRECTORY); FileUtils.mkdirs(outputDir); // first delete the output folder where the final dex file(s) will be. FileUtils.cleanOutputDir(outputDir); FileUtils.mkdirs(outputDir); // find the inputs of the dex merge. // they are the content of the intermediate folder. List&lt;File&gt; outputs = null; if (!multiDex) &#123; // content of the folder is jar files. File[] files = intermediateFolder.listFiles((file, name) -&gt; &#123; return name.endsWith(SdkConstants.DOT_JAR); &#125;); if (files != null) &#123; outputs = Arrays.asList(files); &#125; &#125; else &#123; File[] directories = intermediateFolder.listFiles(File::isDirectory); if (directories != null) &#123; outputs = Arrays.asList(directories); &#125; &#125; if (outputs == null) &#123; throw new RuntimeException("No dex files to merge!"); &#125; androidBuilder.convertByteCode( outputs, outputDir, multiDex, mainDexListFile, dexOptions, getOptimize(), outputHandler); &#125; &#125; &#125; catch (Exception e) &#123; throw new TransformException(e); &#125;&#125; 这个方法看起来很长， 因为要处理multidex和非multidex的情况。我们慢慢分析。 首先看第一个if里的代码if ((jarInputs.size() + directoryInputs.size()) == 1|| !dexOptions.getPreDexLibraries()), 这个代码中的outputDir路径为: build/intermediates/transforms/dex/folders/${outputTypes}/${scope}/main， 这也就是我们看到的最终的classes.dex这个文件的地方，这里面调用了一个很重要的方法，但是在这篇文章我们不会去跟进里面的具体实现，可以等待后续文章分析它的具体实现，就是下面这个方法。 12345678androidBuilder.convertByteCode( inputFiles, outputDir, multiDex, mainDexListFile, dexOptions, getOptimize(), outputHandler); 这个方法的作用说起来很简单，但是里面的过程很复杂，就是将字节码转化为Dalvik格式的字节码。 这样，这个if里的内容就分析完了，接下来我们看对应的else里面的内容。 else里面的代码什么时候触发呢？最简单的方式就是符合开启multidex的条件，并开启multidex。 这里的代码和if里的一样，收集最终需要转化的inputs文件，最终输出文件地址为build/intermediates/transforms/dex/folders/${outputTypes}/${scope}/main， 通过androidBuilder.convertByteCode转化这些字节码。 在这里讲一段代码，也是AS为gradle打包提速的一个方法: 生成cache 123456789101112WaitableExecutor&lt;Void&gt; executor = WaitableExecutor.useGlobalSharedThreadPool();for (Map.Entry&lt;File, File&gt; entry : inputFiles.entrySet()) &#123; Callable&lt;Void&gt; action = new PreDexTask( entry.getKey(), entry.getValue(), hashs, outputHandler, externalLibs.contains(entry.getKey()) ? buildCache : FileCache.NO_CACHE); logger.info("Adding PreDexTask for %s : %s", entry.getKey(), action); executor.execute(action);&#125; 这个地方的代码为参与最终转化的代码生成了cache，cache的具体位置在$Users/.android/build-cache/这个目录下，用包的sha1值作为目录名称，如果对应的包没改过，则sha1值不会变，就使用cache中的包。 这样我们就把DexTransform讲完了。 回到createPostCompilationTasks这个方法，讲完了DexTransform也就意味着这个方法结束了，也就是说PostCompilationTasks到这里也结束了。 那么我们就需要去理解整个打包过程最后一个方法了。]]></content>
      <tags>
        <tag>AndroidPlugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidPlugin源码解析(六)]]></title>
    <url>%2F2017%2F08%2F15%2FAndroidPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E5%85%AD)%2F</url>
    <content type="text"><![CDATA[上篇提到，我们这篇研究的是接下来三个过程, 分别是: createBuildConfigTask createApkProcessResTask createProcessJavaResTasks 接下来，我们一个一个来看 createBuildConfigTask这个task实际执行如下方法: 1234567891011121314151617181920212223242526272829303132333435// must clear the folder in case the packagename changed, otherwise,// there'll be two classes.File destinationDir = getSourceOutputDir();FileUtils.cleanOutputDir(destinationDir);BuildConfigGenerator generator = new BuildConfigGenerator( getSourceOutputDir(), getBuildConfigPackageName());// Hack (see IDEA-100046): We want to avoid reporting "condition is always true"// from the data flow inspection, so use a non-constant value. However, that defeats// the purpose of this flag (when not in debug mode, if (BuildConfig.DEBUG &amp;&amp; ...) will// be completely removed by the compiler), so as a hack we do it only for the case// where debug is true, which is the most likely scenario while the user is looking// at source code.//map.put(PH_DEBUG, Boolean.toString(mDebug));generator.addField("boolean", "DEBUG", isDebuggable() ? "Boolean.parseBoolean(\"true\")" : "false") .addField("String", "APPLICATION_ID", '"' + getAppPackageName() + '"') .addField("String", "BUILD_TYPE", '"' + getBuildTypeName() + '"') .addField("String", "FLAVOR", '"' + getFlavorName() + '"') .addField("int", "VERSION_CODE", Integer.toString(getVersionCode())) .addField("String", "VERSION_NAME", '"' + Strings.nullToEmpty(getVersionName()) + '"') .addItems(getItems());List&lt;String&gt; flavors = getFlavorNamesWithDimensionNames();int count = flavors.size();if (count &gt; 1) &#123; for (int i = 0; i &lt; count; i += 2) &#123; generator.addField( "String", "FLAVOR_" + flavors.get(i + 1), '"' + flavors.get(i) + '"'); &#125;&#125;generator.generate(); 这个方法的结果是build/generated/source/${buildTypes}/${packageName}目录下生成BuildConfig.java文件。这个我相信大家都很熟悉了。 我们可以看到, 即使我们在build.gradle中不填任何buildConfigField，也会生成这样一个文件，这个文件里的内容一定有DEBUG, APPLICATION_ID, BUILD_TYPE, FLAVOR, VERSION_CODE, VERSION_NAME字段。 DEBUG这个字段是由isDebuggable这个方法决定的。也就是我们平时会在debug{}或者release{}中写的debuggable true。 getItems不用说，就是把我们用buildConfigField声明的参数转化为Field。 最后的generate方法就不看具体实现了，就是按照Java文件格式，将这些内容写入BuildConfig.java文件中。 好了，这个BuildConfigTask到这里就分析完成了。 我们来看下一个方法 createApkProcessResTask1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// we have to clean the source folder output in case the package name changed.File srcOut = getSourceOutputDir();if (srcOut != null) &#123; FileUtils.cleanOutputDir(srcOut);&#125;@Nullable// 对于application来说，这个文件是`build/intermediates/res/resources-$&#123;buildType&#125;.ap_// 对于library来说，为null// 这个是aapt执行完成后输出的压缩文件，里面包含了所有资源文件，和最终的`resources.arsc`File resOutBaseNameFile = getPackageOutputFile();File manifestFileToPackage = getManifestFile();AndroidBuilder builder = getBuilder();MergingLog mergingLog = new MergingLog(getMergeBlameLogFolder());ProcessOutputHandler processOutputHandler = new ParsingProcessOutputHandler( new ToolOutputParser(new AaptOutputParser(), getILogger()), // 处理执行完的log new MergingLogRewriter(mergingLog, builder.getErrorReporter())); // merge后的log位于 // build/intermediates/blame/res/$&#123;buildConfig&#125;/// 生成对应的Aapt对象Aapt aapt = AaptGradleFactory.make( getBuilder(), processOutputHandler, true, true, variantScope.getGlobalScope().getProject(), variantScope.getVariantConfiguration().getType(), FileUtils.mkdirs(new File(getIncrementalFolder(), "aapt-temp")), aaptOptions.getCruncherProcesses());// 给Aapt设置参数AaptPackageConfig.Builder config = new AaptPackageConfig.Builder() .setManifestFile(manifestFileToPackage) .setOptions(getAaptOptions()) .setResourceDir(getResDir()) .setLibraries(getLibraries()) .setCustomPackageForR(getPackageForR()) .setSymbolOutputDir(getTextSymbolOutputDir()) .setSourceOutputDir(srcOut) .setResourceOutputApk(resOutBaseNameFile) .setProguardOutputFile(getProguardOutputFile()) .setMainDexListProguardOutputFile(getMainDexListProguardOutputFile()) .setVariantType(getType()) .setDebuggable(getDebuggable()) .setPseudoLocalize(getPseudoLocalesEnabled()) .setResourceConfigs(getResourceConfigs()) .setSplits(getSplits()) .setPreferredDensity(getPreferredDensity());builder.processResources(aapt, config, getEnforceUniquePackageName());if (resOutBaseNameFile != null &amp;&amp; LOG.isInfoEnabled()) &#123; LOG.info("Aapt output file &#123;&#125;", resOutBaseNameFile.getAbsolutePath());&#125; 大概看一下，这里其实就是执行aapt的过程。 大家应该没有手动执行过aapt的命令，那么跟着我一起看一下aapt命令是如何执行的。 这里和前面提到的一样，只分析Aapt1，至于Aapt2，在这个版本还未成熟，还不能使用。 那么，我们来看builder.processResources(aapt, config, getEnforceUniquePackageName());这个方法: 123456AaptPackageConfig aaptConfig = aaptConfigBuilder.build();try &#123; aapt.link(aaptConfig).get();&#125; catch (Exception e) &#123; throw new ProcessException("Failed to execute aapt", e);&#125; 这个方法我没有贴完，先看aapt.link(aaptConfig)方法，然后再继续往下看 AbstractAapt link12345public ListenableFuture&lt;Void&gt; link(@NonNull AaptPackageConfig config) throws AaptException &#123; validatePackageConfig(config); // 做一些校验 return makeValidatedPackage(config);&#125; 这个方法很简单，就两个方法，validatePackageConfig(config);这个方法就是做一些校验，这里就不关心了。 makeValidatedPackage(config);其实就是执行aapt命令。 那么如何执行命令呢，就是由其中的ProcessInfoBuilder builder = makePackageProcessBuilder(config);方法创建的，这里其实就是构成了执行aapt的命令，这个命令是: 1aapt package -v -f --no-crunch -i $&#123;android.jarPath&#125; -M $&#123;ManifestPath&#125; -S $&#123;resourcesDir&#125; -m -J $&#123;sourceOutputDir&#125; -F $&#123;resourceOutputApkPath&#125; -G $&#123;proguardOutputPath&#125; -D $&#123;mainDexClassListFilePath&#125; --debug-mode -0 apk --output-text-symbols $&#123;symbolOutputDirPath&#125; 如果是Android Library,则会添加--non-constant-id选项，看到这个选项应该能了解为何Library的R文件不是public static final了。 如果buildTools &gt;= 23，则会添加--no-version-vectors。 这个时候，apk的压缩等级为0。 我们关注一下aapt命令中的各个路径: android.jarPath = ${sdk}/platforms/android-${compileSdk}/android.jar ManifestPath: library中manifestFile路径为:build/intermediates/manifests/aapt/${buildConfig}/AndroidManifest.xml app中manifestFile路径为: build/intermediates/manifests/full/${buildConfig}/AndroidManifest.xml resourcesDir = build/intermediates/res/merged/${buildConfig}/ sourceOutputDir = build/generated/source/r/${buildTypes}/${packageName} resourceOutputApkPath 对于application来说，这个文件是`build/intermediates/res/resources-${buildType}.ap_ 对于library来说，为null proguardOutputPath = build/intermediates/proguard-rules/${buildType}/aapt_rules.txt mainDexClassListFilePath = build/intermediates/multi-dex/${buildTypes}/manifest_keep.txt symbolOutputDirPath = build/intermediates/symbols/${buildTypes} 这里有两个文件夹的生成是有条件的，首先当然是proguardOutputPath，只有设置了minifyEnabled true，才会生成。 第二，是mainDexClassListFilePath, 只有minSdk &lt; 21 &amp;&amp; buildTools &gt; 24.0.0才会生成。 这样，aapt这个命令操作了哪些参数就很明显了，至于aapt对这些参数是如何处理的，这就不是我这篇博客的内容了，想了解这方面的内容，请到老罗的博客继续了解。 好了，aapt.link方法分析完了，我们继续看builder.processResources(aapt, config, getEnforceUniquePackageName());这个方法剩下的内容， 剩下的代码结果就是build/generated/source/r/${buildTypes}/${packageName}目录下的各个R.java文件，根据最终结果反推这些代码的含义还是很容易的，所以这里就不仔细分析了。 这样，ProcessResTask就分析完毕了。 我们来看下一个方法 createProcessJavaResTasks123456789101112131415161718192021222324252627282930public void createProcessJavaResTasks( @NonNull TaskFactory tasks, @NonNull VariantScope variantScope) &#123; TransformManager transformManager = variantScope.getTransformManager(); // now copy the source folders java resources into the temporary location, mainly to // maintain the PluginDsl COPY semantics. AndroidTask&lt;Sync&gt; processJavaResourcesTask = androidTasks.create(tasks, new ProcessJavaResConfigAction(variantScope)); variantScope.setProcessJavaResourcesTask(processJavaResourcesTask); // create the stream generated from this task variantScope.getTransformManager().addStream(OriginalStream.builder() .addContentType(DefaultContentType.RESOURCES) .addScope(Scope.PROJECT) .setFolder(variantScope.getSourceFoldersJavaResDestinationDir()) .setDependency(processJavaResourcesTask.getName()) .build()); // compute the scopes that need to be merged. Set&lt;Scope&gt; mergeScopes = getResMergingScopes(variantScope); // Create the merge transform MergeJavaResourcesTransform mergeTransform = new MergeJavaResourcesTransform( variantScope.getGlobalScope().getExtension().getPackagingOptions(), mergeScopes, DefaultContentType.RESOURCES, "mergeJavaRes"); variantScope.setMergeJavaResourcesTask( transformManager.addTransform(tasks, variantScope, mergeTransform));&#125; 这个方法的作用就像名字说的，处理Java的资源，通常我们不会遇到Java的资源。 但是有几种情况会出现Java资源： 比如，使用RxJava的时候，使用okhttp的时候，这些库都带着Java的资源；还有Java Doc， LICENSE之类的资源。 这里的资源根据你在packageOptions{}中设置的选项，最后merge成一个jar包或者一个文件夹，文件夹的情况我没见到过，这里就不分析了。 Jar包的路径为:build/intermediates/transforms/mergeJavaRes/${buildType}/jars/${TypeValue}/${ScopesValue}/main.jar 至于TypeValue和ScopesValue，这其实是QualifiedContent内部的DefaultContentType和Scope两个枚举类的value值。 这里就是Transform Api的一些用法，看这个代码可以学习Transform Api，对于写Gradle plugin很有用。 好了，这里的处理过程不是重点，我们了解生成什么就可以了，所以，ProcessJavaResTasks到这里就结束了。]]></content>
      <tags>
        <tag>AndroidPlugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidPlugin源码解析(五)]]></title>
    <url>%2F2017%2F07%2F20%2FAndroidPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%BA%94)%2F</url>
    <content type="text"><![CDATA[上篇提到，我们这篇研究的是如下过程, 分别是: createGenerateResValuesTask createMergeResourcesTask createMergeAssetsTask 接下来，我们一个一个来看 createGenerateResValuesTask这个task实际执行下面的方法： 123456789101112// 该folder名字为resValuesFile folder = getResOutputDir();List&lt;Object&gt; resolvedItems = getItems();if (resolvedItems.isEmpty()) &#123; FileUtils.cleanOutputDir(folder);&#125; else &#123; ResValueGenerator generator = new ResValueGenerator(folder); generator.addItems(getItems()); generator.generate();&#125; 这个任务的代码看起来很简单，主要就是else内的内容: 我们来看下generate方法: ResValueGenerator generate123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public void generate() throws IOException, ParserConfigurationException &#123; File pkgFolder = getFolderPath(); if (!pkgFolder.isDirectory()) &#123; if (!pkgFolder.mkdirs()) &#123; throw new RuntimeException("Failed to create " + pkgFolder.getAbsolutePath()); &#125; &#125; File resFile = new File(pkgFolder, "generated.xml"); DocumentBuilderFactory factory = DocumentBuilderFactory.newInstance(); factory.setNamespaceAware(true); factory.setValidating(false); factory.setIgnoringComments(true); DocumentBuilder builder; builder = factory.newDocumentBuilder(); Document document = builder.newDocument(); Node rootNode = document.createElement(TAG_RESOURCES); document.appendChild(rootNode); rootNode.appendChild(document.createTextNode("\n")); rootNode.appendChild(document.createComment("Automatically generated file. DO NOT MODIFY")); rootNode.appendChild(document.createTextNode("\n\n")); for (Object item : mItems) &#123; if (item instanceof ClassField) &#123; ClassField field = (ClassField)item; ResourceType type = ResourceType.getEnum(field.getType()); boolean hasResourceTag = (type != null &amp;&amp; RESOURCES_WITH_TAGS.contains(type)); Node itemNode = document.createElement(hasResourceTag ? field.getType() : TAG_ITEM); Attr nameAttr = document.createAttribute(ATTR_NAME); nameAttr.setValue(field.getName()); itemNode.getAttributes().setNamedItem(nameAttr); if (!hasResourceTag) &#123; Attr typeAttr = document.createAttribute(ATTR_TYPE); typeAttr.setValue(field.getType()); itemNode.getAttributes().setNamedItem(typeAttr); &#125; // 加入 translatable="false" if (type == ResourceType.STRING) &#123; Attr translatable = document.createAttribute(ATTR_TRANSLATABLE); translatable.setValue(VALUE_FALSE); itemNode.getAttributes().setNamedItem(translatable); &#125; if (!field.getValue().isEmpty()) &#123; itemNode.appendChild(document.createTextNode(field.getValue())); &#125; rootNode.appendChild(itemNode); &#125; else if (item instanceof String) &#123; rootNode.appendChild(document.createTextNode("\n")); rootNode.appendChild(document.createComment((String) item)); rootNode.appendChild(document.createTextNode("\n")); &#125; &#125; String content; try &#123; content = XmlPrettyPrinter.prettyPrint(document, true); &#125; catch (Throwable t) &#123; content = XmlUtils.toXml(document); &#125; Files.write(content, resFile, Charsets.UTF_8);&#125; 这里就是在gradle的buildType中定义的resValue，最终会在build/generated/res/resValues/${buildTypes}/values目录下生成generated.xml文件， 这样，在buildType中定义的resValue就可以在代码中使用了。我在这里通常就是定义一些string，没用过其他resValue类型，所以这里就不详细分析了。 通过generated.xml文件来对应这个代码，理解起来很容易。 createMergeResourcesTask这个task实际执行下面的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041// 预处理VectorDrawable，如果没有，则忽略ResourcePreprocessor preprocessor = getPreprocessor();// this is full run, clean the previous outputFile destinationDir = getOutputDir();FileUtils.cleanOutputDir(destinationDir);List&lt;ResourceSet&gt; resourceSets = getConfiguredResourceSets(preprocessor);// create a new merger and populate it with the sets.ResourceMerger merger = new ResourceMerger(minSdk);// 这个resourceSets的来源是VariantConfiguration的getResourceSets方法// 这个方法添加资源的顺序，决定了最后merge的时候保留的资源for (ResourceSet resourceSet : resourceSets) &#123; resourceSet.loadFromFiles(getILogger()); merger.addDataSet(resourceSet);&#125;// get the merged set and write it down.// 当你使用的build tools版本是24.0.0 rc2的之后，可以在gradle.properties中设置android.enableAapt2=true属性使用aapt2// 但是，不建议你在gradle-plugin:3.0.0-beta1之前版本使用，会有各种问题，那么我们这里关注Aapt1，而不是2版本。// 当前版本的Aapt2的实现中存在各种Fix的注释Aapt aapt = AaptGradleFactory.make( getBuilder(), getCrunchPng(), getProcess9Patch(), variantScope, getAaptTempDir());MergedResourceWriter writer = new MergedResourceWriter( destinationDir, getPublicFile(), getBlameLogFolder(), preprocessor, aapt::compile, // 处理.9png getIncrementalFolder());merger.mergeData(writer, false /*doCleanUp*/);// No exception? Write the known state.merger.writeBlobTo(getIncrementalFolder(), writer, false); 这里主要解释两个方法，即mergedResourceWriter的两个方法mergeDta和writeBlobTo 剩下的看代码中的注释即可。 MergedResourceWriter mergeDta123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133public void mergeData(@NonNull MergeConsumer&lt;I&gt; consumer, boolean doCleanUp) throws MergingException &#123; // 对于MergeResources这个consumer来说，这就是一个赋值操作 consumer.start(mFactory); try &#123; // get all the items keys. Set&lt;String&gt; dataItemKeys = Sets.newHashSet(); for (S dataSet : mDataSets) &#123; // quick check on duplicates in the resource set. dataSet.checkItems(); ListMultimap&lt;String, I&gt; map = dataSet.getDataMap(); dataItemKeys.addAll(map.keySet()); &#125; // loop on all the data items. for (String dataItemKey : dataItemKeys) &#123; // 对于Resources来说，如果存在declare-styleable则需要merge if (requiresMerge(dataItemKey)) &#123; // get all the available items, from the lower priority, to the higher // priority List&lt;I&gt; items = Lists.newArrayListWithExpectedSize(mDataSets.size()); for (S dataSet : mDataSets) &#123; // look for the resource key in the set ListMultimap&lt;String, I&gt; itemMap = dataSet.getDataMap(); List&lt;I&gt; setItems = itemMap.get(dataItemKey); items.addAll(setItems); &#125; mergeItems(dataItemKey, items, consumer); continue; &#125; // for each items, look in the data sets, starting from the end of the list. I previouslyWritten = null; I toWrite = null; /* * We are looking for what to write/delete: the last non deleted item, and the * previously written one. */ boolean foundIgnoredItem = false; setLoop: for (int i = mDataSets.size() - 1 ; i &gt;= 0 ; i--) &#123; S dataSet = mDataSets.get(i); // look for the resource key in the set ListMultimap&lt;String, I&gt; itemMap = dataSet.getDataMap(); List&lt;I&gt; items = itemMap.get(dataItemKey); if (items.isEmpty()) &#123; continue; &#125; // The list can contain at max 2 items. One touched and one deleted. // More than one deleted means there was more than one which isn't possible // More than one touched means there is more than one and this isn't possible. for (int ii = items.size() - 1 ; ii &gt;= 0 ; ii--) &#123; I item = items.get(ii); if (consumer.ignoreItemInMerge(item)) &#123; foundIgnoredItem = true; continue; &#125; if (item.isWritten()) &#123; assert previouslyWritten == null; previouslyWritten = item; &#125; if (toWrite == null &amp;&amp; !item.isRemoved()) &#123; toWrite = item; &#125; if (toWrite != null &amp;&amp; previouslyWritten != null) &#123; break setLoop; &#125; &#125; &#125; // done searching, we should at least have something, unless we only // found items that are not meant to be written (attr inside declare styleable) assert foundIgnoredItem || previouslyWritten != null || toWrite != null; if (toWrite != null &amp;&amp; !filterAccept(toWrite)) &#123; toWrite = null; &#125; //noinspection ConstantConditions if (previouslyWritten == null &amp;&amp; toWrite == null) &#123; continue; &#125; // now need to handle, the type of each (single res file, multi res file), whether // they are the same object or not, whether the previously written object was // deleted. if (toWrite == null) &#123; // nothing to write? delete only then. assert previouslyWritten.isRemoved(); consumer.removeItem(previouslyWritten, null /*replacedBy*/); &#125; else if (previouslyWritten == null || previouslyWritten == toWrite) &#123; // easy one: new or updated res consumer.addItem(toWrite); &#125; else &#123; // replacement of a resource by another. // force write the new value toWrite.setTouched(); consumer.addItem(toWrite); // and remove the old one consumer.removeItem(previouslyWritten, toWrite); &#125; &#125; &#125; finally &#123; consumer.end(); &#125; if (doCleanUp) &#123; // reset all states. We can't just reset the toWrite and previouslyWritten objects // since overlayed items might have been touched as well. // Should also clean (remove) objects that are removed. postMergeCleanUp(); &#125;&#125; 虽然看起来代码有点复杂，但是完成的任务挺清晰的，就是完成ResourceItem对象的add和merge操作，然后将ResourceItem对象添加到consumer内。 在consumer.end()的时候把这些ResourceItem对象写入/build/intermediates/merge${BuildType}Resources/下面的所有文件，也就是我们在工程中定义的values文件夹之内的那些文件。然后，将cache和真正的value一一对应，并写入compile-file-map.properties文件中。 接下来看这个任务中最后一个方法 MergedResourceWriter writeBlobTo123456789101112131415161718192021222324252627282930313233343536373839public void writeBlobTo(@NonNull File blobRootFolder, @NonNull MergeConsumer&lt;I&gt; consumer, boolean includeTimestamps) throws MergingException &#123; // write "compact" blob DocumentBuilder builder; builder = mFactory.newDocumentBuilder(); Document document = builder.newDocument(); Node rootNode = document.createElement(NODE_MERGER); // add the version code. NodeUtils.addAttribute(document, rootNode, null, ATTR_VERSION, MERGE_BLOB_VERSION); document.appendChild(rootNode); for (S dataSet : mDataSets) &#123; Node dataSetNode = document.createElement(NODE_DATA_SET); rootNode.appendChild(dataSetNode); dataSet.appendToXml(dataSetNode, document, consumer, includeTimestamps); &#125; // write merged items // 创建&lt;mergedItems&gt;&lt;configuration&gt;&lt;xxx&gt;&lt;/xxx&gt;&lt;/configuration&gt;&lt;/mergedItems&gt; // 这里是说明merge之后使用哪个资源文件的地方，如果发现merge之后图片不对，来看一下 writeAdditionalData(document, rootNode); String content = XmlUtils.toXml(document); try &#123; createDir(blobRootFolder); &#125; catch (IOException ioe) &#123; throw MergingException.wrapException(ioe).withFile(blobRootFolder).build(); &#125; File file = new File(blobRootFolder, FN_MERGER_XML); try &#123; Files.write(content, file, Charsets.UTF_8); &#125; catch (IOException ioe) &#123; throw MergingException.wrapException(ioe).withFile(file).build(); &#125;&#125; 这个方法就是将dataSet转化成一个xml文件，这个xml文件路径是build/intermediates/incremental/merge${buildTypes}Resources/merger.xml 最重要的两个方法是： dataSet.appendToXml(dataSetNode, document, consumer, includeTimestamps);和writeAdditionalData(document, rootNode); 这里就不继续看内部的代码了，简单说一下这两个方法的作用， dataSet.appendToXml(dataSetNode, document, consumer, includeTimestamps);方法的作用是: 按顺序创建&lt;dataSet&gt;&lt;source&gt;&lt;file&gt;&lt;xxx&gt;&lt;/xxx&gt;&lt;/file&gt;&lt;/source&gt;&lt;/dataSet&gt;这样的xml，可以在merger.xml中观察到。 writeAdditionalData(document, rootNode);方法的作用是: 创建&lt;mergedItems&gt;&lt;configuration&gt;&lt;xxx&gt;&lt;/xxx&gt;&lt;/configuration&gt;&lt;/mergedItems&gt;这样的xml 这里是说明merge之后使用哪个资源文件的地方，可以在merger.xml中观察到。 这样，整MergeResourcesTask的过程就讲完了 createMergeAssetsTask这个task实际执行下面的方法： 123456789101112131415161718192021222324// this is full run, clean the previous outputFile destinationDir = getOutputDir();FileUtils.cleanOutputDir(destinationDir);List&lt;AssetSet&gt; assetSets = getInputDirectorySets();// create a new merger and populate it with the sets.AssetMerger merger = new AssetMerger();// AssetSet 和ResourceSet一样，都是DataSet的子类// 所以，做的事和上面的createMergeResourcesTask方法中类似，不过一个是resourceSet对象，一个是AssetSet对象for (AssetSet assetSet : assetSets) &#123; // set needs to be loaded. assetSet.loadFromFiles(getILogger()); merger.addDataSet(assetSet);&#125;// get the merged set and write it down.MergedAssetWriter writer = new MergedAssetWriter(destinationDir);merger.mergeData(writer, false /*doCleanUp*/);// No exception? Write the known state.merger.writeBlobTo(getIncrementalFolder(), writer, false); 大概浏览一下，会不会觉得这个方法和createMergeResourcesTask中的方法很相似。那么，理解起来应该就相对容易一些了。同样的代码，不同子类的实现。 先讲一下mergeData，对于这个方法来说，MergedAssetWriter中requiresMerge直接返回false，也就是不能merge。MergedAssetWriter中end方法什么也不做。 这里的addItem方法需要讲解一下，否则，看其他库中出现gzip包就不会太理解，比如okhttp这个库。 这里，会直接把gzip压缩过的文件还原为原始文件，同时会将该文件重命名为去掉.gz的文件名 // e.g. foo.txt.gz to foo.txt 至于dataSet.appendToXml(dataSetNode, document, consumer, includeTimestamps);方法，作用和上面一样，在不同的文件夹下生成而已。 writeAdditionalData()方法就是啥也不做。 这样，整MergeAssetsTask的过程就讲完了。下一篇，我们继续createBuildConfigTask, createApkProcessResTask和createProcessJavaResTasks的过程。 如果大家有不懂，欢迎通过留言和邮件进行交流。]]></content>
      <tags>
        <tag>AndroidPlugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidPlugin源码解析(四)]]></title>
    <url>%2F2017%2F06%2F30%2FAndroidPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E5%9B%9B)%2F</url>
    <content type="text"><![CDATA[接下来几篇就来解析上篇提到的代码。 一个一个Task来看 createAnchorTasks这个方法创建的Tasks就如名字所示，是Anchor Tasks（即所谓的锚点任务）。在这里不做仔细的解析。 具体就是创建一些preXXXBuild任务，generateXXXResources/Assets/Sources任务以及compileXXXSources任务。 createCheckManifestTask主要作用就是检测Manifest是否存在在指定路径。在这里也不做仔细的解析。 createDependencyStreams主要作用是将所有依赖的Jar包合成，通过TransformManager来完成此任务。 这里提一句，TransformManager是新加入的Api，让我们可以开发Gradle插件来Hook Android自身的打包过程。 Tinker之类的库都是通过这个Api来Hook打包过程，插入自己的代码逻辑的。 createMergeAppManifestsTask精简代码如下： 1234567891011121314151617181920212223public void createMergeAppManifestsTask( @NonNull TaskFactory tasks, @NonNull VariantScope variantScope) &#123; ApplicationVariantData appVariantData = (ApplicationVariantData) variantScope.getVariantData(); Set&lt;String&gt; screenSizes = appVariantData.getCompatibleScreens(); // loop on all outputs. The only difference will be the name of the task, and location // of the generated manifest for (final BaseVariantOutputData vod : appVariantData.getOutputs()) &#123; VariantOutputScope scope = vod.getScope(); List&lt;ManifestMerger2.Invoker.Feature&gt; optionalFeatures = getIncrementalMode( variantScope.getVariantConfiguration()) != IncrementalMode.NONE ? ImmutableList.of(ManifestMerger2.Invoker.Feature.INSTANT_RUN_REPLACEMENT) : ImmutableList.of(); AndroidTask&lt;? extends ManifestProcessorTask&gt; processManifestTask = androidTasks.create(tasks, getMergeManifestConfig(scope, optionalFeatures)); scope.setManifestProcessorTask(processManifestTask); // 将Manifest放入对应的output文件夹内 // library放入build/intermediates/bundles // app放入build/intermediates/manifests addManifestArtifact(tasks, scope.getVariantScope().getVariantData()); &#125;&#125; 这里执行的主要代码是两种Task，就是ManifestProcessorTask的子类，这个我们来仔细跟进。 两个子类分别是MergeManifests和ProcessManifest，后者是针对Library打包的时候调用的， 而且这两个子类在我们打包过程中，执行的代码都是AndroidBuilder里面的mergeManifestsForApplication方法，只不过参数不一样。 所以直接解析mergeManifestsForApplication 方法了 AndroidBuilder mergeManifestsForApplication12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public void mergeManifestsForApplication( @NonNull File mainManifest, @NonNull List&lt;File&gt; manifestOverlays, @NonNull List&lt;? extends AndroidLibrary&gt; libraries, String packageOverride, int versionCode, String versionName, @Nullable String minSdkVersion, @Nullable String targetSdkVersion, @Nullable Integer maxSdkVersion, @NonNull String outManifestLocation, @Nullable String outAaptSafeManifestLocation, @Nullable String outInstantRunManifestLocation, ManifestMerger2.MergeType mergeType, Map&lt;String, Object&gt; placeHolders, @NonNull List&lt;Invoker.Feature&gt; optionalFeatures, @Nullable File reportFile) &#123; Invoker manifestMergerInvoker = ManifestMerger2.newMerger(mainManifest, mLogger, mergeType) .setPlaceHolderValues(placeHolders) .addFlavorAndBuildTypeManifests( manifestOverlays.toArray(new File[manifestOverlays.size()])) .addBundleManifests(libraries) .withFeatures(optionalFeatures.toArray( new Invoker.Feature[optionalFeatures.size()])) .setMergeReportFile(reportFile); if (mergeType == ManifestMerger2.MergeType.APPLICATION) &#123; // 如果是Application，则加入移除tools声明的Features manifestMergerInvoker.withFeatures(Invoker.Feature.REMOVE_TOOLS_DECLARATIONS); &#125; //noinspection VariableNotUsedInsideIf if (outAaptSafeManifestLocation != null) &#123; // 这个代表是Library， Application的时候该值为null // 这个Feature的含义是Encode unresolved placeholders to be AAPT friendly. // 也就是说某些placeHolders可能没有正确的赋值，留给Application赋值 manifestMergerInvoker.withFeatures(Invoker.Feature.MAKE_AAPT_SAFE); &#125; // 这个就是将packageName versionCode versionName minSdkVersion targetSdkVersion maxSdkVersion设置进去 setInjectableValues(manifestMergerInvoker, packageOverride, versionCode, versionName, minSdkVersion, targetSdkVersion, maxSdkVersion); MergingReport mergingReport = manifestMergerInvoker.merge(); mLogger.info("Merging result:" + mergingReport.getResult()); switch (mergingReport.getResult()) &#123; case WARNING: mergingReport.log(mLogger); // fall through since these are just warnings. case SUCCESS: String xmlDocument = mergingReport.getMergedDocument( MergingReport.MergedManifestKind.MERGED); String annotatedDocument = mergingReport.getMergedDocument( MergingReport.MergedManifestKind.BLAME); if (annotatedDocument != null) &#123; mLogger.verbose(annotatedDocument); &#125; save(xmlDocument, new File(outManifestLocation)); mLogger.info("Merged manifest saved to " + outManifestLocation); if (outAaptSafeManifestLocation != null) &#123; save(mergingReport.getMergedDocument(MergingReport.MergedManifestKind.AAPT_SAFE), new File(outAaptSafeManifestLocation)); &#125; break; case ERROR: mergingReport.log(mLogger); throw new RuntimeException(mergingReport.getReportString()); default: throw new RuntimeException("Unhandled result type : " + mergingReport.getResult()); &#125;&#125; 我们可以看出，初始化了manifestMergerInvoker对象,在初始化的过程中，做了如下操作： 将placeHolder的值设置进来 将BuildType和ProductFlavor对应的Manifests存进来了 将非Provided的library加入进来，代码如下。所以Provided的库不会打包到最终apk中。 12345for (AndroidBundle library : libraries) &#123; if (!library.isProvided()) &#123; mLibraryFilesBuilder.add(Pair.of(library.getName(), library.getManifest())); &#125;&#125; 接下来是manifestMergerInvoker.merge()，真正执行merge的地方，代码如下: ManifestMerger2.Invoker merge()12345678910111213141516171819202122232425262728293031public MergingReport merge() throws MergeFailureException &#123; // provide some free placeholders values. ImmutableMap&lt;ManifestSystemProperty, Object&gt; systemProperties = mSystemProperties.build(); if (systemProperties.containsKey(ManifestSystemProperty.PACKAGE)) &#123; // if the package is provided, make it available for placeholder replacement. // 将PackageName放入待替换Map中 mPlaceholders.put(PACKAGE_NAME, systemProperties.get(ManifestSystemProperty.PACKAGE)); // as well as applicationId since package system property overrides everything // but not when output is a library since only the final (application) // application Id should be used to replace libraries "applicationId" placeholders. if (mMergeType != MergeType.LIBRARY) &#123; // 如果不是Library，则将ApplicationID放入待替换Map中 mPlaceholders.put(APPLICATION_ID, systemProperties.get(ManifestSystemProperty.PACKAGE)); &#125; &#125; FileStreamProvider fileStreamProvider = mFileStreamProvider != null ? mFileStreamProvider : new FileStreamProvider(); ManifestMerger2 manifestMerger = new ManifestMerger2( mLogger, mMainManifestFile, mLibraryFilesBuilder.build(), mFlavorsAndBuildTypeFiles.build(), mFeaturesBuilder.build(), mPlaceholders.build(), new MapBasedKeyBasedValueResolver&lt;ManifestSystemProperty&gt;(systemProperties), mMergeType, Optional.fromNullable(mReportFile), fileStreamProvider); return manifestMerger.merge();&#125; 可以看到，这个merge方法主要就是调用ManifestMerger2的merge方法，剩下的看代码中的注释即可，ManifestMerger2的merge方法代码如下: ManifestMerger2 merge()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113private MergingReport merge() throws MergeFailureException &#123; // initiate a new merging report MergingReport.Builder mergingReportBuilder = new MergingReport.Builder(mLogger); SelectorResolver selectors = new SelectorResolver(); // load all the libraries xml files up front to have a list of all possible node:selector // values. List&lt;LoadedManifestInfo&gt; loadedLibraryDocuments = loadLibraries(selectors, mergingReportBuilder); // load the main manifest file to do some checking along the way. LoadedManifestInfo loadedMainManifestInfo = load( new ManifestInfo( mManifestFile.getName(), mManifestFile, XmlDocument.Type.MAIN, Optional.&lt;String&gt;absent() /* mainManifestPackageName */), selectors, mergingReportBuilder); // first do we have a package declaration in the main manifest ? Optional&lt;XmlAttribute&gt; mainPackageAttribute = loadedMainManifestInfo.getXmlDocument().getPackage(); // perform system property injection performSystemPropertiesInjection(mergingReportBuilder, loadedMainManifestInfo.getXmlDocument()); // force the re-parsing of the xml as elements may have been added through system // property injection. // 因为前面将mergingReportBuilder内的元素加入到loadedMainManifestInfo内了， // 所以需要重新解析一遍 loadedMainManifestInfo = new LoadedManifestInfo(loadedMainManifestInfo, loadedMainManifestInfo.getOriginalPackageName(), loadedMainManifestInfo.getXmlDocument().reparse()); // invariant : xmlDocumentOptional holds the higher priority document and we try to // merge in lower priority documents. Optional&lt;XmlDocument&gt; xmlDocumentOptional = Optional.absent(); for (File inputFile : mFlavorsAndBuildTypeFiles) &#123; mLogger.info("Merging flavors and build manifest %s \n", inputFile.getPath()); LoadedManifestInfo overlayDocument = load( new ManifestInfo(null, inputFile, XmlDocument.Type.OVERLAY, Optional.of(mainPackageAttribute.get().getValue())), selectors, mergingReportBuilder); // check package declaration. Optional&lt;XmlAttribute&gt; packageAttribute = overlayDocument.getXmlDocument().getPackage(); overlayDocument.getXmlDocument().getRootNode().getXml().setAttribute("package", mainPackageAttribute.get().getValue()); xmlDocumentOptional = merge(xmlDocumentOptional, overlayDocument, mergingReportBuilder); if (!xmlDocumentOptional.isPresent()) &#123; return mergingReportBuilder.build(); &#125; &#125; mLogger.info("Merging main manifest %s\n", mManifestFile.getPath()); xmlDocumentOptional = merge(xmlDocumentOptional, loadedMainManifestInfo, mergingReportBuilder); if (!xmlDocumentOptional.isPresent()) &#123; return mergingReportBuilder.build(); &#125; // force main manifest package into resulting merged file when creating a library manifest. if (mMergeType == MergeType.LIBRARY) &#123; // extract the package name... String mainManifestPackageName = loadedMainManifestInfo.getXmlDocument().getRootNode() .getXml().getAttribute("package"); // save it in the selector instance. if (!Strings.isNullOrEmpty(mainManifestPackageName)) &#123; xmlDocumentOptional.get().getRootNode().getXml() .setAttribute("package", mainManifestPackageName); &#125; &#125; for (LoadedManifestInfo libraryDocument : loadedLibraryDocuments) &#123; mLogger.info("Merging library manifest " + libraryDocument.getLocation()); xmlDocumentOptional = merge( xmlDocumentOptional, libraryDocument, mergingReportBuilder); if (!xmlDocumentOptional.isPresent()) &#123; return mergingReportBuilder.build(); &#125; &#125; // done with proper merging phase, now we need to trim unwanted elements, placeholder // substitution and system properties injection. ElementsTrimmer.trim(xmlDocumentOptional.get(), mergingReportBuilder); if (mergingReportBuilder.hasErrors()) &#123; return mergingReportBuilder.build(); &#125; if (!mOptionalFeatures.contains(Invoker.Feature.NO_PLACEHOLDER_REPLACEMENT)) &#123; // do one last placeholder substitution, this is useful as we don't stop the build // when a library failed a placeholder substitution, but the element might have // been overridden so the problem was transient. However, with the final document // ready, all placeholders values must have been provided. performPlaceHolderSubstitution(loadedMainManifestInfo, xmlDocumentOptional.get(), mergingReportBuilder); if (mergingReportBuilder.hasErrors()) &#123; return mergingReportBuilder.build(); &#125; &#125; // perform system property injection. // 进行比如PACKAGE, VERSION_CODE, VERSION_NAME, MIN_SDK_VERSION之类的系统属性注入 performSystemPropertiesInjection(mergingReportBuilder, xmlDocumentOptional.get()); XmlDocument finalMergedDocument = xmlDocumentOptional.get(); // 做一些验证，排序的工作 PostValidator.validate(finalMergedDocument, mergingReportBuilder); if (mergingReportBuilder.hasErrors()) &#123; finalMergedDocument.getRootNode().addMessage(mergingReportBuilder, MergingReport.Record.Severity.WARNING, "Post merge validation failed"); &#125; // finally optional features handling. // 清理tools声明等一些收尾工作 processOptionalFeatures(finalMergedDocument, mergingReportBuilder); MergingReport mergingReport = mergingReportBuilder.build(); if (mReportFile.isPresent()) &#123; writeReport(mergingReport); &#125; return mergingReport;&#125; 在这段代码里，我们可以看到三个LoadedManifestInfo对象，分别是: loadedLibraryDocuments loadedMainManifestInfo overlayDocument loadedLibraryDocuments虽然是List&lt;LoadedManifestInfo&gt;,也可以归于同一类。 这就告诉了我们merge过程中，哪些Manifest会参与其中。再继续往下看，可以注意到，有一行代码 xmlDocumentOptional = merge(xmlDocumentOptional, overlayDocument, mergingReportBuilder); 又一个merge?! 是的，没错，这个merge就是决定最终Manifest中元素的地方，我们来看一下代码: 123456789101112131415161718192021222324private Optional&lt;XmlDocument&gt; merge( @NonNull Optional&lt;XmlDocument&gt; xmlDocument, @NonNull LoadedManifestInfo lowerPriorityDocument, @NonNull MergingReport.Builder mergingReportBuilder) throws MergeFailureException &#123; // 检验xml 元素的合法性... // Optional&lt;XmlDocument&gt; result; if (xmlDocument.isPresent()) &#123; result = xmlDocument.get().merge( lowerPriorityDocument.getXmlDocument(), mergingReportBuilder); &#125; else &#123; mergingReportBuilder.getActionRecorder().recordDefaultNodeAction( lowerPriorityDocument.getXmlDocument().getRootNode()); result = Optional.of(lowerPriorityDocument.getXmlDocument()); &#125; // if requested, dump each intermediary merging stage into the report. if (mOptionalFeatures.contains(Invoker.Feature.KEEP_INTERMEDIARY_STAGES) &amp;&amp; result.isPresent()) &#123; mergingReportBuilder.addMergingStage(result.get().prettyPrint()); &#125; return result;&#125; 我们可以看到，这里面主要逻辑就在if else里了，先看else的内容: 12mergingReportBuilder.getActionRecorder().recordDefaultNodeAction( lowerPriorityDocument.getXmlDocument().getRootNode()); 这个方法的内容很简单，就是将存在于lowerPriorityDocument中且不存在mergingReportBuilder中的元素加入到mergingReportBuilder中， 所以，越晚调用此方法，越会忽略lowerPriorityDocument中的元素。 可以看到， merge的过程中，三个此方法的调用顺序是: xmlDocumentOptional = merge(xmlDocumentOptional, overlayDocument, mergingReportBuilder); xmlDocumentOptional = merge(xmlDocumentOptional, loadedMainManifestInfo, mergingReportBuilder); xmlDocumentOptional = merge(xmlDocumentOptional, libraryDocument, mergingReportBuilder); 这就是官方文档Merge Multiple Manifest Files所提到的顺序的原因。 接下来，我们再看if的内容: XmlDocument merge12345678910111213141516171819public Optional&lt;XmlDocument&gt; merge( @NonNull XmlDocument lowerPriorityDocument, @NonNull MergingReport.Builder mergingReportBuilder) &#123; if (getFileType() == Type.MAIN) &#123; mergingReportBuilder.getActionRecorder().recordDefaultNodeAction(getRootNode()); &#125; // 处理Manifest里面的tools定义的操作,这里根据tools定义的不同操作，进行不同的处理 getRootNode().mergeWithLowerPriorityNode( lowerPriorityDocument.getRootNode(), mergingReportBuilder); // 进行一些隐含的检测，比如uses-sdk, targetSdk，library和main的必须相同 // 某些权限申请了一个必须申请另一个，比如WRITE_EXTERNAL_STORAGE addImplicitElements(lowerPriorityDocument, mergingReportBuilder); // force re-parsing as new nodes may have appeared. return mergingReportBuilder.hasErrors() ? Optional.&lt;XmlDocument&gt;absent() : Optional.of(reparse());&#125; 看代码中的注释，应该大概能了解函数的含义。 这样，整个Manifest的merge过程就讲完了.下一篇，我们来研究createGenerateResValuesTask,createMergeResourcesTask和createMergeAssetsTask的过程. 如果大家有不懂，欢迎通过留言和邮件进行交流。]]></content>
      <tags>
        <tag>AndroidPlugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidPlugin源码解析(三)]]></title>
    <url>%2F2017%2F06%2F15%2FAndroidPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%89)%2F</url>
    <content type="text"><![CDATA[上个系列文章留下的taskManager.createTasksForVariantData(tasks, variantData);的分析放到这个系列来进行。 还记得上篇的内容吗？这个方法的具体实现主要分为application和library。 本文将会跳过Instant Run相关代码 由于代码篇幅原因，此篇文章主要是两个taskManager创建Task的步骤。并不包含具体的分析过程，分析过程放在后面几篇文章讲解。 对比下面的代码可以看出，Application Task和Library Task大部分都是相同的，只有几个方法不同。 ApplicationTaskManager createTasksForVariantData123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361@Overridepublic void createTasksForVariantData( @NonNull final TaskFactory tasks, @NonNull final BaseVariantData&lt;? extends BaseVariantOutputData&gt; variantData) &#123; assert variantData instanceof ApplicationVariantData; final String projectPath = project.getPath(); final String variantName = variantData.getName(); final VariantScope variantScope = variantData.getScope(); createAnchorTasks(tasks, variantScope); createCheckManifestTask(tasks, variantScope); //... //有一些和手表相关的Tasks创建过程 //... // Create all current streams (dependencies mostly at this point) createDependencyStreams(tasks, variantScope); // Add a task to process the manifest(s) createMergeAppManifestsTask(tasks, variantScope); // Add a task to create the res values createGenerateResValuesTask(tasks, variantScope); // Add a task to compile renderscript files. createRenderscriptTask(tasks, variantScope); // Add a task to merge the resource folders createMergeResourcesTask(tasks, variantScope); // Add a task to merge the asset folders createMergeAssetsTask(tasks, variantScope); // Add a task to create the BuildConfig class createBuildConfigTask(tasks, variantScope); // Add a task to process the Android Resources and generate source files createApkProcessResTask(tasks, variantScope); // Add a task to process the java resources createProcessJavaResTasks(tasks, variantScope); // Add a task to process the Aidl createAidlTask(tasks, variantScope); createShaderTask(tasks, variantScope); // Add NDK tasks if (!isComponentModelPlugin) &#123; createNdkTasks(variantScope); &#125; else &#123; if (variantData.compileTask != null) &#123; variantData.compileTask.dependsOn(getNdkBuildable(variantData)); &#125; else &#123; variantScope.getCompileTask().dependsOn(tasks, getNdkBuildable(variantData)); &#125; &#125; variantScope.setNdkBuildable(getNdkBuildable(variantData)); // Add external native build tasks createExternalNativeBuildJsonGenerators(variantScope); createExternalNativeBuildTasks(tasks, variantScope); // Add a task to merge the jni libs folders createMergeJniLibFoldersTasks(tasks, variantScope); // Add a compile task CoreJackOptions jackOptions = variantData.getVariantConfiguration().getJackOptions(); AndroidTask&lt;? extends JavaCompile&gt; javacTask = createJavacTask(tasks, variantScope); if (jackOptions.isEnabled()) &#123; AndroidTask&lt;TransformTask&gt; jackTask = createJackTask(tasks, variantScope, true /*compileJavaSource*/); setJavaCompilerTask(jackTask, tasks, variantScope); &#125; else &#123; // Prevent the use of java 1.8 without jack, which would otherwise cause an // internal javac error. if(variantScope.getGlobalScope().getExtension().getCompileOptions() .getTargetCompatibility().isJava8Compatible()) &#123; // Only warn for users of retrolambda and dexguard if (project.getPlugins().hasPlugin("me.tatarka.retrolambda") || project.getPlugins().hasPlugin("dexguard")) &#123; getLogger().warn("Jack is disabled, but one of the plugins you " + "are using supports Java 8 language features."); &#125; else &#123; androidBuilder.getErrorReporter().handleSyncError( variantScope.getVariantConfiguration().getFullName(), SyncIssue.TYPE_JACK_REQUIRED_FOR_JAVA_8_LANGUAGE_FEATURES, "Jack is required to support java 8 language features. " + "Either enable Jack or remove " + "sourceCompatibility JavaVersion.VERSION_1_8." ); &#125; &#125; addJavacClassesStream(variantScope); setJavaCompilerTask(javacTask, tasks, variantScope); getAndroidTasks().create(tasks, new AndroidJarTask.JarClassesConfigAction(variantScope)); createPostCompilationTasks(tasks, variantScope); &#125; // Add data binding tasks if enabled if (extension.getDataBinding().isEnabled()) &#123; createDataBindingTasks(tasks, variantScope); &#125; createStripNativeLibraryTask(tasks, variantScope); if (variantData.getSplitHandlingPolicy().equals( SplitHandlingPolicy.RELEASE_21_AND_AFTER_POLICY)) &#123; if (getExtension().getBuildToolsRevision().getMajor() &lt; 21) &#123; throw new RuntimeException("Pure splits can only be used with buildtools 21 and later"); &#125; createSplitTasks(tasks, variantScope); &#125; @Nullable AndroidTask&lt;InstantRunWrapperTask&gt; fullBuildInfoGeneratorTask = createInstantRunPackagingTasks(tasks, variantScope); createPackagingTask(tasks, variantScope, true /*publishApk*/, fullBuildInfoGeneratorTask); // create the lint tasks. createLintTasks(tasks, variantScope);&#125;~~~ ### LibraryTaskManager createTasksForVariantData~~~ java@Overridepublic void createTasksForVariantData( @NonNull final TaskFactory tasks, @NonNull final BaseVariantData&lt;? extends BaseVariantOutputData&gt; variantData) &#123; final boolean generateSourcesOnly = AndroidGradleOptions.generateSourcesOnly(project); final LibraryVariantData libVariantData = (LibraryVariantData) variantData; final GradleVariantConfiguration variantConfig = variantData.getVariantConfiguration(); final CoreBuildType buildType = variantConfig.getBuildType(); final VariantScope variantScope = variantData.getScope(); GlobalScope globalScope = variantScope.getGlobalScope(); final File intermediatesDir = globalScope.getIntermediatesDir(); final Collection&lt;String&gt; variantDirectorySegments = variantConfig.getDirectorySegments(); final File variantBundleDir = variantScope.getBaseBundleDir(); final String projectPath = project.getPath(); final String variantName = variantData.getName(); // 创建一些preXXXBuild任务，generateXXXResources/Assets/Sources任务以及 // compileXXXSources任务 createAnchorTasks(tasks, variantScope); // Create all current streams (dependencies mostly at this point) createDependencyStreams(tasks, variantScope); // checkXXXManifest createCheckManifestTask(tasks, variantScope); // Add a task to create the res values createGenerateResValuesTask(tasks, variantScope); // Add a task to process the manifest(s) createMergeLibManifestsTask(tasks, variantScope); // Add a task to compile renderscript files. createRenderscriptTask(tasks, variantScope); AndroidTask&lt;MergeResources&gt; packageRes = basicCreateMergeResourcesTask( tasks, variantScope, "package", FileUtils.join(variantBundleDir, "res"), false /*includeDependencies*/, false /*process9Patch*/); if (variantData.getVariantDependency().hasNonOptionalLibraries()) &#123; // Add a task to merge the resource folders, including the libraries, in order to // generate the R.txt file with all the symbols, including the ones from // the dependencies. createMergeResourcesTask( tasks, variantScope, false /*process9patch*/); &#125; packageRes.configure(tasks, new Action&lt;Task&gt;() &#123; @Override public void execute(Task task) &#123; MergeResources mergeResourcesTask = (MergeResources) task; mergeResourcesTask.setPublicFile(FileUtils.join( variantBundleDir, SdkConstants.FN_PUBLIC_TXT // public.txt )); &#125; &#125;); // Add a task to merge the assets folders createMergeAssetsTask(tasks, variantScope); // Add a task to create the BuildConfig class createBuildConfigTask(tasks, variantScope); // Add a task to process Res createProcessResTask(tasks, variantScope, variantBundleDir, false /*generateResourcePackage*/); // process java resources createProcessJavaResTasks(tasks, variantScope); // Add a task to process Aidl createAidlTask(tasks, variantScope); createShaderTask(tasks, variantScope); // Add a compile task AndroidTask&lt;? extends JavaCompile&gt; javacTask = createJavacTask(tasks, variantScope); addJavacClassesStream(variantScope); TaskManager.setJavaCompilerTask(javacTask, tasks, variantScope); // Add data binding tasks if enabled if (extension.getDataBinding().isEnabled()) &#123; createDataBindingTasks(tasks, variantScope); &#125; // Add dependencies on NDK tasks if NDK plugin is applied. if (!isComponentModelPlugin) &#123; // Add NDK tasks createNdkTasks(variantScope); &#125; variantScope.setNdkBuildable(getNdkBuildable(variantData)); // External native build createExternalNativeBuildJsonGenerators(variantScope); createExternalNativeBuildTasks(tasks, variantScope); // merge jni libs. createMergeJniLibFoldersTasks(tasks, variantScope); Sync packageRenderscript = project.getTasks().create( variantScope.getTaskName("package", "Renderscript"), Sync.class); // package from 3 sources. the order is important to make sure the override works well. packageRenderscript.from(variantConfig.getRenderscriptSourceList()) .include("**/*.rsh"); packageRenderscript.into(new File(variantBundleDir, FD_RENDERSCRIPT)); // merge consumer proguard files from different build types and flavors MergeFileTask mergeProGuardFileTask = project.getTasks().create( variantScope.getTaskName("merge", "ProguardFiles"), MergeFileTask.class); mergeProGuardFileTask.setVariantName(variantConfig.getFullName()); mergeProGuardFileTask.setInputFiles( project.files(variantConfig.getConsumerProguardFiles()) .getFiles()); mergeProGuardFileTask.setOutputFile( new File(variantBundleDir, FN_PROGUARD_TXT)); // copy lint.jar into the bundle folder Copy lintCopy = project.getTasks().create( variantScope.getTaskName("copy", "Lint"), Copy.class); lintCopy.dependsOn(LINT_COMPILE); lintCopy.from(new File( globalScope.getIntermediatesDir(), "lint/lint.jar")); lintCopy.into(variantBundleDir); final Zip bundle = project.getTasks().create(variantScope.getTaskName("bundle"), Zip.class); if (variantData.getVariantDependency().isAnnotationsPresent()) &#123; libVariantData.generateAnnotationsTask = createExtractAnnotations(project, variantData); &#125; if (libVariantData.generateAnnotationsTask != null &amp;&amp; !generateSourcesOnly) &#123; bundle.dependsOn(libVariantData.generateAnnotationsTask); &#125; final boolean instrumented = variantConfig.getBuildType().isTestCoverageEnabled(); TransformManager transformManager = variantScope.getTransformManager(); // ----- Code Coverage first ----- if (instrumented) &#123; createJacocoTransform(tasks, variantScope); &#125; // ----- External Transforms ----- // apply all the external transforms. List&lt;Transform&gt; customTransforms = extension.getTransforms(); // 插件中Transform任务 List&lt;List&lt;Object&gt;&gt; customTransformsDependencies = extension.getTransformsDependencies(); for (int i = 0, count = customTransforms.size() ; i &lt; count ; i++) &#123; Transform transform = customTransforms.get(i); // Check the transform only applies to supported scopes for libraries: // We cannot transform scopes that are not packaged in the library // itself. Sets.SetView&lt;Scope&gt; difference = Sets.difference(transform.getScopes(), TransformManager.SCOPE_FULL_LIBRARY); if (!difference.isEmpty()) &#123; String scopes = difference.toString(); androidBuilder.getErrorReporter().handleSyncError( "", SyncIssue.TYPE_GENERIC, String.format("Transforms with scopes '%s' cannot be applied to library projects.", scopes)); &#125; AndroidTask&lt;TransformTask&gt; task = transformManager .addTransform(tasks, variantScope, transform); if (task != null) &#123; List&lt;Object&gt; deps = customTransformsDependencies.get(i); if (!deps.isEmpty()) &#123; task.dependsOn(tasks, deps); &#125; // if the task is a no-op then we make assemble task depend on it. if (transform.getScopes().isEmpty()) &#123; variantScope.getAssembleTask().dependsOn(tasks, task); &#125; &#125; &#125; // ----- Minify next ----- if (buildType.isMinifyEnabled()) &#123; createMinifyTransform(tasks, variantScope, false); &#125; // now add a transform that will take all the class/res and package them // into the main and secondary jar files. // This transform technically does not use its transform output, butthat's // ok. We use the transform mechanism to get incremental data from // the streams. String packageName = variantConfig.getPackageFromManifest(); if (packageName == null) &#123; throw new BuildException("Failed to read manifest", null); &#125; LibraryJarTransform transform = new LibraryJarTransform( new File(variantBundleDir, FN_CLASSES_JAR), new File(variantBundleDir, LIBS_FOLDER), variantScope.getTypedefFile(), packageName, getExtension().getPackageBuildConfig()); excludeDataBindingClassesIfNecessary(variantScope, transform); AndroidTask&lt;TransformTask&gt; jarPackagingTask = transformManager .addTransform(tasks, variantScope, transform); if (!generateSourcesOnly) &#123; bundle.dependsOn(jarPackagingTask.getName()); &#125; // now add a transform that will take all the native libs and package // them into the libs folder of the bundle. LibraryJniLibsTransform jniTransform = new LibraryJniLibsTransform( new File(variantBundleDir, FD_JNI)); AndroidTask&lt;TransformTask&gt; jniPackagingTask = transformManager .addTransform(tasks, variantScope, jniTransform); if (!generateSourcesOnly) &#123; bundle.dependsOn(jniPackagingTask.getName()); &#125; bundle.dependsOn( packageRes.getName(), packageRenderscript, lintCopy, mergeProGuardFileTask, // The below dependencies are redundant in a normal build as // generateSources depends on them. When generateSourcesOnly iinjected they are // needed explicitly, as bundle no longer depends on compileJava variantScope.getAidlCompileTask().getName(), variantScope.getMergeAssetsTask().getName(), variantData.getOutputs().get(0).getScope().getManifestProcessorTask.getName()); if (!generateSourcesOnly) &#123; bundle.dependsOn(variantScope.getNdkBuildable()); &#125; bundle.setDescription("Assembles a bundle containing the library in " + variantConfig.getFullName() + "."); bundle.setDestinationDir( new File(globalScope.getOutputsDir(), BuilderConstants.EXT_LIB_ARCHIVE)); bundle.setArchiveName(globalScope.getProjectBaseName() + "-" + variantConfig.getBaseName() + "." + BuilderConstants.EXT_LIB_ARCHIVE); bundle.setExtension(BuilderConstants.EXT_LIB_ARCHIVE); bundle.from(variantBundleDir); bundle.from(FileUtils.join(intermediatesDir, StringHelper.toStrings(ANNOTATIONS, variantDirectorySegments))); // get the single output for now, though that may always be the case for a library. LibVariantOutputData variantOutputData = libVariantData.getOutputs().get(0); variantOutputData.packageLibTask = bundle; variantScope.getAssembleTask().dependsOn(tasks, bundle); variantOutputData.getScope().setAssembleTask(variantScope.getAssembleTask()); variantOutputData.assembleTask = variantData.assembleVariantTask; if (getExtension().getDefaultPublishConfig().equals(variantConfig.getFullName())) &#123; VariantHelper.setupDefaultConfig(project, variantData.getVariantDependency().getPackageConfiguration()); // add the artifact that will be published project.getArtifacts().add("default", bundle); getAssembleDefault().dependsOn(variantScope.getAssembleTask().getName()); &#125; // also publish the artifact with its full config name if (getExtension().getPublishNonDefault()) &#123; project.getArtifacts().add( variantData.getVariantDependency().getPublishConfiguration().getName(), bundle); bundle.setClassifier( variantData.getVariantDependency().getPublishConfiguration().getName()); &#125; // configure the variant to be testable. variantConfig.setOutput(new LocalTestedAarLibrary( bundle.getArchivePath(), variantBundleDir, variantData.getName(), project.getPath(), variantData.getName(), false /*isProvided*/)); createLintTasks(tasks, variantScope);&#125;]]></content>
      <tags>
        <tag>AndroidPlugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidPlugin源码解析(二)]]></title>
    <url>%2F2017%2F05%2F31%2FAndroidPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[前言上一篇文章还没分析完，还留了剩下两步，这一篇我们继续跟进。先从第三步开始： BasePlugin createTasks看apply方法中第三个过程createTasks() 12345private void createTasks() &#123; taskManager.createTasksBeforeEvaluate( new TaskContainerAdaptor(project.getTasks())); createAndroidTasks(false);&#125; 方法很短，里面的内容就两个方法。第一个方法里面创建了一些task，可是这些task和我们打包过程基本无关，所以这里忽视掉。跳过了一些ndk相关的代码，来看看第二个方法 BasePlugin createAndroidTasks1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@VisibleForTestingfinal void createAndroidTasks(boolean force) &#123; // 检测buildToolVersion,compileSdkVersion的设置 // Make sure unit tests set the required fields. checkState(extension.getBuildToolsRevision() != null, "buildToolsVersion is not specified."); checkState(extension.getCompileSdkVersion() != null, "compileSdkVersion is not specified."); // 不允许依赖java plugin // get current plugins and look for the default Java plugin. if (project.getPlugins().hasPlugin(JavaPlugin.class)) &#123; throw new BadPluginException( "The 'java' plugin has been applied, but it is not compatible with the Android plugins."); &#125; // 初始化TargetInfo这个类 // 这个类负责给build project的时候提供需要的信息 ensureTargetSetup(); // don't do anything if the project was not initialized. // Unless TEST_SDK_DIR is set in which case this is unit tests and we don't return. // This is because project don't get evaluated in the unit test setup. // See AppPluginDslTest if (!force &amp;&amp; (!project.getState().getExecuted() || project.getState().getFailure() != null) &amp;&amp; SdkHandler.sTestSdkFolder == null) &#123; return; &#125; if (hasCreatedTasks) &#123; return; &#125; hasCreatedTasks = true; extension.disableWrite(); // 移除远端Android sdk Maven依赖，改为本地，并将Android sdk Maven依赖放置到最前方 // setup Android SDK repositories. sdkHandler.addLocalRepositories(project); // databinding相关 taskManager.addDataBindingDependenciesIfNecessary(extension.getDataBinding()); variantManager.createAndroidTasks(); ApiObjectFactory apiObjectFactory = new ApiObjectFactory( androidBuilder, extension, variantFactory, instantiator); for (BaseVariantData variantData : variantManager.getVariantDataList()) &#123; apiObjectFactory.create(variantData); &#125;&#125; 前面的通过注释能了解一个大概，后面的很重要，也无法用注释来简单说明。这个方法里有一个方法是最重要的，那就是variantManager.createAndroidTasks();我们来看一看这个方法 VariantManager createAndroidTasks12345678910111213141516171819202122public void createAndroidTasks() &#123; // 这里主要是检测Libray plugin情况下 ProductFlavor和BuildType不能添加applicationIdSuffix和Jack支持 // 以及ProductFlavor不能重写applicationId variantFactory.validateModel(this); // 这个只是在AndroidTest的时候做了操作 variantFactory.preVariantWork(project); final TaskFactory tasks = new TaskContainerAdaptor(project.getTasks()); // 生成我们选择最终编译出来的Variant, 比如debugProd。就是BuildType和ProductFlaovr结合生成的 // ProductFlavor自身也可以通过dimensions结合，参见http://tools.android.com/tech-docs/new-build-system/user-guide#TOC-Multi-flavor-variants if (variantDataList.isEmpty()) &#123; populateVariantDataList(); &#125; // Create top level test tasks. taskManager.createTopLevelTestTasks(tasks, !productFlavors.isEmpty()); for (final BaseVariantData&lt;? extends BaseVariantOutputData&gt; variantData : variantDataList) &#123; createTasksForVariantData(tasks, variantData); &#125; // 类似androidDependencies之类的获取信息的task taskManager.createReportTasks(tasks, variantDataList);&#125; 这里提一点，我们项目里出现的defaultConfig其实就是ProductFlavor；所以，所有defaultConfig里出现的设置，都可以在ProductFlavor中修改。 我们来仔细看一下这个方法createTasksForVariantData(tasks, variantData);,这个方法描述了打包流程。所以这个方法很重要。去掉为测试生成的task代码 VariantManager createTasksForVariantData123456789101112131415161718192021222324252627/** * Create tasks for the specified variantData. */public void createTasksForVariantData( final TaskFactory tasks, final BaseVariantData&lt;? extends BaseVariantOutputData&gt; variantData) &#123; final BuildTypeData buildTypeData = buildTypes.get( variantData.getVariantConfiguration().getBuildType().getName()); // 创建类似于AssembleDebug, AssembleRelease之类的Ｔａｓｋ if (buildTypeData.getAssembleTask() == null) &#123; buildTypeData.setAssembleTask(taskManager.createAssembleTask(tasks, buildTypeData)); &#125; // Add dependency of assemble task on assemble build type task. tasks.named("assemble", new Action&lt;Task&gt;() &#123; @Override public void execute(Task task) &#123; assert buildTypeData.getAssembleTask() != null; task.dependsOn(buildTypeData.getAssembleTask().getName()); &#125; &#125;); VariantType variantType = variantData.getType(); // 把ProductFlaovr的Assemble任务加上 createAssembleTaskForVariantData(tasks, variantData); taskManager.createTasksForVariantData(tasks, variantData);&#125; 这个方法里最重要的就是最后一行taskManager.createTasksForVariantData(tasks, variantData);，不管Test的情况下分为两种实现，一种是application，一种是library，这里我们先放着，因为这里是整个打包过程具体实现的地方，下一系列文章(Android打包过程解析)来解析这个方法的代码。本篇文章继续往下跟进。 打包过程的第一阶段——配置，到这里还剩最后一个方法就完成了，我们来看看。 123456ApiObjectFactory apiObjectFactory = new ApiObjectFactory( androidBuilder, extension, variantFactory, instantiator); // variantManager.getVariantDataList() 就是前面创建的ProductFlavorfor (BaseVariantData variantData : variantManager.getVariantDataList()) &#123; apiObjectFactory.create(variantData);&#125; 我们来看看create方法 ApiObjectFactory create12345678public void create(BaseVariantData&lt;?&gt; variantData) &#123; // 这个方法主要目的是把output对象和variant对象关联起来 BaseVariant variantApi = variantFactory.createVariantApi(variantData, readOnlyObjectProvider); // Only add the variant API object to the domain object set once it's been fully // initialized. extension.addVariant(variantApi);&#125; 不管Test相关的代码的话，我们可以看到，这个方法变成了只有两行，且最后一个方法的注释明显的写明了初始化完毕(it’s been fully initialized)。 最后那个extension对象就是我们刚开始用的Android Extension对象。将variant加入Android Extension对象，初始化就完毕了。]]></content>
      <tags>
        <tag>AndroidPlugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndroidPlugin源码解析(一)]]></title>
    <url>%2F2017%2F05%2F30%2FAndroidPlugin%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[前言上一篇我们知道com.android.application plugin对应的类为com.android.build.gradle.AppPlugin 这个类的声明为: public class AppPlugin extends BasePlugin implements Plugin&lt;Project&gt; 看到最后implements Plugin&lt;Project&gt;，熟悉gradle plugin的人应该知道，apply plugin: &#39;com.android.application&#39;其实就是调用AppPlugin类的public void apply(@NonNull Project project)方法。 com.android.library plugin对应的类为com.android.build.gradle.LibraryPlugin。 这个类的声明为: public class LibraryPlugin extends BasePlugin implements Plugin&lt;Project&gt; 这个两个apply方法的具体内容只有一点点不同，两个都调用了super.apply(project)方法: 12345678@Overridepublic void apply(@NonNull Project project) &#123; super.apply(project); // 下面的代码只在Library plugin中存在 // Default assemble task for the default-published artifact. // This is needed for the prepare task on the consuming project. project.getTasks().create("assembleDefault");&#125; 接下来我们一步步的跟进: BasePlugin apply可以看到，就是调用了BasePlugin的apply方法。我们来看一下BasePlugin的apply方法做了什么。老规矩，分析中会去掉日志，记录，错误检查之类的代码。 1234567891011// 去掉那些我认为不重要的代码后，整个apply方法的流程如下。protected void apply(@NonNull Project project) &#123; configureProject(); createExtension(); createTasks(); // 读取 "android.additional.plugins"对应的插件名称 // Apply additional plugins for (String plugin : AndroidGradleOptions.getAdditionalPlugins(project)) &#123; project.apply(ImmutableMap.of("plugin", plugin)); &#125;&#125; 可以看到，其实整个apply方法分4步，最后一步读取插件没有什么好分析的，对于剩下三步来说本篇文章只分析前两步。 BasePlugin configureProject我们一个过程一个过程研究。先看configureProject() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071String creator = "Android Gradle " Version.ANDROID_GRADLE_PLUGIN_VERSION;protected void configureProject() &#123; sdkHandler = new SdkHandler(project, getLogger()); androidBuilder = new AndroidBuilder( project == project.getRootProject() ? project.getName() : project.getPath(), // project Id creator, // the createdBy String for the apk manifest（打包之后的MANIFEST.MF文件可以看到） new GradleProcessExecutor(project), // An executor for external processes. new GradleJavaProcessExecutor(project), // An executor for external Java-based processes. extraModelInfo, getLogger(), isVerbose()); project.getPlugins().apply(JavaBasePlugin.class); jacocoPlugin = project.getPlugins().apply(JacocoPlugin.class); project.getTasks().getByName("assemble").setDescription( "Assembles all variants of all applications and secondary packages."); // call back on execution. This is called after the whole build is done (not // after the current project is done). // This is will be called for each (android) projects though, so this should support // being called 2+ times. project.getGradle().addBuildListener(new BuildListener() &#123; private final LibraryCache libraryCache = LibraryCache.getCache(); @Override public void buildStarted(Gradle gradle) &#123; &#125; @Override public void settingsEvaluated(Settings settings) &#123; &#125; @Override public void projectsLoaded(Gradle gradle) &#123; &#125; @Override public void projectsEvaluated(Gradle gradle) &#123; &#125; @Override public void buildFinished(BuildResult buildResult) &#123; ExecutorSingleton.shutdown(); sdkHandler.unload(); PreDexCache.getCache().clear( new File(project.getRootProject().getBuildDir(), FD_INTERMEDIATES + "/dex-cache/cache.xml"), getLogger()); JackConversionCache.getCache().clear( new File(project.getRootProject().getBuildDir(), FD_INTERMEDIATES + "/jack-cache/cache.xml"), getLogger()); libraryCache.unload(); Main.clearInternTables(); &#125; &#125;); project.getGradle().getTaskGraph().addTaskExecutionGraphListener( new TaskExecutionGraphListener() &#123; @Override public void graphPopulated(TaskExecutionGraph taskGraph) &#123; for (Task task : taskGraph.getAllTasks()) &#123; if (task instanceof TransformTask) &#123; Transform transform = ((TransformTask) task).getTransform(); if (transform instanceof DexTransform) &#123; PreDexCache.getCache().load( new File(project.getRootProject().getBuildDir(), FD_INTERMEDIATES + "/dex-cache/cache.xml")); break; &#125; else if (transform instanceof JackPreDexTransform) &#123; JackConversionCache.getCache().load( new File(project.getRootProject().getBuildDir(), FD_INTERMEDIATES + "/jack-cache/cache.xml")); break; &#125; &#125; &#125; &#125; &#125;);&#125; 这个方法主要做了如下几个操作: 初始化SdkHandler 初始化AndroidBuilder 依赖JavaBasePlugin，JacocoPlugin；这两个Plugin的apply()方法我这里就不写了，大家有兴趣就像本文一样跟进去即可。 给”assemble”任务加上说明 当Gradle Build完成的时候做一些关闭和清理的操作 在Transform任务真正执行之前，读取对应的Cache。 SdkHandler主要作用是找local.properties文件里SdkLocation和NdkLocationSdkLocation的查找顺序为： 1. local.properties文件里sdk.dir的配置 2. local.properties文件里android.dir的配置 3. 环境变量&quot;ANDROID_HOME&quot; 4. 环境变量&quot;android.home&quot; NdkLocation的查找顺序为： 1. local.properties文件里ndk.dir的配置 2. 环境变量&quot;ANDROID_NDK_HOME&quot; AndroidBuilder对象主要的几个参数的含义从我在代码中添加的注释即可了解。最后讲一下TaskExecutionGraphListener这个接口。官方文档是这样说的: A TaskExecutionGraphListener is notified when the TaskExecutionGraph has been populated.You can use this interface in your build file to perform some action based on the contents of the graph,before any tasks are actually executed. 大概翻译一下，当Gradle将所有task的关系图填充之后，该接口会被调用。你可以在build文件中使用这个接口，在任意task真正执行之前，去完成一些基于task关系图内容的任务。所以这里可以根据对应的Task，判断Task的类型，做对应的操作。 BasePlugin createExtension继续看apply方法中第二个过程createExtension() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127private void createExtension() &#123; // 保存BuildType的NamedDomainObjectContainer final NamedDomainObjectContainer&lt;BuildType&gt; buildTypeContainer = project.container( BuildType.class, new BuildTypeFactory(instantiator, project, project.getLogger())); // 保存ProductFlavor的NamedDomainObjectContainer final NamedDomainObjectContainer&lt;ProductFlavor&gt; productFlavorContainer = project.container( ProductFlavor.class, new ProductFlavorFactory(instantiator, project, project.getLogger(), extraModelInfo)); // 保存SigningConfig的NamedDomainObjectContainer final NamedDomainObjectContainer&lt;SigningConfig&gt; signingConfigContainer = project.container( SigningConfig.class, new SigningConfigFactory(instantiator)); // 创建android这个extension extension = project.getExtensions().create("android", getExtensionClass(), project, instantiator, androidBuilder, sdkHandler, buildTypeContainer, productFlavorContainer, signingConfigContainer, extraModelInfo, isLibrary()); // create the default mapping configuration. // 创建default-mapping和default-metadata两个configuration，并加入描述 // 具体的作用暂时没有看出来,如果你知道，欢迎留言告诉我 // 通过如下代码放在build.gradle，可以打印出当前所有的configuration /** configurations.names.forEach(new Consumer&lt;String&gt;() &#123; @Override void accept(String s) &#123; println "configurations：" + s; &#125; &#125;) */ project.getConfigurations().create("default" + VariantDependencies.CONFIGURATION_MAPPING) .setDescription("Configuration for default mapping artifacts."); project.getConfigurations().create("default" + VariantDependencies.CONFIGURATION_METADATA) .setDescription("Metadata for the produced APKs."); // 创建DependencyManager, 负责管理配置的所有依赖 dependencyManager = new DependencyManager( project, extraModelInfo, sdkHandler); // 负责管理ndk相关，这里略过不提 ndkHandler = new NdkHandler( project.getRootDir(), null, /* compileSkdVersion, this will be set in afterEvaluate */ "gcc",/* toolchainName */ "" /*toolchainVersion*/); // 负责创建taskManager taskManager = createTaskManager( project, androidBuilder, dataBindingBuilder, extension, sdkHandler, ndkHandler, dependencyManager, registry); // 负责创建variant variantFactory = createVariantFactory(); variantManager = new VariantManager( project, androidBuilder, extension, variantFactory, taskManager, instantiator); // Register a builder for the custom tooling model ModelBuilder modelBuilder = new ModelBuilder( androidBuilder, variantManager, taskManager, extension, extraModelInfo, ndkHandler, new NativeLibraryFactoryImpl(ndkHandler), isLibrary(), AndroidProject.GENERATION_ORIGINAL); registry.register(modelBuilder); // Register a builder for the native tooling model NativeModelBuilder nativeModelBuilder = new NativeModelBuilder(variantManager); registry.register(nativeModelBuilder); // 下面三个whenObjectAdded方法从名字上就很好理解 // 当你添加一个对应的对象的时候，回调此方法，也就是需要在variantManager里面添加对应的对象 // map the whenObjectAdded callbacks on the containers. signingConfigContainer.whenObjectAdded(new Action&lt;SigningConfig&gt;() &#123; @Override public void execute(SigningConfig signingConfig) &#123; variantManager.addSigningConfig(signingConfig); &#125; &#125;); buildTypeContainer.whenObjectAdded(new Action&lt;BuildType&gt;() &#123; @Override public void execute(BuildType buildType) &#123; // 默认debug签名 SigningConfig signingConfig = signingConfigContainer.findByName(BuilderConstants.DEBUG); buildType.init(signingConfig); variantManager.addBuildType(buildType); &#125; &#125;); productFlavorContainer.whenObjectAdded(new Action&lt;ProductFlavor&gt;() &#123; @Override public void execute(ProductFlavor productFlavor) &#123; variantManager.addProductFlavor(productFlavor); &#125; &#125;); // 同上面类似，三个回调方法，不过是移除的时候抛出异常 // 这个只能讲一下注释，具体如何复现暂时我不了解 // map whenObjectRemoved on the containers to throw an exception. signingConfigContainer.whenObjectRemoved( new UnsupportedAction("Removing signingConfigs is not supported.")); buildTypeContainer.whenObjectRemoved( new UnsupportedAction("Removing build types is not supported.")); productFlavorContainer.whenObjectRemoved( new UnsupportedAction("Removing product flavors is not supported.")); // 最后创建了这些默认的对象 // create default Objects, signingConfig first as its used by the BuildTypes. variantFactory.createDefaultComponents( buildTypeContainer, productFlavorContainer, signingConfigContainer);&#125; 看到这么长的代码，本想去掉点，发现这里面去什么都不合适。那么跟着我慢慢看一下。这里有几个地方需要解释: NamedDomainObjectContainer是什么？ NamedDomainObjectContainer简单来说就是一个容器，里面的泛型保存了容器里面需要传的类型，类似一个List。 extension的创建代表了什么? extension的创建代表了我们在build.gradle文件中，可以使用 123android&#123;&#125; 这样的闭包来给该扩展传消息。我们在{}内写的任何被允许的内容，在这里都被定义好了。从getExtensionClass方法获取具体的Class，application: 使用com.android.build.gradle.AppExtension.classlibrary: 使用com.android.build.gradle.LibraryExtension.class。后面的值都是负责初始化这两个类的时候传入的值。 TaskManager的作用? 首先这个依旧根据application和library做区分。application: 创建ApplicationTaskManagerlibrary: 创建LibraryTaskManager这两个类就是负责创建我们用来处理Android源码的Gradle Task的地方，比如assemblyDebug, installDebug…现在这里大概了解一下这个对象，后面再细细解读此对象。 VariantManager的作用？ 这就是管理Build Variant的地方，Build Variant的意义就是build type和product flavor交叉形成的，换句话说就是合并这两个东东的属性形成Build Variant的配置。暂时也是单纯的提一下，后面再细细解读。 ModelBuilder, NativeModelBuilder和private ToolingModelBuilderRegistry registry这三个对象我们都先放一下，这个和Android Plugin本身无关，是和gradle的运行机制相关的东东。 好了，这里大概梳理一下此方法的逻辑， 创建buildTypeContainer, productFlavorContainer, signingConfigContainer 将android这个extension加入build.gradle 创建一些后面要使用的对象主要指ModelBuilder和NativeModelBuilder,注册到gradle中。 给上面提到的Container加一些回调 通过variantFactory给Container创建默认的配置 看一下这个默认的配置，App和Library的默认配置是相同的，都是如下代码。 VariantFactory createDefaultComponents1234567891011@Overridepublic void createDefaultComponents( @NonNull NamedDomainObjectContainer&lt;BuildType&gt; buildTypes, @NonNull NamedDomainObjectContainer&lt;ProductFlavor&gt; productFlavors, @NonNull NamedDomainObjectContainer&lt;SigningConfig&gt; signingConfigs) &#123; // must create signing config first so that build type 'debug' can be initialized // with the debug signing config. signingConfigs.create(DEBUG); buildTypes.create(DEBUG); buildTypes.create(RELEASE);&#125; 可以看出来我们的SigningConfigs里面默认有debug类型。为什么不需要写signingConfig就有个默认的debug签名？就是这里配置的。同理，为什么新建工程buildTypes有debug和release？就是这里创建的。这里就相当于我们在build.gradle文件写了如下内容: 12345678910android&#123; signingConfigs &#123; debug &#123;&#125; &#125; buildTypes &#123; debug &#123;&#125; release &#123;&#125; &#125;&#125; 这个方法到这里也就暂时过完了。所以这一篇到这里就告一段落了。]]></content>
      <tags>
        <tag>AndroidPlugin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android Plugin 概述]]></title>
    <url>%2F2017%2F05%2F29%2FAndroidPlugin%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[Plugin前言用Android Studio的会发现，我们新建的Android工程会在根目录的build.gradle文件内引入一个classpath:classpath &#39;com.android.tools.build:gradle:x.y.z&#39;, 我们还会在build.gradle引入如下的plugin: 1234// app apply plugin: 'com.android.application'// libraryapply plugin: 'com.android.library' 我们同时会在如下的范围内配置各种东东 123android&#123;&#125; 这到底是怎么工作的呢？ 简述这其实是一个Gradle Plugin，它表示引入了com.android.tools.build:gradle-x.y.z的jar包。这个包需要在repositories里面声明的位置找。引入了这样一个jar包，我们才能引入必要的plugin: 1234// app apply plugin: 'com.android.application'// libraryapply plugin: 'com.android.library' 我们apply plugin之后，如果对应的plugin接受配置，我们就可以按照plugin的要求进行配置。 123android &#123; // 以及这里面的一大堆配置&#125; 看了前面的内容，我们来分析一下apply plugin之后发生了什么。基于com.android.tools.build:gradle:2.2.2分析。 在源码的gradle目录下，我们可以看到resources/META-INF/gradle-plugins目录下存在一些以.properties结尾的文件。这些文件就是我们前面apply plugin: xxx的名字，每个配置文件里的内容说明引入该plugin相当于引入哪个具体的文件。在这个系列的文章里，我们主要关注两个插件，com.android.application和com.android.library com.android.application.properties里的内容为:implementation-class=com.android.build.gradle.AppPlugin com.android.library.properties里的内容为:implementation-class=com.android.build.gradle.LibraryPlugin 这个就指明了我们要研究的类；application插件对应com.android.build.gradle.AppPlugin类library插件对应com.android.build.gradle.LibraryPlugin类 好了，这篇简述就到此为止了，接下来分几篇来研究整个AndroidPlugin流程。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Groovy & Gradle 入门]]></title>
    <url>%2F2017%2F03%2F01%2FGroovy%26Gradle%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[GroovyGroovy的API文档位于 http://www.groovy-lang.org/api.html 字符串 单引号’’中的内容严格对应Java中的String，不对$符号进行转义 1def singleQuote='I am $ dolloar' //输出就是I am $ dolloar 双引号””的内容则和脚本语言的处理有点像，如果字符中有$符的话，则它会$表达式先求值。 123def doubleQuoteWithoutDollar = "I am one dollar" //输出 I am one dollardef x = 1def doubleQuoteWithDollar = "I am $x dolloar" //输出I am 1 dolloar 函数调用的时候可以不加括号 1println("test") ----&gt; println "test" 123456def getString()&#123; //代码的最后一句是返回值 "Hello World!" // 也可以使用return，和Java中普通函数一样 // return "Hello World!"&#125; 闭包(Closure)是一种数据类型，它代表了一段可执行的代码（类比Java的匿名内部类，可以被称为匿名函数）。其外形如下： 12345def closure = &#123;//闭包是一段代码，所以需要用花括号括起来.. String param1, int param2 -&gt; //这个箭头很关键。箭头前面是参数定义，箭头后面是代码 println "this is codes, $param1, $param2" //这是代码，最后一句是返回值&#125; 简而言之，Closure的定义格式是： 12def closure = &#123;params -&gt; codes&#125; // ordef closure = &#123;codes&#125; // no params ,so no '-&gt;' 闭包定义好后，要调用它的方法就是： 123closure.call(params) // 下面的方式也可以（groovy 的语法糖）closure(params) 如果闭包没定义参数的话，则隐含有一个参数，这个参数名字叫it，和this的作用类似。it代表闭包的参数。 12def greeting = &#123; "Hello, $it!" &#125;assert greeting('XiaoKa') == 'Hello, XiaoKa!' Groovy中，调用函数时可以省略圆括号，当然，对于函数的参数里包含闭包同样适用。 比如对于下面这个方法 1public static &lt;T&gt; List&lt;T&gt; each(List&lt;T&gt; self, Closure closure) 12345// 就可以如下方式调用def testList = [1,2,3,4,5] //定义一个ListtestList.each &#123; println it&#125; 这个地方要记得，对于看gradle的代码很有帮助 123doLast&#123; println 'Hello World!'&#125; 完整代码应该是 123doLast(&#123; println 'Hello World!'&#125;) Gradle (基于3.2.1版本)Gradle是什么: Gradle是一个框架，作为框架，它负责定义流程和规则。而具体的编译工作则是通过插件(Plugin)的方式来完成的。 Gradle工作流程 可以看出，Gradle工作包含三个阶段： 首先是初始化阶段(Initiliazation phase):对Android项目而言，就是evaluate settings.gradle，并将每个Project内的build.gradle转化为Project对象。 Configration阶段:配置对应的Project对象，build.gradle中有关build的代码将会被执行。Configuration阶段完了后，整个build的project以及内部的Task关系就确定了。Configuration会建立一个有向图来描述Task之间的依赖关系。 最后一个阶段就是执行阶段: 我们可以通过给gradle传递相应的命令来执行相应的task。 写Gradle代码Gradle dsl api 文档: https://docs.gradle.org/current/dsl/ Gradle基于Groovy，Groovy又基于Java。所以，Gradle执行的时候和Groovy一样，会把脚本转换成Java对象。Gradle主要有三种对象，这三种对象和三种不同的脚本文件对应，在gradle执行的时候，会将脚本转换成对应的对象： Gradle对象：当我们执行gradle xxx或者什么的时候，gradle会从默认的配置脚本中构造出一个Gradle对象。在整个执行过程中，只有这么一个对象。Gradle对象的数据类型就是Gradle。我们一般很少去定制这个默认的配置脚本。 Project对象：每一个build.gradle会转换成一个Project对象。 Settings对象：显然，每一个settings.gradle都会转换成一个Settings对象。 当我们执行gradle的时候，gradle首先是按顺序解析各个gradle文件。这里边就有所谓的顺序问题。这里看一下下面的文档，里面提到的生命周期就是说明这个顺序的。 Lifecycle There is a one-to-one relationship between a Project and a build.gradle file. During build initialisation, Gradle assembles a Project object for each project which is to participate in the build, as follows: Create a Settings instance for the build. Evaluate the settings.gradle script, if present, against the Settings object to configure it. Use the configured Settings object to create the hierarchy of Project instances. Finally, evaluate each Project by executing its build.gradle file, if present, against the project. The projects are evaluated in breadth-wise order, such that a project is evaluated before its child projects. This order can be overridden by calling Project.evaluationDependsOnChildren() or by adding an explicit evaluation dependency using Project.evaluationDependsOn(java.lang.String). Project和build.gradle文件是一一对应的。在build初始化阶段，Gradle为每一个参与Build的project创建一个Project对象。 为此次build创建一个Settings实例 Evaluate settings.gradle脚本，如果存在，修改前面Settings实例的属性 根据前面配置过的Settings实例创建Project实例的关系图 最后，通过执行它的build.gradle文件来evaluate每个Project。这个evaluate按照广度优先的顺序，这样可以让子Project在父Project之后evaluate。这个顺序也可以修改。 Project对象每一个build.gradle文件都会转换成一个Project对象。在Gradle术语中，Project对象对应的是Build Script。 Build scripts are code Project包含若干Tasks。另外，由于Project对应具体的工程，所以需要为Project加载所需要的插件(apply plugin: &#39;xxx&#39;)。其实，一个Project包含多少Task往往是插件决定的。 所以，在Project中，我们要: 加载插件。 配置插件的行为，就相当于设置配置文件 Project API 文档: https://docs.gradle.org/current/javadoc/org/gradle/api/Project.html 加载插件 12apply plugin: 'com.android.library' &lt;==如果是编译Library，则加载此插件apply plugin: 'com.android.application' &lt;==如果是编译Android APP，则加载此插件 这是每个Android项目都会见到的代码，这个代码调用apply函数，看一下上面的文档，在Method Summary最底部才能看到apply函数，原来是继承自PluginAware接口。 那么，上面那个apply方法是上图所示的第几个方法呢？点击查看详细情况，发现第三个apply函数的解释是: The following options are available: from: A script to apply. Accepts any path supported by Project.uri(Object). plugin: The id or implementation class of the plugin to apply. to: The target delegate object or objects. The default is this plugin aware object. Use this to configure objects other than this object. 除了最常见的apply plugin: &#39;xxx&#39;,我们经常使用的apply from: &#39;xxx&#39;也在此。 apply plugin: &#39;xxx&#39;加载二进制插件，也就是把对应的jar包下载到了本地。至于我们使用的apply from: &#39;xxx&#39;就是加载对应的文件。 配置属性 这一点大家只要去看对应plugin的文档即可，文档内提到有哪些属性，则就可以配置哪些属性。 Gradle官方提供的plugin都可以在这里找到对应的文档（比如我们日常用的plugin: ‘maven’）https://docs.gradle.org/current/userguide/userguide.html Android library和application文档见:http://google.github.io/android-gradle-dsl/current/index.html 其他的第三方plugin,则直接找他们的文档即可。 Project 的一些其它说明: Extra 属性所有额外的属性都需要通过命名空间ext来定义。一旦额外属性被定义了，它可以被所属对象直接访问(读写)(在Project中定义的话，就可以在Project，Task和子Project中访问了)只有初始声明的时候需要命名空间。(当然，如果和其它属性重名还需要全称来指定) All extra properties must be defined through the ext namespace. Once an extra property has been defined,it is available directly on the owning object (in the below case the Project, Task, and sub-projects respectively) andcan be read and updated. Only the initial declaration that needs to be done via the namespace. 最后就是查找顺序，放在这里供大家参考，就不翻译了。 PropertiesA project has 5 property ‘scopes’, which it searches for properties. You can access these properties by name in your build file, or by calling the project’s Project.property(java.lang.String) method. The scopes are: The Project object itself. This scope includes any property getters and setters declared by the Project implementation class. For example, Project.getRootProject() is accessible as the rootProject property. The properties of this scope are readable or writable depending on the presence of the corresponding getter or setter method. The extra properties of the project. Each project maintains a map of extra properties, which can contain any arbitrary name -&gt; value pair. Once defined, the properties of this scope are readable and writable. See extra properties for more details. The extensions added to the project by the plugins. Each extension is available as a read-only property with the same name as the extension. The convention properties added to the project by the plugins. A plugin can add properties and methods to a project through the project’s Convention object. The properties of this scope may be readable or writable, depending on the convention objects. The tasks of the project. A task is accessible by using its name as a property name. The properties of this scope are read-only. For example, a task called compile is accessible as the compile property. The extra properties and convention properties inherited from the project’s parent, recursively up to the root project. The properties of this scope are read-only.When reading a property, the project searches the above scopes in order, and returns the value from the first scope it finds the property in. If not found, an exception is thrown. See Project.property(java.lang.String) for more details. When writing a property, the project searches the above scopes in order, and sets the property in the first scope it finds the property in. If not found, an exception is thrown. See Project.setProperty(java.lang.String, java.lang.Object) for more details. Dynamic MethodsA project has 5 method ‘scopes’, which it searches for methods: The Project object itself. The build file. The project searches for a matching method declared in the build file. The extensions added to the project by the plugins. Each extension is available as a method which takes a closure or Action as a parameter. The convention methods added to the project by the plugins. A plugin can add properties and method to a project through the project’s Convention object. The tasks of the project. A method is added for each task, using the name of the task as the method name and taking a single closure or Action parameter. The method calls the Task.configure(groovy.lang.Closure) method for the associated task with the provided closure. For example, if the project has a task called compile, then a method is added with the following signature: void compile(Closure configureClosure). The methods of the parent project, recursively up to the root project. A property of the project whose value is a closure. The closure is treated as a method and called with the provided parameters. The property is located as described above. 参考: 深入理解Android之Gradle]]></content>
  </entry>
  <entry>
    <title><![CDATA[OkHttp源码解析-(下)]]></title>
    <url>%2F2016%2F12%2F10%2FOkHttp%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-(%E4%B8%8B)%2F</url>
    <content type="text"><![CDATA[这篇的主要内容就是解析这一个个拦截器，所以重新将图放在这里。 图中存在用户自定义的Interceptor对象，这一部分我们忽略，剩下的Interceptor对象还有如下几个： RetryAndFollowUpInterceptor: 失败重试以及重定向 BridgeInterceptor: 用户友好代码和网络友好代码之间的转化。 CacheInterceptor: 读取缓存直接返回、更新缓存 ConnectInterceptor: 和服务器建立连接 CallServerInterceptor: 向服务器发送请求数据、从服务器读取响应数据的 第一个分析RetryAndFollowUpInterceptor这个Interceptor对象。 RetryAndFollowUpInterceptor作为网络框架，意外不可避免，尤其是外部环境导致的意外，这个时候要有合理的恢复策略，同时在HTTP的世界中，还存在服务端修改了域名，旧的域名要通过重定向访问到新的域名的情况。对于框架来说，异常和重定向都是需要重新请求网络的，就在这个拦截器都给处理了。 interceptor()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586@Override public Response intercept(Chain chain) throws IOException &#123; Request request = chain.request(); streamAllocation = new StreamAllocation( client.connectionPool(), createAddress(request.url()), callStackTrace); int followUpCount = 0; Response priorResponse = null; while (true) &#123; if (canceled) &#123; streamAllocation.release(); throw new IOException("Canceled"); &#125; Response response = null; boolean releaseConnection = true; try &#123; response = ((RealInterceptorChain) chain).proceed(request, streamAllocation, null, null); releaseConnection = false; &#125; catch (RouteException e) &#123; // The attempt to connect via a route failed. The request will not have been sent. if (!recover(e.getLastConnectException(), false, request)) &#123; throw e.getLastConnectException(); &#125; releaseConnection = false; continue; &#125; catch (IOException e) &#123; // An attempt to communicate with a server failed. The request may have been sent. boolean requestSendStarted = !(e instanceof ConnectionShutdownException); if (!recover(e, requestSendStarted, request)) throw e; releaseConnection = false; continue; &#125; finally &#123; // We're throwing an unchecked exception. Release any resources. if (releaseConnection) &#123; streamAllocation.streamFailed(null); streamAllocation.release(); &#125; &#125; // Attach the prior response if it exists. Such responses never have a body. if (priorResponse != null) &#123; response = response.newBuilder() .priorResponse(priorResponse.newBuilder() .body(null) .build()) .build(); &#125; // 将服务端返回的消息转换为新的Request // 比如服务端返回301，会在Header头有Location字段告诉你要跳转到哪里。 Request followUp = followUpRequest(response); if (followUp == null) &#123; if (!forWebSocket) &#123; streamAllocation.release(); &#125; return response; &#125; closeQuietly(response.body()); // 不会无限的重定向跟踪，防止环形重定向或者造成攻击 // MAX_FOLLOW_UPS的次数是20 if (++followUpCount &gt; MAX_FOLLOW_UPS) &#123; streamAllocation.release(); throw new ProtocolException("Too many follow-up requests: " + followUpCount); &#125; if (followUp.body() instanceof UnrepeatableRequestBody) &#123; streamAllocation.release(); throw new HttpRetryException("Cannot retry streamed HTTP body", response.code()); &#125; if (!sameConnection(response, followUp.url())) &#123; streamAllocation.release(); streamAllocation = new StreamAllocation( client.connectionPool(), createAddress(followUp.url()), callStackTrace); &#125; else if (streamAllocation.codec() != null) &#123; throw new IllegalStateException("Closing the body of " + response + " didn't close its backing stream. Bad interceptor?"); &#125; request = followUp; priorResponse = response; &#125;&#125; 首先构造了StreamAllocation对象，该对象将三个实体的关系联系起来了。分别是 Connections: 物理socket链接到远端服务 Streams: 逻辑上的HTTP request/response对，在Connections层之上。 Calls: 逻辑上的流的序列，通常是一个初始请求和接下来的跳转请求。 然后，尝试从服务端获取请求，获取请求之后处理请求，通过followUpRequest()方法，这个方法是这个拦截器处理的核心。如果获取响应失败，则会尝试恢复请求，这个处理内容在recover()方法内，其他的一些错误处理我这里就不解析了。那我们来看一看followUpRequest()方法。 followUpRequest()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * Figures out the HTTP request to make in response to receiving &#123;@code userResponse&#125;. This will * either add authentication headers, follow redirects or handle a client request timeout. If a * follow-up is either unnecessary or not applicable, this returns null. */private Request followUpRequest(Response userResponse) throws IOException &#123; if (userResponse == null) throw new IllegalStateException(); Connection connection = streamAllocation.connection(); Route route = connection != null ? connection.route() : null; int responseCode = userResponse.code(); final String method = userResponse.request().method(); switch (responseCode) &#123; // HTTP Status-Code 407: Proxy Authentication Required. // 需要代理，则调用创建okhttp对象的时候设置的代理对象 case HTTP_PROXY_AUTH: Proxy selectedProxy = route != null ? route.proxy() : client.proxy(); if (selectedProxy.type() != Proxy.Type.HTTP) &#123; throw new ProtocolException("Received HTTP_PROXY_AUTH (407) code while not using proxy"); &#125; return client.proxyAuthenticator().authenticate(route, userResponse); // HTTP Status-Code 401: Unauthorized. // 需要身份验证，则调用创建okhttp对象的时候设置的验证对象，加入对应的信息 case HTTP_UNAUTHORIZED: return client.authenticator().authenticate(route, userResponse); case HTTP_PERM_REDIRECT: case HTTP_TEMP_REDIRECT: // "If the 307 or 308 status code is received in response to a request other than GET // or HEAD, the user agent MUST NOT automatically redirect the request" if (!method.equals("GET") &amp;&amp; !method.equals("HEAD")) &#123; return null; &#125; // fall-through case HTTP_MULT_CHOICE: case HTTP_MOVED_PERM: case HTTP_MOVED_TEMP: case HTTP_SEE_OTHER: // Does the client allow redirects? if (!client.followRedirects()) return null; // Header 头中读取Location字段 String location = userResponse.header("Location"); if (location == null) return null; // 通过Location字段的值构造新的请求的url HttpUrl url = userResponse.request().url().resolve(location); // Don't follow redirects to unsupported protocols. if (url == null) return null; // If configured, don't follow redirects between SSL and non-SSL. boolean sameScheme = url.scheme().equals(userResponse.request().url().scheme()); if (!sameScheme &amp;&amp; !client.followSslRedirects()) return null; // Most redirects don't include a request body. Request.Builder requestBuilder = userResponse.request().newBuilder(); if (HttpMethod.permitsRequestBody(method)) &#123; final boolean maintainBody = HttpMethod.redirectsWithBody(method); // 除了PROPFIND(WebDAV用的)请求，其他请求都要转为GET请求 if (HttpMethod.redirectsToGet(method)) &#123; requestBuilder.method("GET", null); &#125; else &#123; RequestBody requestBody = maintainBody ? userResponse.request().body() : null; requestBuilder.method(method, requestBody); &#125; if (!maintainBody) &#123; requestBuilder.removeHeader("Transfer-Encoding"); requestBuilder.removeHeader("Content-Length"); requestBuilder.removeHeader("Content-Type"); &#125; &#125; // When redirecting across hosts, drop all authentication headers. This // is potentially annoying to the application layer since they have no // way to retain them. if (!sameConnection(userResponse, url)) &#123; requestBuilder.removeHeader("Authorization"); &#125; return requestBuilder.url(url).build(); case HTTP_CLIENT_TIMEOUT: // 408's are rare in practice, but some servers like HAProxy use this response code. The // spec says that we may repeat the request without modifications. Modern browsers also // repeat the request (even non-idempotent ones.) if (userResponse.request().body() instanceof UnrepeatableRequestBody) &#123; return null; &#125; // 超时返回原始的请求，就代表重新请求 return userResponse.request(); default: return null; &#125;&#125; 主要的解析都在代码中以注释的形式出现了。到这里，这个Interceptor就解析完毕了，我们来看看文章最开头链上下一个Interceptor: BridgeInterceptor作为框架，不可能要求所有使用者都对HTTP协议理解的很深刻。所以，框架需要将HTTP协议中约定的信息加入其中，要让使用者尽可能少的处理HTTP协议的细节，这就是这个Interceptor的任务。 interceptor()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869@Override public Response intercept(Chain chain) throws IOException &#123; Request userRequest = chain.request(); Request.Builder requestBuilder = userRequest.newBuilder(); RequestBody body = userRequest.body(); if (body != null) &#123; MediaType contentType = body.contentType(); if (contentType != null) &#123; requestBuilder.header("Content-Type", contentType.toString()); &#125; // 从这里可以看出，HTTP请求头的Content-Length和Transfer-Encoding是互斥的 long contentLength = body.contentLength(); if (contentLength != -1) &#123; requestBuilder.header("Content-Length", Long.toString(contentLength)); requestBuilder.removeHeader("Transfer-Encoding"); &#125; else &#123; requestBuilder.header("Transfer-Encoding", "chunked"); requestBuilder.removeHeader("Content-Length"); &#125; &#125; if (userRequest.header("Host") == null) &#123; requestBuilder.header("Host", hostHeader(userRequest.url(), false)); &#125; if (userRequest.header("Connection") == null) &#123; requestBuilder.header("Connection", "Keep-Alive"); &#125; // If we add an "Accept-Encoding: gzip" header field we're responsible for also decompressing // the transfer stream. boolean transparentGzip = false; // 不指定Accept-Encoding请求头，默认使用gzip，压缩数据 if (userRequest.header("Accept-Encoding") == null) &#123; transparentGzip = true; requestBuilder.header("Accept-Encoding", "gzip"); &#125; List&lt;Cookie&gt; cookies = cookieJar.loadForRequest(userRequest.url()); if (!cookies.isEmpty()) &#123; requestBuilder.header("Cookie", cookieHeader(cookies)); &#125; // 用户设置了UA,这里就不能覆盖了，否则使用当前okhttp版本作为UA if (userRequest.header("User-Agent") == null) &#123; requestBuilder.header("User-Agent", Version.userAgent()); &#125; Response networkResponse = chain.proceed(requestBuilder.build()); HttpHeaders.receiveHeaders(cookieJar, userRequest.url(), networkResponse.headers()); Response.Builder responseBuilder = networkResponse.newBuilder() .request(userRequest); if (transparentGzip &amp;&amp; "gzip".equalsIgnoreCase(networkResponse.header("Content-Encoding")) &amp;&amp; HttpHeaders.hasBody(networkResponse)) &#123; // 因为响应式gzip编码，所以需要先解压 GzipSource responseBody = new GzipSource(networkResponse.body().source()); Headers strippedHeaders = networkResponse.headers().newBuilder() .removeAll("Content-Encoding") .removeAll("Content-Length") .build(); responseBuilder.headers(strippedHeaders); responseBuilder.body(new RealResponseBody(strippedHeaders, Okio.buffer(responseBody))); &#125; return responseBuilder.build();&#125; 这里理解起来很容易，看代码中的注释即可，接下来看下一个Interceptor: CacheInterceptor网络请求毕竟是一个缓慢的操作，所以，可以通过缓存来加速，但是，不能所有都缓存，也不能什么情况下都从缓存中拿数据，这里就是处理这个逻辑的地方。 intercept()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485@Override public Response intercept(Chain chain) throws IOException &#123; Response cacheCandidate = cache != null ? cache.get(chain.request()) : null; long now = System.currentTimeMillis(); // 根据HTTP的Date|Expires|Last-Modified|ETag|Age头来确定对应的策略 CacheStrategy strategy = new CacheStrategy.Factory(now, chain.request(), cacheCandidate).get(); Request networkRequest = strategy.networkRequest; Response cacheResponse = strategy.cacheResponse; if (cache != null) &#123; cache.trackResponse(strategy); &#125; if (cacheCandidate != null &amp;&amp; cacheResponse == null) &#123; closeQuietly(cacheCandidate.body()); // The cache candidate wasn't applicable. Close it. &#125; // If we're forbidden from using the network and the cache is insufficient, fail. if (networkRequest == null &amp;&amp; cacheResponse == null) &#123; return new Response.Builder() .request(chain.request()) .protocol(Protocol.HTTP_1_1) .code(504) .message("Unsatisfiable Request (only-if-cached)") .body(Util.EMPTY_RESPONSE) .sentRequestAtMillis(-1L) .receivedResponseAtMillis(System.currentTimeMillis()) .build(); &#125; // If we don't need the network, we're done. if (networkRequest == null) &#123; return cacheResponse.newBuilder() .cacheResponse(stripBody(cacheResponse)) .build(); &#125; Response networkResponse = null; try &#123; networkResponse = chain.proceed(networkRequest); &#125; finally &#123; // If we're crashing on I/O or otherwise, don't leak the cache body. if (networkResponse == null &amp;&amp; cacheCandidate != null) &#123; closeQuietly(cacheCandidate.body()); &#125; &#125; // If we have a cache response too, then we're doing a conditional get. if (cacheResponse != null) &#123; // HTTP Status-Code 304: Not Modified. // 存在缓存，服务端还返回这个HTTP状态码 if (networkResponse.code() == HTTP_NOT_MODIFIED) &#123; Response response = cacheResponse.newBuilder() .headers(combine(cacheResponse.headers(), networkResponse.headers())) .sentRequestAtMillis(networkResponse.sentRequestAtMillis()) .receivedResponseAtMillis(networkResponse.receivedResponseAtMillis()) .cacheResponse(stripBody(cacheResponse)) .networkResponse(stripBody(networkResponse)) .build(); networkResponse.body().close(); // Update the cache after combining headers but before stripping the // Content-Encoding header (as performed by initContentStream()). cache.trackConditionalCacheHit(); cache.update(cacheResponse, response); return response; &#125; else &#123; closeQuietly(cacheResponse.body()); &#125; &#125; Response response = networkResponse.newBuilder() .cacheResponse(stripBody(cacheResponse)) .networkResponse(stripBody(networkResponse)) .build(); if (HttpHeaders.hasBody(response)) &#123; CacheRequest cacheRequest = maybeCache(response, networkResponse.request(), cache); response = cacheWritingResponse(cacheRequest, response); &#125; return response;&#125; 这里主要通过CacheStrategy类来管理Cache的储存策略，比如要不要保存Cache，保存Cache的超时时间等等，详细内容看这个类即可。如果没网，不存在Cache就返回504状态码的响应，否则返回cache响应。通过网络请求获取响应。响应的状态码304的情况下，还存在缓存，则更新缓存，返回对应的响应。最后，不存在缓存的情况下去除cacheResponse和networkResponse的body，返回通过请求获取的响应。 接着看下一个Interceptor: ConnectInterceptor这个Interceptor的作用就是建立与服务端的连接，为什么将连接服务器和服务器之间的交互分开呢？我觉得因为提供的networkInterceptors对象，这个对象给了框架使用者这样一种能力，在连接到服务器的时候做一些需要的操作（我暂时没遇到这样的需求，所以对这里理解不深，大家有想法的可以在评论里告诉我） intercept()123456789101112@Override public Response intercept(Chain chain) throws IOException &#123; RealInterceptorChain realChain = (RealInterceptorChain) chain; Request request = realChain.request(); StreamAllocation streamAllocation = realChain.streamAllocation(); // We need the network to satisfy this request. Possibly for validating a conditional GET. boolean doExtensiveHealthChecks = !request.method().equals("GET"); HttpCodec httpCodec = streamAllocation.newStream(client, doExtensiveHealthChecks); RealConnection connection = streamAllocation.connection(); return realChain.proceed(request, streamAllocation, httpCodec, connection);&#125; 还记得分析RetryAndFollowUpInterceptor过程中出现的StreamAllocation对象吗？这里又出现，根据前面说的，HttpCodec就是一个Stream，RealConnection就是Connection。那也就意味着，逻辑的HTTP请求响应是HttpCodec负责处理的。 这里就简单分析一下HttpCodec,对它有个具体的认识，到分析下一个Interceptor的时候，才不会那么头疼。 123456789101112131415161718192021222324252627282930/** Encodes HTTP requests and decodes HTTP responses. */public interface HttpCodec &#123; /** * The timeout to use while discarding a stream of input data. Since this is used for connection * reuse, this timeout should be significantly less than the time it takes to establish a new * connection. */ int DISCARD_STREAM_TIMEOUT_MILLIS = 100; /** Returns an output stream where the request body can be streamed. */ Sink createRequestBody(Request request, long contentLength); /** This should update the HTTP engine's sentRequestMillis field. */ void writeRequestHeaders(Request request) throws IOException; /** Flush the request to the underlying socket. */ void finishRequest() throws IOException; /** Read and return response headers. */ Response.Builder readResponseHeaders() throws IOException; /** Returns a stream that reads the response body. */ ResponseBody openResponseBody(Response response) throws IOException; /** * Cancel this stream. Resources held by this stream will be cleaned up, though not synchronously. * That may happen later by the connection pool thread. */ void cancel();&#125; 可以看到HttpCodec是一个接口，为什么是一个接口呢？因为HTTP协议的兼容性问题，HTTP现在已经存在两种实现了，分为HTTP1和HTTP2，HTTP协议的不同，当然，进行这些操作的实现方式也不一样，所以，通过接口隔离具体协议实现方式的不同。当然，具体的实现在streamAllocation.newStream()这里，通过连接到服务器，服务器会返回接受的协议，发现服务端接受”h2”，则使用Http2Codec，否则使用Http1Codec 好了，终于到了最后一个Interceptor: CallServerInterceptor前面的Interceptor做了这么多铺垫，就等着最后一个Interceptor完成最后一步，向服务端发送请求，从服务端获取请求。 intercept()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Override public Response intercept(Chain chain) throws IOException &#123; HttpCodec httpCodec = ((RealInterceptorChain) chain).httpStream(); StreamAllocation streamAllocation = ((RealInterceptorChain) chain).streamAllocation(); Request request = chain.request(); long sentRequestMillis = System.currentTimeMillis(); // 发送request header httpCodec.writeRequestHeaders(request); if (HttpMethod.permitsRequestBody(request.method()) &amp;&amp; request.body() != null) &#123; // 发送request body Sink requestBodyOut = httpCodec.createRequestBody(request, request.body().contentLength()); BufferedSink bufferedRequestBody = Okio.buffer(requestBodyOut); request.body().writeTo(bufferedRequestBody); bufferedRequestBody.close(); &#125; // 完成request httpCodec.finishRequest(); // 读取response header Response response = httpCodec.readResponseHeaders() .request(request) .handshake(streamAllocation.connection().handshake()) .sentRequestAtMillis(sentRequestMillis) .receivedResponseAtMillis(System.currentTimeMillis()) .build(); int code = response.code(); if (forWebSocket &amp;&amp; code == 101) &#123; // Connection is upgrading, but we need to ensure interceptors see a non-null response body. response = response.newBuilder() .body(Util.EMPTY_RESPONSE) .build(); &#125; else &#123; response = response.newBuilder() .body(httpCodec.openResponseBody(response)) .build(); &#125; if ("close".equalsIgnoreCase(response.request().header("Connection")) || "close".equalsIgnoreCase(response.header("Connection"))) &#123; streamAllocation.noNewStreams(); &#125; if ((code == 204 || code == 205) &amp;&amp; response.body().contentLength() &gt; 0) &#123; throw new ProtocolException( "HTTP " + code + " had non-zero Content-Length: " + response.body().contentLength()); &#125; return response;&#125; 主要流程是: 发送request header 存在request body,发送给服务端 完成request 读取服务端response header，生成Response对象 存在response body,则将body添加到上一步生成的Response对象里 好了，到这里我们就把Interceptor链给分析完毕了。然后Response对象就一层层的返回到之前的Interceptors里了。如果前面的Interceptor关心Response，就重新进行这样的链式处理，否则就返回给我们调用网络请求的地方，这样我们就拿到了需要的Response对象。 通过我们的分析，可以看出，这个责任链把功能分层分的淋漓尽致，需要什么功能，加一个专门的Interceptor即可，了解到了这样一种简洁干净的设计，以后写代码的时候就可以借鉴一下。]]></content>
      <tags>
        <tag>square</tag>
        <tag>okhttp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OkHttp源码解析-(上)]]></title>
    <url>%2F2016%2F12%2F03%2FOkHttp%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90-(%E4%B8%8A)%2F</url>
    <content type="text"><![CDATA[一直都知道Retrofit-OkHttp-Okio是Square公司封装的用于网络请求的大杀器，项目中也往往都在用Retrofit，看过我之前的文章的朋友应该看到过我的Retrofit源码解析系列， 但是一直没空往下继续深入，去解析OkHttp和Okio，毕竟Retrofit2.0本身就是搭建于OkHttp之上的。 老规矩，先讲一下这个库如何用，最后渐渐的一步步走到这个库的处理过程。 如何使用OkHttp官方文档很详细的解释了如何使用OkHttp，我们只要一步步跟着就可以了。至于OkHttp优点，或者说为什么使用OkHttp我在这里就略过不提，相信你在看源码的过程中会有自己的理解。 大家在平常的http请求中，最常见的就是使用GET和POST请求，所以，官方Demo也就主要描述了如何处理这两种请求。 1234567891011121314151617181920212223final OkHttpClient client = new OkHttpClient();String get(String url) throws IOException &#123; Request request = new Request.Builder() .url(url) .build(); Response response = client.newCall(request).execute(); return response.body().string();&#125;public static final MediaType JSON = MediaType.parse("application/json; charset=utf-8"); String post(String url, String json) throws IOException &#123; RequestBody body = RequestBody.create(JSON, json); Request request = new Request.Builder() .url(url) .post(body) .build(); Response response = client.newCall(request).execute(); return response.body().string();&#125; 这里可以看出，想要完成一次请求需要以下几个过程： 构造OkHttpClient对象 创建Request 调用OkHttpClient对象的newCall()方法构造Call对象 调用Call对象的execute()方法获取Response OkHttp 整体调用流程 这次先看图，有了图，跟代码的时候才不会在代码中迷失。 OkHttp源码解读OkHttpClient对象参考流程图，我们先需要一个OkHttpClient对象，这个对象需要许多参数，所以用建造者模式构建，当然，每个参数都提供了默认值，也可以直接用OkHttpClient的构造函数来使用默认的实现。 这是各个参数的默认值，需要修改的通过Builder直接修改即可。 123456789101112131415161718192021public Builder() &#123; dispatcher = new Dispatcher(); protocols = DEFAULT_PROTOCOLS; connectionSpecs = DEFAULT_CONNECTION_SPECS; proxySelector = ProxySelector.getDefault(); cookieJar = CookieJar.NO_COOKIES; socketFactory = SocketFactory.getDefault(); hostnameVerifier = OkHostnameVerifier.INSTANCE; certificatePinner = CertificatePinner.DEFAULT; proxyAuthenticator = Authenticator.NONE; authenticator = Authenticator.NONE; connectionPool = new ConnectionPool(); dns = Dns.SYSTEM; followSslRedirects = true; followRedirects = true; retryOnConnectionFailure = true; connectTimeout = 10_000; readTimeout = 10_000; writeTimeout = 10_000; pingInterval = 0;&#125; Call对象接下来就需要发请求了，发请求需要一个Call对象, 我们通过newCall()方法获取这个对象。 123@Override public Call newCall(Request request) &#123; return new RealCall(this, request, false /* for web socket */);&#125; 可以看出，真正调用的Call实现类是RealCall这个类,默认情况下，这个RealCall对象的forWebSocket属性为false。 执行请求构造完Call对象，通过Call对象的execute()方法同步的执行请求或者enqueue()方法异步的执行请求。 这里看一下图，会感觉图中的线在这里很密集，而且Dispatcher对象的线会指给这么多的方法，等我们进入源码中，就可以仔细了解了。 RealCall execute()123456789101112131415@Override public Response execute() throws IOException &#123; synchronized (this) &#123; if (executed) throw new IllegalStateException("Already Executed"); executed = true; &#125; captureCallStackTrace(); try &#123; client.dispatcher().executed(this); Response result = getResponseWithInterceptorChain(); if (result == null) throw new IOException("Canceled"); return result; &#125; finally &#123; client.dispatcher().finished(this); &#125;&#125; RealCall enqueue()12345678@Override public void enqueue(Callback responseCallback) &#123; synchronized (this) &#123; if (executed) throw new IllegalStateException("Already Executed"); executed = true; &#125; captureCallStackTrace(); client.dispatcher().enqueue(new AsyncCall(responseCallback));&#125; 可以看到，这里面的方法都会调用Dispatcher对象的方法，所以，图中从Dispatcher对象中发出3条线，代表对应方法执行过程中调用Dispatcher对象的方法。 虽然Dispatcher对象在同步和异步的请求中都有它身影的出现，但是，它主要作用是在异步请求中，开线程池执行异步请求，并用队列保持准备执行的请求。 Dispatcher enqueue()12345678synchronized void enqueue(AsyncCall call) &#123; if (runningAsyncCalls.size() &lt; maxRequests &amp;&amp; runningCallsForHost(call) &lt; maxRequestsPerHost) &#123; runningAsyncCalls.add(call); // runningAsyncCalls是一个队列 executorService().execute(call); // executorService是一个线程池 &#125; else &#123; readyAsyncCalls.add(call); // readyAsyncCalls是一个队列 &#125;&#125; 在同步请求中，它的作用是保存当前正在执行的请求，那么为什么要进行这样一个操作呢？ Dispatcher executed()123synchronized void executed(RealCall call) &#123; runningSyncCalls.add(call); // runningSyncCalls是一个队列&#125; 查看Dispatcher对象的方法，发现有个cancelAll()方法，原来给用户提供了取消所有请求的操作，那么当前执行的同步请求依旧是要被cancel的，所以，自然要把当前正在执行的同步请求加入其中了。 Dispatcher cancelAll()1234567891011121314public synchronized void cancelAll() &#123; for (AsyncCall call : readyAsyncCalls) &#123; call.get().cancel(); &#125; for (AsyncCall call : runningAsyncCalls) &#123; call.get().cancel(); &#125; for (RealCall call : runningSyncCalls) &#123; call.cancel(); &#125;&#125; 最后获取到Response对象的时候，通知Dispatcher请求结束了，Dispatcher就会在队列里移除相应的请求，所以图中Dispatcher对象还有一条线指向Response对象。 重新回到RealCall对象，发现无论同步还是异步请求，获取Response的方式都是通过 1Response response = getResponseWithInterceptorChain(); 这样获取的。 我们通过这个方法就获取了Response对象，说明这个方法为我们做了真正发请求的工作，那么我们先看一张图，看这么复杂的工作，这个方法是如何实现的。 从图中可以看到，这个执行过程像链条一样一环套一环，如果熟悉设计模式，这不就是很好的责任链模式嘛。好了，我们看一下它这里具体做了什么。 RealCall getResponseWithInterceptorChain()1234567891011121314151617Response getResponseWithInterceptorChain() throws IOException &#123; // Build a full stack of interceptors. List&lt;Interceptor&gt; interceptors = new ArrayList&lt;&gt;(); interceptors.addAll(client.interceptors()); interceptors.add(retryAndFollowUpInterceptor); interceptors.add(new BridgeInterceptor(client.cookieJar())); interceptors.add(new CacheInterceptor(client.internalCache())); interceptors.add(new ConnectInterceptor(client)); if (!forWebSocket) &#123; interceptors.addAll(client.networkInterceptors()); &#125; interceptors.add(new CallServerInterceptor(forWebSocket)); Interceptor.Chain chain = new RealInterceptorChain( interceptors, null, null, null, 0, originalRequest); return chain.proceed(originalRequest);&#125; 可以看到，这其中有下面几种拦截器进行操作。 在配置 OkHttpClient 时设置的 interceptors； 负责失败重试以及重定向的 RetryAndFollowUpInterceptor； 负责把用户构造的请求转换为发送到服务器的请求、把服务器返回的响应转换为用户友好的响应的 BridgeInterceptor；4.负责读取缓存直接返回、更新缓存的 CacheInterceptor； 负责和服务器建立连接的 ConnectInterceptor； 配置 OkHttpClient 时设置的 networkInterceptors； 负责向服务器发送请求数据、从服务器读取响应数据的 CallServerInterceptor。 可以看到，这个方法最终执行的是RealInterceptorChain对象的process()方法。 12345678910111213141516171819202122232425262728293031323334353637public Response proceed(Request request, StreamAllocation streamAllocation, HttpCodec httpCodec, Connection connection) throws IOException &#123; if (index &gt;= interceptors.size()) throw new AssertionError(); calls++; // If we already have a stream, confirm that the incoming request will use it. if (this.httpCodec != null &amp;&amp; !sameConnection(request.url())) &#123; throw new IllegalStateException("network interceptor " + interceptors.get(index - 1) + " must retain the same host and port"); &#125; // If we already have a stream, confirm that this is the only call to chain.proceed(). if (this.httpCodec != null &amp;&amp; calls &gt; 1) &#123; throw new IllegalStateException("network interceptor " + interceptors.get(index - 1) + " must call proceed() exactly once"); &#125; // Call the next interceptor in the chain. RealInterceptorChain next = new RealInterceptorChain( interceptors, streamAllocation, httpCodec, connection, index + 1, request); Interceptor interceptor = interceptors.get(index); Response response = interceptor.intercept(next); // Confirm that the next interceptor made its required call to chain.proceed(). if (httpCodec != null &amp;&amp; index + 1 &lt; interceptors.size() &amp;&amp; next.calls != 1) &#123; throw new IllegalStateException("network interceptor " + interceptor + " must call proceed() exactly once"); &#125; // Confirm that the intercepted response isn't null. if (response == null) &#123; throw new NullPointerException("interceptor " + interceptor + " returned null"); &#125; return response;&#125; 如果不关心异常状况，核心代码就是如下几行： 12345 // Call the next interceptor in the chain.RealInterceptorChain next = new RealInterceptorChain( interceptors, streamAllocation, httpCodec, connection, index + 1, request);Interceptor interceptor = interceptors.get(index);Response response = interceptor.intercept(next); 在process()的过程中，做了如下几个操作： 生成新的RealInterceptorChain对象 按index获取当前interceptors列表中Interceptor对象 调用Interceptor对象的intercept()方法，并将新的RealInterceptorChain传给Interceptor对象。 这样，只要Interceptor对象在intercept()方法执行过程中调用Chain对象的proceed()方法，就会调用传给Interceptor对象的下一个RealInterceptorChain对象的proceed()方法。这样，就像上面说的，一条链一样的不停调用。 好了，上半部分的分析暂时就到这里了，下半部分对各个Interceptor进行分析。 参考: 拆轮子系列：拆 OkHttp]]></content>
      <tags>
        <tag>square</tag>
        <tag>okhttp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins的使用]]></title>
    <url>%2F2016%2F10%2F11%2FJenkins%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前提: 使用Git作为公司的版本控制工具，使用GitLab作为对应的服务器 首先安装Jenkins plugins, 下面列出两个关键的Plugins GitLab Plugin Git plugin 打包APK对于APK的打包，相信大家公司内部都有不同的测试环境，不同的功能需要在不同的测试环境上测试，不同的功能又对应不同的分支，如果开发人员负责根据测试人员的需求打包的话，测试人员麻烦，开发人员也麻烦。程序员一个极好的特质就是懒，那么，这时候，Jenkins提供的This build is parameterized功能就派上了用处。 勾选了这个选项之后，就可以添加自己需要的参数了，比如: 记住这个地方填写的name， 这里的名称将会是shell里的变量，使用$来引用对应具体的变量，下面将会看到这些变量的使用。 既然环境和分支都已经可选，第二步是配置Jenkins去哪个地址拉源代码，即SCM配置，如下图: 可以看到，在Branches to build的地方，我填的内容是*/$git_branch，这个参数就是从前面This build is parameterized位置添加的参数，所以用户填了哪个分支，这里就能拿到用户填写的分支，在Build的时候也就会拉对应分支的代码。 按照我们的意向拉了对应分支的代码，开头所说的另外一个问题，更改对应的环境，当然，可以使用ProductFlavor来解决这个问题，再最后打包的情况下选择对应的ProductFlavor，数量少了还好说，数量多了，就会变得很麻烦。因此，这里在Build Environment的地方，打勾Executor shell script on remote host using ssh，如下图 这里需要插件SSH Plugin的支持 在Pre build script的地方，修改你工程中决定使用哪个环境的文件，这里就可以使用最开头的$url_host那个设定的参数。 当然还有Post build script，需要的话就同样写一段shell来达到你的目的。 有些情况下，你需要获取这次打包对应的git信息，可以看到，每个打包都有一个Git Build Data，这里面有对应的git信息，所以，勾选inject environment variables to the build process即可将对应的信息添加到这次打包的环境变量中。这个需要Environment Injector Plugin插件的支持。这里有个问题，就是Evaluated Groovy Script脚本的执行过程中，使用正常方式无法获取所有的Jenkins环境变量，那么需要使用currentBuild.getEnvironment(currentListener).get(&#39;var&#39;)来获取var的环境变量。currentBuild和currentListener在Evaluated Groovy Script右边的?说明里 最后，测试人员肯定希望能下载打包完成的APK，那么在最后的Post-build Actions即可实现该需求。 在Archive the artifacts里面填入打包完成的apk的路径，则Jenkins会以可以下载的形式输出该Apk的链接在对应的打包完成页面。 打包AAR打包AAR和打包APK的需求是不同的，对于AAR的输出，一定希望对开发透明，不需要任何人去点一下build，才去打包AAR，这个时候，我们前面安装的GitLab Plugin就十分有用。有了它，我们可以设定触发打包任务的条件: 画红线的URL代表 GitLab WebHook需要回调的URL，即GitLab收到某些事件(push, merge request ..etc)，将会调用该URL，此时将会触发打包。在最下面还有个红线，就是指定相应的分支，在这些分支另在GitLab WebHook回调的时候才进行打包，公司的特殊需求即可在这里定制。 有可能你想流式的打包，也可能你的aar有优先级，换句话说，A aar可能依赖B aar，那么一定要B aar打包完毕后，才能打包A aar，那样的话你就需要下面这个插件Jenkins Parameterized Trigger plugin这个插件将前一个打包aar的Build Env传给后一个打包aar的过程中，那样，就拥有一致的Build Env了。]]></content>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Retrofit2源码分析-(下)]]></title>
    <url>%2F2016%2F05%2F22%2Fretrofit2.0%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%8B)%2F</url>
    <content type="text"><![CDATA[引言 上篇我们主要看了一下Retrofit的设计者对Retrofit1.+版本设计的评价（好的方面和坏的方面），同时也讲了Retrofit2都这些问题时如何解决的，这篇，我们就一起深入去了解一下。 网络请求 一个网络连接需要构造请求，发送请求，处理服务端返回内容三个步骤组成，但是处理服务端返回内容是用库的人的工作，所以一个网络请求库只要做到前两步并将服务端返回内容转化为使用库的人需要的格式即可。 对于这三个步骤，两个版本的区别在于 构造请求: Retrofit2新加了@Url注解。 新加了对某个请求单独加入Http请求头，@Headers(用于方法)/@Header(用于函数参数)。 发送请求: 将网络请求交给了OkHttp 将服务端返回内容转化为你需要的格式: Retrofit2将可以同时拿到返回内容的Header和Body，Retrofit1则不可以 使用Call返回值类型将同步和异步请求统一 可以添加多个Converter 可以添加多个返回值类型的解析机制，在Retrofit2中称为CallAdapterFactory使用addCallAdapterFactory() 我们接下来跟着官方的例子来看一下这些修改时如何实现的。 源码分析12345678910111213Retrofit retrofit = new Retrofit.Builder() .baseUrl("https://api.github.com/") .addConverterFactory(GsonConverterFactory.create()) .addCallAdapterFactory(RxJavaCallAdapterFactory.create()) .build();GitHubService service = retrofit.create(GitHubService.class);Call&lt;List&lt;Repo&gt;&gt; repos = service.listRepos("octocat");public interface GitHubService &#123; @GET("users/&#123;user&#125;/repos") Call&lt;List&lt;Repo&gt;&gt; listRepos(@Path("user") String user);&#125; 从这里可以看出，通过Retrofit对象的create()方法创建出GithubService接口的实现，然后通过该实现进行网路请求，那么我们看看create()方法， 123456789101112131415161718192021222324public &lt;T&gt; T create(final Class&lt;T&gt; service) &#123; Utils.validateServiceInterface(service); if (validateEagerly) &#123; eagerlyValidateMethods(service); &#125; return (T) Proxy.newProxyInstance(service.getClassLoader(), new Class&lt;?&gt;[] &#123;service&#125;,new InvocationHandler() &#123; private final Platform platform = Platform.get(); @Override public Object invoke(Object proxy, Method method, Object... args) throws Throwable &#123; // If the method is a method from Object then defer to normal invocation. if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(this, args); &#125; if (platform.isDefaultMethod(method)) &#123; return platform.invokeDefaultMethod(method, service, proxy, args); &#125; ServiceMethod serviceMethod = loadServiceMethod(method); OkHttpCall okHttpCall = new OkHttpCall&lt;&gt;(serviceMethod, args); return serviceMethod.callAdapter.adapt(okHttpCall); &#125; &#125;);&#125; 熟悉Retrofit1的同学可以看出这里有3点不同的地方，不熟悉也没关系，因为相同的地方就是验证接口的有效性和使用动态代理生成接口对应的实现类。接下来讲一下这三点不同。 添加了validateEagerly参数，让客户端调用网络请求的时候不需要在反射生成的代理类中才进行初始化;提前初始化，提前验证接口是否合法，不需要在调用时才知道。 添加了一个暂时不用的方法，为以后使用做扩展platform.isDefaultMethod(method)。 将初始化过的方法交给OkHttpCall去执行，执行完后，通过设置的CallAdapter将返回值转化为你要的返回类型对象，当你通过该对象调用它的方法的时候，将把请求交给OkHttp去执行。 分开来讲一下，先看第二点： 123boolean isDefaultMethod(Method method) &#123; return false;&#125; 可以看出这个方法压根就没有用，所以我不是很了解放在这里一个不需要的方法意义是什么。 再看第一点： 1234567891011121314151617181920212223242526if (validateEagerly) &#123; eagerlyValidateMethods(service);&#125;private void eagerlyValidateMethods(Class&lt;?&gt; service) &#123; //和Retrofit1一样，通过反射确定客户端的平台，使用不同的方式处理 Platform platform = Platform.get(); for (Method method : service.getDeclaredMethods()) &#123; if (!platform.isDefaultMethod(method)) &#123; loadServiceMethod(method); &#125; &#125;&#125;//和Retrofit1一样，使用Map做了一个缓存，有的话直接取，//否则遍历该方法的信息，创建ServiceMethod对象ServiceMethod loadServiceMethod(Method method) &#123; ServiceMethod result; synchronized (serviceMethodCache) &#123; result = serviceMethodCache.get(method); if (result == null) &#123; result = new ServiceMethod.Builder(this, method).build(); serviceMethodCache.put(method, result); &#125; &#125; return result;&#125; 看一下第三点： 123ServiceMethod serviceMethod = loadServiceMethod(method); OkHttpCall okHttpCall = new OkHttpCall&lt;&gt;(serviceMethod, args); return serviceMethod.callAdapter.adapt(okHttpCall); serviceMethod.callAdapter.adapt()方法将Call对象转化为你写的返回值类型对象，即你在接口中所需的除Call&lt;T&gt;类型外，都需要对应的CallAdapter来进行转化。OkHttpCall实现了Call&lt;T&gt;接口，也就是前一篇讲到的，加入了Call&lt;T&gt;返回值类型。默认的CallAdapter支持转化成Call类型对象，如果需要其他的类型，你就需要调用addCallAdapterFactory()方法来添加新类型了。然后通过OkHttp进行网络请求。 到这里大体上就讲完了，接下来就重新回到前面讲的，对一个网络请求的三个步骤进行分析，看看代码中具体是如何实现的（老规矩，忽视不重要的错误处理）。 构造请求:这一点的重点在ServiceMethod这个类，前面讲到了这个类初始化的地方，那么就从new ServiceMethod.Builder(this, method).build()开始。构造函数就初始化了一些类变量，来看一下build()方法: 1234567891011121314151617181920212223242526272829303132333435public ServiceMethod build() &#123; // callAdapter = createCallAdapter(); // 把函数返回值类型中泛型内的类型拿出来， // 比如接口方法中某个方法返回Call&lt;Repo&gt;，这个方法执行结果是Repo responseType = callAdapter.responseType(); responseConverter = createResponseConverter(); for (Annotation annotation : methodAnnotations) &#123; //解析定义的Http注解，如GET，HTTP，FormUrlEncoded，Multipart，Headers //如果存在Headers注解，Headers注解内的内容不能为空 parseMethodAnnotation(annotation); &#125; // parameterAnnotationsArrays = method.getParameterAnnotations(), // 即参数中的注解，二维注解数组Annotation[][] int parameterCount = parameterAnnotationsArray.length; // ParameterHandler这个类如名字所示，负责处理有注解的函数参数 parameterHandlers = new ParameterHandler&lt;?&gt;[parameterCount]; for (int p = 0; p &lt; parameterCount; p++) &#123; // parameterType = method.getGenericParameterTypes() Type parameterType = parameterTypes[p]; // 这个方法就是检测方法参数类型是否是可以处理的类型 // 这个方法可以学到如何遍历所有的参数类型，包括泛型类型参数 if (Utils.hasUnresolvableType(parameterType)) &#123; throw parameterError(p, "Parameter type must not include a type variable or wildcard: %s", parameterType); &#125; Annotation[] parameterAnnotations = parameterAnnotationsArray[p]; // 这里处理Retrofit2定义的所有@Target(PARAMETER)的参数，返回对应的ParameterHandler parameterHandlers[p] = parseParameter(p, parameterType, parameterAnnotations); &#125; return new ServiceMethod&lt;&gt;(this);&#125; 除了createCallAdapter()，createResponseConverter()这两个方法，这两个方法我们一会再说，按名字理解就是创建CallAdapter和ResponseConverter，这两个东西的作用就是将方法的返回值转化成你要的。 剩下的关键方法都在方法中做了注释，这样，ServiceMethod类对象就生成了。到了这里，先不继续进行，先看一下parseMethodAnnotation(annotation)方法中使用的parseHttpMethodAndPath()方法，这个方法中会做一些验证，这个验证个人觉得有些不好理解，所以放出源代码，并将注释写在方法中。 1234567891011121314151617181920212223private void parseHttpMethodAndPath(String httpMethod, String value, boolean hasBody) &#123; this.httpMethod = httpMethod; this.hasBody = hasBody; if (value.isEmpty()) &#123; return; &#125; // Get the relative URL path and existing query string, if present. int question = value.indexOf('?'); if (question != -1 &amp;&amp; question &lt; value.length() - 1) &#123; // Ensure the query string does not have any named parameters. String queryParams = value.substring(question + 1); Matcher queryParamMatcher = PARAM_URL_REGEX.matcher(queryParams); if (queryParamMatcher.find()) &#123;// url中?之后的的String不允许存在"&#123;&#125;" throw methodError("URL query string \"%s\" must not have replace block. " + "For dynamic query parameters use @Query.", queryParams); &#125; &#125; this.relativeUrl = value; this.relativeUrlParamNames = parsePathParameters(value);&#125; 好了， 这点不好理解的地方也过去了。既然生成了ServiceMethod，那么我们继续往下看：构造函数生成了OkHttpCall对象，最后，通过ServiceMethod的CallAdapter对象将OkHttpCall对象转化为你在网络请求接口中声明的返回值类型。 在这里，我们再看一下上面提到但没分析的那两个方法createCallAdapter()和createResponseConverter()。先看createCallAdapter(): 12345678910private CallAdapter&lt;?&gt; createCallAdapter() &#123; // 返回方法声明的返回类型 Type returnType = method.getGenericReturnType(); if (returnType == void.class) &#123; throw methodError("Service methods cannot return void."); &#125; Annotation[] annotations = method.getAnnotations(); return retrofit.callAdapter(returnType, annotations);&#125; 这个方法就获取了方法的返回值类型和方法的注解，最后调用Retrofit对象的callAdapter()方法找到对应的callAdapter，好了，我们继续,retrofit对象的callAdapter()方法就一句代码，return nextCallAdapter(null, returnType, annotations); 123456789101112131415public CallAdapter&lt;?&gt; nextCallAdapter(CallAdapter.Factory skipPast, Type returnType, Annotation[] annotations) &#123; checkNotNull(returnType, "returnType == null"); checkNotNull(annotations, "annotations == null"); // List&lt;CallAdapter.Factory&gt; adapterFactories,你调用addCallAdapterFactory()就将你的CallAdapterFactory加入到了这个列表中 //即使你不调用addCallAdapterFactory()方法，系统也会加入一个默认的CallAdapterFactory,就是在第一篇文章中提到的Call返回值类型。 int start = adapterFactories.indexOf(skipPast) + 1; for (int i = start, count = adapterFactories.size(); i &lt; count; i++) &#123; CallAdapter&lt;?&gt; adapter = adapterFactories.get(i).get(returnType, annotations, this); if (adapter != null) &#123; // 如果返回值类型和adapter能处理的相同，则不为null return adapter; &#125; &#125; throw new IllegalArgumentException("...");&#125; 这里将注解传给callAdapter()是为了我们使用更好的扩展。这个扩展具体指什么呢？前面我们提到，可以添加多个Converter和CallAdapter。这里就是给你这样一种能力，如果你有自定义注解，在这里你就可以拿到自己定义的注解来处理。callAdapter()方法直接从adapterFactories列表中获取目标类型，即直接获取你需要该方法返回什么类型的值。可以看到，这里就是找哪个CallAdapter可以处理用户声明的该方法返回值类型，这样一个CallAdapter对象就生成了。 接下来看看createResponseConverter()方法，在第一篇的介绍中提到Converter和CallAdapter类似，那么我猜测代码中的创建过程应该也是类似的，来仔细瞧一瞧是不是这样。 12345678private Converter&lt;ResponseBody, T&gt; createResponseConverter() &#123; Annotation[] annotations = method.getAnnotations(); try &#123; return retrofit.responseBodyConverter(responseType, annotations); &#125; catch (RuntimeException e) &#123; // Wide exception range because factories are user code. throw methodError(e, "Unable to create converter for %s", responseType); &#125;&#125; 和上面一样，调用了retrofit对象的方法，responseBodyConverter()方法同样一句代码:return nextResponseBodyConverter(null, type, annotations); 12345678910111213141516171819202122public &lt;T&gt; Converter&lt;ResponseBody, T&gt; nextResponseBodyConverter(Converter.Factory skipPast, Type type, Annotation[] annotations) &#123; checkNotNull(type, "type == null"); checkNotNull(annotations, "annotations == null"); // List&lt;Converter.Factory&gt; converterFactories,你调用addConverterFactory()方法就是将你的Converter.Factory加入这个列表中，因为列表有序，所以从前往后找，JSON没有明显的特征，所以需要将JSON放在最后 // 即使你不调用addConverterFactory()方法，会加入内置的Converter.Factory // 下面是加入内置Converter.Factory的方法和注释。 // Add the built-in converter factory first. This prevents overriding its behavior but also // ensures correct behavior when using converters that consume all types. // converterFactories.add(new BuiltInConverters()); int start = converterFactories.indexOf(skipPast) + 1; for(int i = start, count = converterFactories.size(); i &lt; count; i++)&#123; //将ResponseBody转化为你需要的类型 Converter&lt;ResponseBody, ?&gt; converter = converterFactories.get(i).responseBodyConverter(type, annotations, this); if (converter != null) &#123; // 如果能处理对应的type，则不为null //noinspection unchecked return (Converter&lt;ResponseBody, T&gt;) converter; &#125; &#125; throw new IllegalArgumentException("...");&#125; 除了这个ResponseBodyConverter，还有一个RequestBodyConverter，其实这个也是从converterFactories里面寻找处理请求参数的Converter。 到这里，Retrofit对象的create()方法就分析完了，CallAdapter将OkHttpCall对象转化成了你想要的对象，此时就可以拿你想要的对象进行操作了，也就是构造请求完成了。 发送请求:当用户调用接口中方法的时候，底层直接通过OkHttp进行发送请求。 将服务端返回内容转化为你需要的格式:OkHttp接收到请求后，通过Converter将服务端返回内容转化为你需要的格式。所以到这里源码的流程已经走完了。 可以看出其实这个框架在构造请求的完成的时候工作也完成了。 接下来有一些需要注意的地方: 接口中任何一个方法的只允许被一个Http方法注解(即[GET, POST, PUT, DELETE, PATCH, HEAD, OPTIONS, HTTP]这个列表中的元素每个方法只能使用一个) 网络请求只要服务端有数据返回，就不算failure，Retrotfit1的时候404和500都算failure。所以当你使用Callback时，在onResponse函数里，使用response.isSuccessful()确定服务端返回正常数据还是服务端错误信息。 Url的拼接规则变了，初始化Retrofit对象的时候baseUrl最后一定要加’/‘。详细的内容查看下面的表格: BaseUrl AnnotationUrl RequestUrl https://api.github.com/repo/ /square/end https://api.github.com/square/end https://api.github.com/repo/ square/end https://api.github.com/repo/square/end https://api.github.com/repo/ http://z.cn/end http://z.cn/end 最后放一张流程图，来源[Retrofit分析-漂亮的解耦套路][2]，是一个很棒的流程图，可以加深对此源码分析的理解。 最后是一些参考资料: 你真的会用Retrofit2吗? 对Retrofit2中用到的注解进行了分类，可以让你更清晰的使用对应的注解；提供了自定义ConverterFactory和CallAdapterFactory的思路。]]></content>
      <tags>
        <tag>retrofit</tag>
        <tag>square</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Retrofit2源码分析-(上)]]></title>
    <url>%2F2016%2F05%2F08%2Fretrofit2.0%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(%E4%B8%8A)%2F</url>
    <content type="text"><![CDATA[前言​ 千呼万唤始出来的Retrofit2.0正式版终于出来了，首先我们来看一看 Jake Wharton 的演讲，这次演讲主要讲了1.0版本的好处和问题，以及2.0版本的优势，对于好处，我们在1.0版本的使用过程中相信都已体会过了，在这里我就不重新提了，那么这第一篇就主要讲一下1.0版本的问题，和2.0在设计上是如何解决这些问题的。至于源代码的分析和对比将会放在第二篇中讲。 Retrofit1 问题 无法同时获取响应返回的原始数据，比如请求头或者请求的URL，和反序列化的响应返回的body。 如果你写了一个请求，有时同步执行，有时异步执行，你就需要写两个基本一样的请求。（如果使用RxJava可以实现，但是你要知道如何创建Observables） converter的工作方式事实上稍微有点低效。 严重限制了我们把自定义类作为参数加入请求的能力。 Retrofit2Call内置和OkHttp的Call类型一样语义的Call类型，不同的是它能做一些额外的事情，比如反序列化对象，相反OkHttp只返回原始的内容给你，这就是Retrofit2实现一个类似的Call而不是用OkHttp中的Call的原因。它是一个请求/响应对，每一个Call实例只能使用一次，它有Java的clone方法来创建新的实例（这个操作很廉价）。另一个巨大的好处是它把同步和异步的执行统一在了一起，这样就解决了Retrofit1中同步请求和异步请求要写两个的问题，同时，它可以被取消，这个是Retrofit1中不存在的特性。接下来我们看一下它的使用: 123456789interface GitHubService &#123; @GET("/repos/&#123;owner&#125;/&#123;repo&#125;/contributors") Call&lt;List&lt;Contributor&gt;&gt; repoContributors( @Path("owner") String owner, @Path("repo") String repo); &#125; Call&lt;List&lt;Contributor&gt;&gt; call = gitHubService.repoContributors("square", "retrofit")&#125;; 参数化Response对象通过Response，你可以获取请求的元数据，包括 response code, message, 和headers。 12345678910class Response&lt;T&gt; &#123; int code(); String message(); Headers headers(); boolean isSuccess(); T body(); ResponseBody errorBody(); com.squareup.okhttp.Response raw();&#125; 只有响应的Http code是200的情况下才会进行反序列化。如果响应没有成功，我们不知道响应是什么类型。将回返回ResponseBody类型，它将Content-Type，Content-Length，还有原始的body进行了封装，让你可以对响应做出想要的处理。 动态URL参数有这样一种情况，请求列表的时候通常都要给服务端传入page，告诉服务端你要第几页数据，如果服务端将page相关的信息放在了响应头中，比如下一页page是什么，总共有几页等等，甚至服务端返回你接下来需要请求的URL。例如Github的API，Retrofit1很难处理这种情况。我们有一个新的@Url注解，允许你在参数中传入Url。如下所示: 123@GETCall&lt;List&lt;Contributor&gt;&gt; repoContributorsPaginate( @Url String url); 多样的，高效的ConvertersRetrofit1有一个Converter的问题，当然，对于大多数人来说这都不算是问题，但对于一个库来说，它就成了问题。考虑下面一种场景，服务端有两套API，只是返回值的类型不同，比如一个返回json，一个返回xml，可能是如下的url: 12@GET("/some/xml/endpoint")@GET("/some/json/endpoint") 在Retrofit1中，你不得不定义两个接口，初始化两个RestAdapter，因为它只有一个Converter，每一个Converter和一个RestAdapter绑定在一起，但是，我们认为这些操作同属于一组API，而不是分离的API，所以，API的返回类型不应该成为你组织Service的方式。 我们会按你添加的顺序来一个个的问Converter是否可以序列化该返回值，如果它的回答是yes，那么就交给该Converter来序列化返回值。 两点需要注意的地方: 由于JSON没有任何要求或者限制，所以我们无法知道它是否可以被JSON Converter序列化，所以JSON Converter永远会回答yes，在这种情况下，JSON Converter应该是你添加的最后一个Converter。 和Retrofit1不同的是，Retrofit2本身提供内置的Converter，但是只是提供了三种基础的Converter，像Json之类的Converter不会内置，所以你需要明确的声明你所用的Converter。当然，我们提供了一些Converter，但是你需要把这些Converter作为独立的依赖加入项目中。 多种多样插件形式的执行机制之前，我们只有死板的执行机制。现在我们把它弄成了插件形式的，它的工作方式和Covnerter类似。你可以加入你自己的方式，或者选择一个我们提供的已有的方式，我们依旧提供RxJava这个执行方式，但是它和Retrofit2库分离，需要单独的引入。 12345678910interface GitHubService &#123; @GET("/repos/&#123;owner&#125;/&#123;repo&#125;/contributors") Call&lt;List&lt;Contributor&gt;&gt; repoContributors(..); @GET("/repos/&#123;owner&#125;/&#123;repo&#125;/contributors") Observable&lt;List&lt;Contributor&gt;&gt; repoContributors2(..); @GET("/repos/&#123;owner&#125;/&#123;repo&#125;/contributors") Future&lt;List&lt;Contributor&gt;&gt; repoContributors3(..);&#125; 我们单纯的查看返回类型，对于第一个函数来说，我们对执行机制的询问过程是这样的。call —&gt; RxJava? No! —&gt; Call? Yes! 对于第三个Future,将会抛出一个异常，因为你没有加入你的执行机制，导致了执行机制无法执行。该过程是Future —&gt; RxJava? No! —&gt; Call? No! —&gt; Throw!。如果你想添加自己的执行机制，只要在初始化Retrofit对象的时候使用addCallAdapterFactory()，添加你自己的执行机制即可。 这个执行机制(Execution Mechanism)翻译到中文不是很合适，按我的理解，这个所谓的执行方式，就是生成的函数有个默认的返回值，但是返回值类型不一定是你需要的，所以，使用这个对象将生成函数的返回值转化成你需要的类型。 由OkHttp提供底层技术支持就是说引入Retrofit2会默认引入OkHttp到你的项目中。 极好的效率（这个我没找到相应的测试，只是Jake Wharton在演讲中提到了）]]></content>
      <tags>
        <tag>retrofit</tag>
        <tag>square</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android管理任务栈之——launchMode]]></title>
    <url>%2F2016%2F03%2F06%2FAndroid%E7%AE%A1%E7%90%86%E4%BB%BB%E5%8A%A1%E6%A0%88%E4%B9%8B%E2%80%94%E2%80%94launchMode%2F</url>
    <content type="text"><![CDATA[前言之前遇到了一个问题，大概是有4个Activity，分别为A, B, C, D Activity，当你的Activity跳转, A -&gt; B -&gt; C -&gt; D 跳转，此时，你需要从D跳回B，不能把Cfinish()掉，因为用户中途可能会返回C，而不继续进行下一步操作；直接跳也不可以，因为默认情况下跳到B的时候，用户点返回会返回D而不是A，这个时候我知道了LaunchMode，发现这种情况很适合一个LaunchMode的使用 ———— singleTask，趁此机会，研究一下LaunchMode。 LaunchMode 开篇说到LaunchMode，我们来看看官方文档怎么说 ： An instruction on how the activity should be launched. There are four modes that work in conjunction with activity flags (FLAG_ACTIVITY_* constants) in Intent objects to determine what should happen when the activity is called upon to handle an intent. They are: “standard” “singleTop” “singleTask” “singleInstance” The default mode is “standard”. 即Activity有4种启动模式，分别是 “standard” “singleTop” “singleTask” “singleInstance” 这个需要在Manifest中指定。可以和Intent中的FLAG_ACTIVITY_*结合使用。 当然，我们要明确一点，Android中以栈的形式来管理Activity，至于什么是栈，请复习数据结构相关内容，这里假设大家都理解栈。 四种模式各个模式的作用先告诉大家一个方法，通过如下命令获取你当前包的Activity任务栈 1adb shell dumpsys activity activities | sed -En -e '/Stack #/p' -e '/Running activities/,/Run #0/p' | grep "包名" “standard” 大家默认新建的Activity就是这个模式的，这个模式相当于不对Activity加任何约束，即你调用intent.startActivity()的时候，每调用一次，就会在栈中新加一个改Activity。 先看一下我们当前的任务栈： 1Run #7: ActivityRecord&#123;ac97db9 u0 com.air.activitylaunchmodetestdemo/.MainActivity t1211&#125; 可以看到，当前只有一个MainActivity，此时，当我点击按钮执行startActivity(new Intent(this, MainActivity.class))的时候，可以看到任务栈变成了： 12Run #8: ActivityRecord&#123;11e0192c u0 com.air.activitylaunchmodetestdemo/.MainActivity t1211&#125;Run #7: ActivityRecord&#123;ac97db9 u0 com.air.activitylaunchmodetestdemo/.MainActivity t1211&#125; 因为没有在startActivity()之后执行finish()方法，现在我们有了两个MainActivity实例，此时如果退出应用，要点两次后退键才可以。如果我再次点击按钮执行startActivity(new Intent(this, MainActivity.class))的时候，可以想象新的任务栈该变成什么了。 接下来我们以图的形式说明该LaunchMode情况下，任务栈的样子。 就像上图画的那样，每启动一个新的Activity，就会添加到栈上，无论即将启动的Activity是否是同一个Activity。 “singleTop” 看到这个名字，先靠命名理解一下，在顶部的时候是单一存在，因为是以栈的形式来管理Activity的，那么顶部指的就是栈的顶部。 好了，上面的猜测其实已经和真正的情况是差不多了，我在此再补充几点细节。对于不是栈顶的Activity，即使设置了这个launchMode，依旧会创建新的Activity。例如，存在两个ActivityA、B，它们的launchMode都是singleTop，如果你在A中启动A，栈不会新添加Activity，因为此时AActivity在栈顶，但是，如果你用A启动B，B就会被加入到栈中，此时栈就变成了AB，再拿B启动A，会产生A的新实例添加到栈内，现在栈变成了ABA。 拿前面举的AActivity例子来说，在A中启动A，由于A在栈顶，所以栈内不会添加A的新实例，自然不会调用A的onCreate()方法，这个时候，如果启动A的时候给A传了额外的参数，那么需要在哪里处理呢？答案是onNewIntent()，这里就是singleTop和standard两种launchMode不同的地方。 常用场景：带搜索功能的Activity，搜索不同的关键词不用多次启动同一个Activity。 “singleTask” 上面介绍的两个launchMode的作用不能实现栈中只存在一个Activity实例，但是有些时候，就像我在开头举的那个例子，业务逻辑中间要跳好几层，最终只想跳到入口界面，即栈中只需要存在一个相应的Activity，而不是多个。 总结一个singleTask的作用，若一个Activity的launchMode被指定为singleTask，则在对应的栈中只会存在一个实例。若这个实例不存在，则新建实例；若存在，则把在栈中该实例之上的其他实例移除出栈，并调用该Activity的onNewIntent()方法，将intent传入。 我们来通过代码验证一下：启动了四个Activity， 1234Run #7: ActivityRecord&#123;b53e419 u0 com.air.activitylaunchmodetestdemo/.BActivity t3909&#125;Run #6: ActivityRecord&#123;7a83deb u0 com.air.activitylaunchmodetestdemo/.AActivity t3909&#125;Run #5: ActivityRecord&#123;df9c4ad u0 com.air.activitylaunchmodetestdemo/.CActivity t3909&#125;Run #4: ActivityRecord&#123;e7c438 u0 com.air.activitylaunchmodetestdemo/.MainActivity t3909&#125; CActivity为launchMode为singleTask的Activity，此时，从BActivity启动CActivity，通过前面的介绍，我们猜测会调用CActivity的onNewIntent()方法，并且，在栈中，CActivity之上的Activity都会被移除，此时，执行startActivity()方法，最新的栈内容如下： 12Run #5: ActivityRecord&#123;df9c4ad u0 com.air.activitylaunchmodetestdemo/.CActivity t3909&#125;Run #4: ActivityRecord&#123;e7c438 u0 com.air.activitylaunchmodetestdemo/.MainActivity t3909&#125; 可以看出，确实是我们所介绍的效果。至于设置taskAffinity后该launchMode的表现，我们在这篇文章中不会涉及，留到下一篇文章再与大家见面。 常用场景：注册Activity或者启动应用的首个Activity，这样就不用担心任务栈内有其他的Activity没有销毁了。 “singleInstance” 这个或许可以称之为singleTask模式的加强版，对于设置了singleTask的Activity，我们可以让它加入到在我们当前的任务栈中，也可以新建一个任务栈，把它放入(设置taskAffinity的情况下)。但是，对于singleInstance的Activity，我们只能新建一个任务栈，并把它放入，没有任何Activity可以和它在一个栈中。 那么对于我们开发的应用，其中有一个Activity需要给其他应用使用，比如浏览器，你从自己的应用点开一个链接，使用浏览器应用开启网页，你单机后退，直接退到了你的应用，而不是你之前浏览的其他页面，如果你在浏览器中访问的连接可以访问你的应用，那么，此时点击后退你会发现，居然在你应用所在的栈中进行了回退操作，而不是退到浏览器页面，然后你退出应用，发现这个时候反倒打开了浏览器页面，这样说有点绕，我们以图的形势来展示一下。 至于常用场景，我本以为支付、分享之类的很可能会使用，但是我反编译微信查看其manifest文件的时候，发现它并没有使用这个launchMode，所以暂时这里空着，如果你有什么使用场景，可以给我留言。 参考文章： 官方文档 深入讲解 Android 中的 Activity launchMode 参考书籍： 《第一行代码》 《Android开发艺术探索》]]></content>
  </entry>
  <entry>
    <title><![CDATA[Retrofit-1.9源码分析-(下)]]></title>
    <url>%2F2016%2F01%2F16%2FRetrofit_1.9%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-(%E4%B8%8B)%2F</url>
    <content type="text"><![CDATA[看过上一篇的分析，并思考了我在最后留给大家的对那个方法的思考之后，我们就可以继续解析这个库了。 记得上一篇提到的小尾巴吗？这里我们先不谈这个小尾巴，先从Demo里接口里面的定义开始谈。 注解1234567public interface GitHubService &#123; //被注释的内容是同步方法，在Android 4.0以后不允许主线程进行网络请求，所以一般不这么用 //@GET("/users/&#123;user&#125;/repos") //List&lt;Repo&gt; listRepos(@Path("user") String user); @GET("/users/&#123;user&#125;/repos") void listRepos(@Path("user") String user, Callback&lt;List&lt;Repo&gt;&gt; callback);&#125; 在这里我们看到使用注解定义进行http请求时所需要的各种信息，比如相对url，参数等等。那我们就先观察一下注解。这里使用了@GET注解，表示HTTP中的GET方法， GET12345678/** Make a GET request to a REST path relative to base URL. */@Documented@Target(METHOD)@Retention(RUNTIME)@RestMethod("GET")public @interface GET &#123; String value();&#125; 注解基础就不在这里讲了，这个@GET注解又被@RestMethod注解注解了，我们来看一下。 RestMethod1234567@Documented@Target(ANNOTATION_TYPE)@Retention(RUNTIME)public @interface RestMethod &#123; String value(); boolean hasBody() default false;&#125; 这是注解注解的注解，也就是所谓的元注解。所有被这个注解注解的注解都可以被认为是该类型，可以当作所有子类都可以被转换为父类。 被这个元注解注解的注解有这么几个, @GET, @POST, @PUT, @PATCH, @DELETE, @DELETE,可以看出，这就是进行HTTP请求的几种常用的请求方式。 在示例中出现的其他注解先放一下。有了注解，那要实现这些注解的解析方式，这个实现在RestMethodInfo.java中这里有两个重要方法来处理自定义的注解：第一种是用在方法上的注解，如@GET，由parseMethodAnnotations()方法实现，第二种是用在参数内的注解，如@PATH，由parseParameters()实现， 在这两个方法中，你可以知道哪些注解可以用在方法上，哪些注解可以用在参数内。 好了，到这里，我们终于可以返回上一篇最后留下的坑继续看了。 123return (T) Proxy.newProxyInstance(service.getClassLoader(), new Class&lt;?&gt;[] &#123; service &#125;, new RestHandler(getMethodInfoCache(service))); 完成接口代理的创建最终，RestHandler实现了InvocationHandler，对接口中的方法进行加工。 看名字应该也很容易理解，getMethodInfoCache()的意义就是从传入的接口中获取对应的相关方法的缓存，用户定义的接口中每个Method都要和RestMethodInfo对应，自然想到使用Map做它们关系的联结。RestHandler持有对应的Map。来看一下InvocationHandler接口中必须实现的唯一的方法： RestHandler.invoke()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960@SuppressWarnings("unchecked") //@Override public Object invoke(Object proxy, Method method, final Object[] args) throws Throwable &#123; // If the method is a method from Object then defer to normal invocation. //Object类方法，直接执行，不需要做额外操作 if (method.getDeclaringClass() == Object.class) &#123; return method.invoke(this, args); &#125; // Load or create the details cache for the current method. final RestMethodInfo methodInfo = getMethodInfo(methodDetailsCache, method); //同步方法的处理逻辑，作为Android库的话忽视就可以了 if (methodInfo.isSynchronous) &#123; try &#123; return invokeRequest(requestInterceptor, methodInfo, args); &#125; catch (RetrofitError error) &#123; Throwable newError = errorHandler.handleError(error); if (newError == null) &#123; throw new IllegalStateException("Error handler returned null for wrapped exception.", error); &#125; throw newError; &#125; &#125; if (httpExecutor == null || callbackExecutor == null) &#123; throw new IllegalStateException("Asynchronous invocation requires calling setExecutors."); &#125; //这个RestMethodInfo类中的类变量，通过你接口中方法定义来确认 if (methodInfo.isObservable) &#123; if (rxSupport == null) &#123; if (Platform.HAS_RX_JAVA) &#123; //和前面hasOkHttpOnClasspath()方法类似，就是找对应的包名 rxSupport = new RxSupport(httpExecutor, errorHandler, requestInterceptor); &#125; else &#123; throw new IllegalStateException("Observable method found but no RxJava on classpath."); &#125; &#125; //rxSupport是一个自定义的类，查看这个方法的源码应该可以提升你对任意对象转换成Observable对象的理解 return rxSupport.createRequestObservable(new RxSupport.Invoker() &#123; @Override public ResponseWrapper invoke(RequestInterceptor requestInterceptor) &#123; return (ResponseWrapper) invokeRequest(requestInterceptor, methodInfo, args); &#125; &#125;); &#125; // Apply the interceptor synchronously, recording the interception so we can replay it later. // This way we still defer argument serialization to the background thread. final RequestInterceptorTape interceptorTape = new RequestInterceptorTape(); requestInterceptor.intercept(interceptorTape); Callback&lt;?&gt; callback = (Callback&lt;?&gt;) args[args.length - 1]; //线程池执行网络请求，callbackExecutor指定callback执行的线程 httpExecutor.execute(new CallbackRunnable(callback, callbackExecutor, errorHandler) &#123; @Override public ResponseWrapper obtainResponse() &#123; return (ResponseWrapper) invokeRequest(interceptorTape, methodInfo, args); &#125; &#125;); return null; // Asynchronous methods should have return type of void.&#125; 不得不说这个代码的注释写的真好，我针对其中的一部分代码写了中文注释。这里invokeRequest()方法很复杂，下面我们来看一下。 RestHandler.invokeRequest()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980/** * Execute an HTTP request. * * @return HTTP response object of specified &#123;@code type&#125; or &#123;@code null&#125;. * @throws RetrofitError if any error occurs during the HTTP request. */private Object invokeRequest(RequestInterceptor requestInterceptor, RestMethodInfo methodInfo, Object[] args) &#123; String url = null; try &#123; methodInfo.init(); // Ensure all relevant method information has been loaded. String serverUrl = server.getUrl(); RequestBuilder requestBuilder = new RequestBuilder(serverUrl, methodInfo, converter); //在这个方法内，将你放入该方法中的各个参数处理成http标准格式 requestBuilder.setArguments(args); //给http请求添加额外的信息，这些信息在requestBuilder写好了 //自己在初始化RestAdapter的时候也可以初始化自己的RequestInterceptor， //这样的话就可以为一群http请求添加共同的header也好，参数也好 requestInterceptor.intercept(requestBuilder); //封装了一个HTTP请求所有需要的信息 Request request = requestBuilder.build(); ... long start = System.nanoTime(); //使用之前设置的Client.Provider进行网络请求，并得到返回值 //Response这个类封装了HTTP返回信息 Response response = clientProvider.get().execute(request); long elapsedTime = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start); int statusCode = response.getStatus(); //就是指接口中方法的返回值类型 Type type = methodInfo.responseObjectType; if (statusCode &gt;= 200 &amp;&amp; statusCode &lt; 300) &#123; // 2XX == successful request //我们一般都要Convert之后的格式, 我还没遇到直接需要Response的情况， // Caller requested the raw Response object directly. if (type.equals(Response.class)) &#123; if (!methodInfo.isStreaming) &#123; //如果你返回值是Response，并且不返回流，而返回原始类型， //response会将服务端返回值写入一个64K大小的数组中，如果返回值很大，那么数据就无法完全储存，所以在这种情况下返回大文件会有问题 // Read the entire stream and replace with one backed by a byte[]. response = Utils.readBodyToBytesIfNecessary(response); &#125; if (methodInfo.isSynchronous) &#123; return response; &#125; return new ResponseWrapper(response, response); &#125; //这个接口的注释 Binary data with an associated mime type. //这个接口用来抽象http的返回值的body TypedInput body = response.getBody(); if (body == null) &#123; if (methodInfo.isSynchronous) &#123; return null; &#125; //这个就是callback里的Response和Body return new ResponseWrapper(response, null); &#125; ExceptionCatchingTypedInput wrapped = new ExceptionCatchingTypedInput(body); try &#123; //调用我们之前定义的Converter来解析数据 Object convert = converter.fromBody(wrapped, type); logResponseBody(body, convert); if (methodInfo.isSynchronous) &#123; return convert; &#125; return new ResponseWrapper(response, convert); &#125; catch (ConversionException e) &#123; ... &#125; &#125; //将body的数据转换成byte数组, http状态码不在200-300之间 response = Utils.readBodyToBytesIfNecessary(response); ... &#125;&#125; 这个方法很长，我去掉了profiler和log以及错误处理相关的内容。 这里首先调用的就是method.init()方法，这个方法: 12345678synchronized void init() &#123; if (loaded) return; parseMethodAnnotations(); parseParameters(); loaded = true;&#125; 如果执行过，直接从缓存Map里拿就可以了，不需要重复执行，这个方法就是前面说的，获取每个方法对应的注解和方法参数内的注解，并给你的那些方法做合理的替换。 剩下的方法基本都已做了注释，看代码即可了解。再提示一点，有TypedInput，自然有TypedOutput，TypedOutput的作用就和大家想的一样，是发送出去的数据类型的接口抽象。 提示在这里进行几点提示： 自定义converter的时候需要实现Converter接口，比如你想用其它的Json解析库替代Gson，或者服务端返回值不是Json，而是XML等等。只要了解了TypedInput和TypedOutput，剩下的很容易就可以完成了。 Retrofit这个版本不支持Multimap，所以如果服务端要求请求的时候key一样value不一样就很悲剧，那么修改RequestBuilder就可以达到Multimap的目的。 Retrofit这个版本不支持在接口中写入整个url，如果endpoint不一样就要重新创建一个RestAdapter，但悲剧的是创建一个RestAdapter的代价是很大的，那么修改RestMethodInfo就可以达到在HTTP方法注解中使用整个url的目的。 到这里我们对这个库的源码分析就完了，接下来以一副图来结束这个专题。 这样看来，Retrofit本身就是一个胶水层，同时像插槽一样留出一些插口给大家使用，简化了网络请求。 参考: 快速Android开发系列网络篇之Retrofit]]></content>
      <tags>
        <tag>retrofit</tag>
        <tag>square</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Retrofit-1.9源码分析-(上)]]></title>
    <url>%2F2016%2F01%2F13%2FRetrofit-1.9%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-(%E4%B8%8A)%2F</url>
    <content type="text"><![CDATA[Retrofit项目的GitHub Retrofit 官网介绍Type-safe HTTP client for Android and Java。 接下来的这几篇文章的分析都是基于1.9版本的。 看过我前面文章的开发者们应该知道，我不喜欢把一篇文章写的很长，所以这个分析依旧会有好几篇，好了，我们开始第一篇的分析。 看到一个库，我们要首先会用，然后再去深入其中，研究其中的源代码。 那我们来看看这个库的用法。 用法官网上的教程是这样写的。 首先定义请求接口： 1234567public interface GitHubService &#123; //被注释的内容是同步方法，在Android 4.0以后不允许主线程进行网络请求，所以一般不这么用 //@GET("/users/&#123;user&#125;/repos") //List&lt;Repo&gt; listRepos(@Path("user") String user); @GET("/users/&#123;user&#125;/repos") void listRepos(@Path("user") String user, Callback&lt;List&lt;Repo&gt;&gt; callback);&#125; 然后初始化RestAdapter，并且通过RestAdapter生成刚才代理的实现类 12345RestAdapter restAdapter = new RestAdapter.Builder() .setEndpoint("https://api.github.com") .build();GitHubService service = restAdapter.create(GitHubService.class); 现在就可以调用接口发送请求了。 123456789service.listRepos("octocat", new Callback&lt;List&lt;Repo&gt;&gt;()&#123; @Override public void success(List&lt;Repo&gt; repos, Response response) &#123; &#125; @Override public void failure(RetrofitError error) &#123; &#125;&#125;); 这样就返回了网络请求对应的Model，并且通过回调让返回的结果在主线程进行操作， 从网络请求返回的数据到对应的Model转换是在RestAdapter那里定义的，默认是Gson解析，即默认服务端返回格式是Json， 当然你也可以使用不一样的Json解析库，当服务端返回Xml，Protocol Buffer的时候，你也可以解析，只要自己实现Converter接口，并在RestAdapter中设置即可。 这里有一个问题，如果服务端的接口不是全部返回一个格式怎么办？或者不是同一个Endpoint怎么办？每一个都需要定义一个对应的RestAdapter对应。 所以这里可能出现的问题就是，某些接口可能数据很简单，但是返回格式不统一，那么就需要新写一个这样类似的模板代码。 这样，我们大概了解了这个版本的库使用方式： 定义一个接口，通过注解说明它是什么请求类型，并且在注解内写明它的相对于Endpoint(2.0版本称作BaseUrl,这样就好理解多了)的Url， 然后声明一个方法，这个方法中的参数就是网络请求时服务端需要的参数，也可以把网络请求的路径作为方法参数，最后定义一个回调，让返回结果在主线程中执行。 定义RestAdapter，并对其进行必要的设置，通过它生成那个接口对应的实现类。 调用实现类，执行网络请求。 可以看出，定义RestAdapter是其中很重要的一步，那么我们先来分析它到底做了什么。 初始化RestAdapter我们看到示例，通过Builder来初始化的，那么源码中一定用了建造着模式，一般情况下，如果可设置项不多，不会用这样一个模式， 看来RestAdapter的可设置项非常多，我们来看看。 在RestAdapter内部的静态Builder类中，有这么多可以设置的内容。 RestAdapter.Builder12345678910private Endpoint endpoint; //就是BaseUrl，private Client.Provider clientProvider; //最终执行网络请求使用的库private Executor httpExecutor; //http线程池的具体实现private Executor callbackExecutor; //callback在哪个线程执行private RequestInterceptor requestInterceptor; //网络请求的拦截者，可以给网络请求加入共同的参数private Converter converter; //网络请求返回值的解析方式(Json/Xml)private Profiler profiler; //可以记录HTTP方法执行时间和状态码private ErrorHandler errorHandler; //错误处理private Log log; private LogLevel logLevel = LogLevel.NONE; 如果分别深入每个类，那么，除了最后的LogLevel是enum之外，其他都是接口，有多少开发者还记得面向接口编程，不面向实现编程， 或者说作为开发者的我们记得这句话，但是自己实现的时候都忘记了。 其实这些接口就是一个个hook，留给使用者去自定义。但是这个库也提供了默认的参数，那这个默认的参数在哪里设置呢？ 看回我们前面的例子，对于建造着模式，最后一步要使用build()方法来返回一个对应的类，那么我们来看一下这个build()方法。 123456789/** Create the &#123;@link RestAdapter&#125; instances. */ public RestAdapter build() &#123; if (endpoint == null) &#123; throw new IllegalArgumentException("Endpoint may not be null."); &#125; ensureSaneDefaults(); return new RestAdapter(endpoint, clientProvider, httpExecutor, callbackExecutor, requestInterceptor, converter, profiler, errorHandler, log, logLevel); &#125; 这里很容易可以看出，必须要设置EndPoint才能继续使用。 那么其它的类变量一定在ensureSaneDefaults()方法初始化了，否则当库的使用者未设置的时候，其它都是null了。 我们来看一下它的源码： RestAdapter ensureSaneDefaults()123456789101112131415161718192021222324 private void ensureSaneDefaults() &#123; if (converter == null) &#123; converter = Platform.get().defaultConverter(); &#125; if (clientProvider == null) &#123; clientProvider = Platform.get().defaultClient(); &#125; if (httpExecutor == null) &#123; httpExecutor = Platform.get().defaultHttpExecutor(); &#125; if (callbackExecutor == null) &#123; callbackExecutor = Platform.get().defaultCallbackExecutor(); &#125; if (errorHandler == null) &#123; errorHandler = ErrorHandler.DEFAULT; &#125; if (log == null) &#123; log = Platform.get().defaultLog(); &#125; if (requestInterceptor == null) &#123; requestInterceptor = RequestInterceptor.NONE; &#125; &#125;&#125; 可以看到，主要需要关心的接口都是由Platform类实现的，那我们进入其中一探究竟。 Platform1234567891011121314151617181920212223abstract class Platform&#123; private static final Platform PLATFORM = findPlatform(); static Platform get() &#123; return PLATFORM; &#125; private static Platform findPlatform() &#123; try &#123; Class.forName("android.os.Build"); if (Build.VERSION.SDK_INT != 0) &#123; return new Android(); &#125; &#125; catch (ClassNotFoundException ignored) &#123; &#125; if (System.getProperty("com.google.appengine.runtime.version") != null) &#123; return new AppEngine(); &#125; return new Base(); &#125;&#125; 想要初始化它们，先使用Platform.get()方法，这个方法获取了单例Platform对象PLATFORM，这里给了我们实现单例的一种思路。 通过findPlatform()方法，如果是Android平台，则使用内部的Android子类，如果是Google AppEngine，则使用内部的AppEngine子类， 如果都不是，则使用内部的Base子类，还记得这个库的目标吧？是Java和Android平台的HTTP库，所以这里还可能是Java平台，所以要使用另外一种实现方式。 这次分析主要针对Android平台，所以如果好奇另外两个实现，请自己查看源码。 还记得我们在使用RestAdapter的Builder的时候除了Endpoint之外的接口吗？在Platform内部，定义了其它默认的实现： 12345abstract Converter defaultConverter();abstract Client.Provider defaultClient();abstract Executor defaultHttpExecutor();abstract Executor defaultCallbackExecutor();abstract RestAdapter.Log defaultLog(); 均是抽象方法，意味着这些都要靠子类实现，那么我们看一下Android子类是如何实现的： Platform.Android123456789101112131415161718192021222324252627282930313233343536373839404142private static class Android extends Platform &#123; @Override Converter defaultConverter() &#123; return new GsonConverter(new Gson()); //默认Gson，处理请求返回的Json &#125; @Override Client.Provider defaultClient() &#123; final Client client; if (hasOkHttpOnClasspath()) &#123; //存在Okhttp库，当然用OkHttp了 client = OkClientInstantiator.instantiate(); &#125; else if (Build.VERSION.SDK_INT &lt; Build.VERSION_CODES.GINGERBREAD) &#123; client = new AndroidApacheClient(); //Android 2.3以下用HttpClient &#125; else &#123; client = new UrlConnectionClient(); //Android 2.3以上用HttpUrlConnection &#125; return new Client.Provider() &#123; @Override public Client get() &#123; return client; &#125; &#125;; &#125; @Override Executor defaultHttpExecutor() &#123; return Executors.newCachedThreadPool(new ThreadFactory() &#123; //使用CachedThreadPool来管理网络请求 @Override public Thread newThread(final Runnable r) &#123; return new Thread(new Runnable() &#123; @Override public void run() &#123; Process.setThreadPriority(THREAD_PRIORITY_BACKGROUND); //给线程设置优先级 r.run(); &#125; &#125;, RestAdapter.IDLE_THREAD_NAME); &#125; &#125;); &#125; @Override Executor defaultCallbackExecutor() &#123; return new MainThreadExecutor(); //callback在主线程执行 &#125; @Override RestAdapter.Log defaultLog() &#123; return new AndroidLog("Retrofit"); &#125; &#125; 这里hasOkHttpOnClasspath()方法我觉得很棒，和前面找对应的平台一样，通过Class.forName(包名)找类，看是否存在。 如果自己写一个库的时候是好用的一种方式，支持一些新的东东。放一下它的源码。 Platform hasOkHttpOnClasspath()12345678private static boolean hasOkHttpOnClasspath() &#123; try &#123; Class.forName("com.squareup.okhttp.OkHttpClient"); return true; &#125; catch (ClassNotFoundException ignored) &#123; &#125; return false;&#125; 到这里为止，RestAdapter就创建好了，接下来跟着例子继续，RestAdapter调用create()方法，创建接口的实现类。 RestAdapter create()123456public &lt;T&gt; T create(Class&lt;T&gt; service) &#123; Utils.validateServiceClass(service); //验证Service是否有效，判断条件：1.这个类是接口 2.该接口不是其它接口的子接口 (接口也可以继承) return (T) Proxy.newProxyInstance(service.getClassLoader(), new Class&lt;?&gt;[] &#123; service &#125;, new RestHandler(getMethodInfoCache(service)));&#125; 这里，通过一个动态代理生成了接口的实现类，并在第三个参数里做了一些的操作。 **动态代理的作用：在运行时创建一个实现了一组给定接口的新类。 为什么要用动态代理？因为在编译时无法确定需要实现哪个接口。** 我们慢慢分析，先看这个方法的签名: 123456789101112131415161718192021222324/** * Returns an instance of the dynamically built class for the specified * interfaces. Method invocations on the returned instance are forwarded to * the specified invocation handler. The interfaces must be visible from the * supplied class loader; no duplicates are permitted. All non-public * interfaces must be defined in the same package. * * @param loader * the class loader that will define the proxy class * @param interfaces * an array of &#123;@code Class&#125; objects, each one identifying an * interface thill be implemented by the returned proxy * object * @param invocationHandler * the invocation handler that handles the dispatched method * invocations * @return a new proxy object that delegates to the handler &#123;@code h&#125;**/ public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler invocationHandler)throws IllegalArgumentException &#123; return getProxyClass(loader, interfaces) .getConstructor(InvocationHandler.class) .newInstance(invocationHandler);&#125; 方法体不管它的错误处理部分，先看它的参数，这个方法有三个参数： loader，没什么可说的，就是一个ClassLoader interfaces, 传入的接口数组，里面的方法由代理实现 invocationHandler, 方法调用的处理器 对于前两个参数默认大家都已经熟悉了，我们看一下最后一个InvocationHandler,这个接口很简单，只定义了一个方法，如下： 1public Object invoke(Object proxy, Method method, Object[] args) throws Throwable; 举个例子来讲这个方法的含义： 拿经纪人的比喻来说吧， 简单来说，你需要让我做一件事情(要调用原始对象的一个函数)，但是，因为我不很会和别人谈判(作为框架不能和业务逻辑耦合太多)， 那么我就找了一个经纪人，由他来和你谈，当经纪人把前前后后的各种事情帮我弄好之后， (可以过滤请求，可以让其他对象来完成对原始对象的调用) 我就可以做我的事情(原始对象调用自己的那个函数)，而不用为这些不擅长的事情分心了。 看看invoke()方法注释中的例子： 123456789public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //do some processing before the method invocation //invoke the method Object result = method.invoke(proxy, args); //do some processing after the method invocation return result;&#125; 在调用方法前后都能加一些你需要做的额外工作，是不是很像我举的例子？还有很重要的一点，你要把原始对象做完的结果返回给调用者。 我们把视线移回到newProxyInstance()的方法体中，在这里先看一下为什么这个方法返回的对象可以被强制转换为传入的接口对象， 就像官方提供的demo一样， 1GitHubService service = restAdapter.create(GitHubService.class); 传入GitHubService，然后最后就可以强制转换为GitHubService对象。 **原因就是在newProxyInstance()这个方法的第二个参数上，我们给这个代理对象提供了一组什么接口，那么我这个代理对象就会实现了这组接口， 这个时候我们当然可以将这个代理对象强制类型转化为这组接口中的任意一个。** 我们传入GitHubService,代理类把这个接口的方法都实现了，自然能转换成GitHubService对象。 在这里第一篇分析就结束了，可以看到new RestHandler(getMethodInfoCache(service))这个方法都没有跟进去， 或许由于局限在Java这门语言的缘故，是因为我觉得Proxy.newProxyInstance()方法很不容易理解，所以到这里结束， ​]]></content>
      <tags>
        <tag>retrofit</tag>
        <tag>square</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(翻译)使用正确的方式绘制布局]]></title>
    <url>%2F2016%2F01%2F12%2F%5B%E7%BF%BB%E8%AF%91%5D%E4%BD%BF%E7%94%A8%E6%AD%A3%E7%A1%AE%E7%9A%84%E6%96%B9%E5%BC%8F%E7%BB%98%E5%88%B6%E5%B8%83%E5%B1%80%2F</url>
    <content type="text"><![CDATA[原文 ： https://possiblemobile.com/2013/05/layout-inflation-as-intended/ 绘制(inflation，翻译下同)布局(Layout)是在Android的Context中使用的术语，它的作用是解析一个XML布局资源并且把这个资源转换到视图对象的层级(hierarchy)中这在Android SDK中很长用，但你会很惊奇的发现有一种错误的方式使用LayoutInflater，并且你的应用可能正在错误的使用它。如果你曾经在你的Android应用中，使用LayoutInflater写过类似下面的代码， 1inflater.inflate(R.layout.my_layout, null); 那么请继续阅读，因为你用错了，我想告诉你为什么你是错的。 了解 LayoutInflater首先，我们看一下LayoutInflater是如何工作，对于常见的应用，inflate() 方法有两种可用的方式。 inflate(int resource, ViewGroup root) inflate(int resource, ViewGroup root, boolean attachToRoot) 第一个参数(resource)指出哪个布局资源想要被绘制。第二个参数是你绘制的资源将会添加到该根视图的层级中(翻译不好，附上原文：The second parameter is the root view of the hierarchy you are inflating the resource to attach to.)。当第三个参数出现的时候，它控制绘制好的视图是否附着到所提供的根视图上。 后两个参数可能会让人困惑。对于这个方法的两个参数版本，LayoutInflater将会自动尝试将绘制好的视图附加到提供的根视图上。然而，系统会做一个检查，防止你给根视图传 null 导致的应用崩溃。 许多开发者使用这种方式，意味着给根视图传null是禁止绘制的视图附着的正确方法；在大部分情况下，甚至没有意识到 inflate() 方法有三个参数的版本。这样做我们同时也禁止了根视图拥有的另外一种很重要的功能——但是我走的太快了，你们可能会跟不上(翻译不好，附上原文：but I’m getting ahead of myself.)。 Android系统的例子在系统希望开发者绘制视图的地方，让我们做一些实验。 Adapters是使用LayoutInflater最常用的地方，通常用在自定义Listview的Adapter中，重载 getView()方法，这个方法有如下的方法签名： 1getView(int position, View convertView, ViewGroup parent) Fragments在创建视图的时候也使用LayoutInflater，通过onCreateView()方法；注意它的方法签名： 1onCreateView(LayoutInflater inflater, ViewGroup container, Bundle savedInstanceState) 你是否注意到，每次系统想让你绘制布局的时候，它都会传给你最终要附着到的父ViewGroup？同时在大部分情况下(包括以上两个例子)，在LayoutInflater被允许将绘制好的视图附加到根视图的时候，它将会抛出一个异常。 当我们不应该附着到ViewGroup的时候，为什么我们会需要它？原来，在绘制过程中，父视图是很重要的部分，因为在 XML 文件被绘制的过程中，计算在根元素声明的LayoutParams需要它 。在这里传null相当于告诉系统“抱歉，我不知道需要附着到哪个父视图上”。 这样做的问题是android:layout_xxx 属性总是在父视图的Context中被计算。因此，如果没有父视图的信息，在XML树中，所有的根元素声明的LayoutParams将会被丢弃，然后，你将会问“为什么系统忽略我声明的Layout属性，我需要好好检查一下为什么，看看是不是哪里有bug”。 没有了LayoutParams, 最终承载绘制布局的ViewGroup将会生成一个默认的设置给你。 如果你足够幸运(大多数情况下都是)，这些默认的参数和你在 XML中声明的一样——因此遮盖了这里有错误的事实。 应用例子因此你说你从没在应用中见过它出现？请看下面的布局，我们用它来绘制 ListView 的行： R.layout.item_row 123456789101112131415161718&lt;LinearLayout xmlns:android="http://schemas.android.com/apk/res/android" android:layout_width="match_parent" android:layout_height="?android:attr/listPreferredItemHeight" android:gravity="center_vertical" android:orientation="horizontal"&gt; &lt;TextView android:id="@+id/text1" android:layout_width="wrap_content" android:layout_height="wrap_content" android:paddingRight="15dp" android:text="Text1" /&gt; &lt;TextView android:id="@+id/text2" android:layout_width="0dp" android:layout_height="wrap_content" android:layout_weight="1" android:text="Text2" /&gt;&lt;/LinearLayout&gt; 我们希望把每行的高度设置为固定的高度，在这种情况下，首选项的高度和当前的主题相关——看起来很合理。 然后，当我们以错误的方式绘制布局的时候 123456public View getView(int position, View convertView, ViewGroup parent) &#123; if (convertView == null) &#123; convertView = inflate(R.layout.item_row, null); &#125; return convertView;&#125; 我们得到的结果看起来像这样： 我们设置的固定高度出了什么情况？ 如果我们替换绘制布局的方式： 123456public View getView(int position, View convertView, ViewGroup parent) &#123; if (convertView == null) &#123; convertView = inflate(R.layout.item_row, parent, false); &#125; return convertView;&#125; 我们得到的结果就如我们希望的那样。 每个规则都有例外（文中的例外在现在的Android版本已经不存在了，所以这一节就不翻译了）所以，下一次你想给 inflate()方法传 null的时候，你需要停下来并问一问你自己“我真的不知道这个视图的根视图是什么吗？(这句话我没有理解作者的意思，就按我觉得翻译了，do I really not know where this view will end up?)” 最后，当第三个参数为true时，你可以使用两个参数版本的inflate() 来省它。当第三个参数为false的时候，你不应该将 null 传给第二个参数来省略它。]]></content>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(翻译)什么是Context]]></title>
    <url>%2F2016%2F01%2F09%2F%5B%E7%BF%BB%E8%AF%91%5D%E4%BB%80%E4%B9%88%E6%98%AF-Context%2F</url>
    <content type="text"><![CDATA[原文 ： https://possiblemobile.com/2013/06/context/ Context 大概是Android应用中使用最多的元素，同时，它可能也是最被滥用的元素Context对象如此常见，经常在不同的类中被传来传去，它可以用于你完全不关心的场景，如加载资源，启动新的Activity，获取系统服务，获取内部文件路径，创建所有需要Context的视图(View)来完成任务，更关键的是，这还仅仅是Context的一小部分功能。我希望这篇文章能帮助你，在你的应用在你的应用中，更有效的使用Context对象。 Context类型不是所有的Context都是相同的。获取的Context是由Android系统组件决定的，每个组件获取的Context对象略有不同。 Application — 在你的应用进程中，它是一个单例。 它可以通过Activity和Service中的getApplication() 方法获取，也可以通过任何继承了Context对象中的getApplicationContext() 方法，无论从哪里获得Application对象，只要在应用进程中，你获得的都是同一个实例。 Activity/Service — （这里前半部分我不按原文翻译，因为最新的Android源码已经不像作者写文章的时候那样了。翻译会误导）都继承了ContextWrapper对象，ContextWrapper就像命名的那样，它的内部包裹了一个Context，它其中的方法其实就是Context的方法。当系统创建一个新的Activity或Service实例的时候，它同样创建了一个新的ContextImpl实例来完成所有费时的操作。对于每一个Activity或Service实例对应一个独一无二的Context。 BroadcastReceiver — 它本身不是Context，但是系统会在每次广播事件到达时，给它的onReceive()传入一个Context。这个Context实例是一个ReceiverRestrictedContext ，它的两个方法不建议使用，分别是registerReceiver() 和 bindService()。每次一个接收者接收到一个广播，则会新生成一个Context。 ContentProvider — 同样不是一个Context，但是当它创建的时候会传给它一个Context对象，然后通过它的getContext()方法来访问。如果ContentProvider和调用者在同一个应用进程中，则它会返回相同的Application实例，如果两个在不同的进程中，它将会新创建一个实例，代表这个ContentProvider所在的包。 保存Context引用我们需要指出的第一个问题来自于在一个对象或一个类中保存 Context 的引用，但是这个对象存在的时间超过了保存的拥有生命周期的 Context 的实例的存在时间（其实就是一个某个对象持有拥有声明周期的 Context 对象，生命周期结束，但那个类还继续持有 Context 对象，这样就造成了内存泄漏）。例如，创建一个自定义的单例，需要一个 Context 来读取资源或者使用ContentProvider，然后，在那个单例中保存了当前的Activity或Service。 Bad Singleton 1234567891011121314151617public class CustomManager &#123; private static CustomManager sInstance; public static CustomManager getInstance(Context context) &#123; if (sInstance == null) &#123; sInstance = new CustomManager(context); &#125; return sInstance; &#125; private Context mContext; private CustomManager(Context context) &#123; mContext = context; &#125;&#125; 这里的问题是我们不知道 Context从哪里来，同时，当Activity或Service的生命周期结束时，依旧持有它的引用是不安全的。因为单例在封闭的类中被单独的静态引用管理。这意味着我们的对象，以及所有其他被它引用的对象将不会被垃圾回收器回收。如果 Context是一个Activity，我们将会在内存中保存它所有的视图以及和它有关系的潜在的大对象；这样将会导致内存泄漏。 为了避免这样，我们修改单例，通过引用Application对象的 Context： Better Singleton 123456789101112131415161718public class CustomManager &#123; private static CustomManager sInstance; public static CustomManager getInstance(Context context) &#123; if (sInstance == null) &#123; //Always pass in the Application Context sInstance = new CustomManager(context.getApplicationContext()); &#125; return sInstance; &#125; private Context mContext; private CustomManager(Context context) &#123; mContext = context; &#125;&#125; 现在，我们不用关心这个context来自哪里了，因为我们持有的引用是安全的。Application对象的 Context本身就是一个单例，所以即使有其他的静态对象引用它也不会造成任何泄漏。另外一个很好的可能偶尔发生的例子是：在正在运行的后台线程或者Pending(将要发生的) Handler中，保存了 Context 的引用。 那么，为什么我们不能总是引用Application对象的 Context？就像我们前面提到的一样，以中间人的方式（指context.getApplicationContext()）实现，并且不需要担心内存泄漏？答案是像我在前言中暗示的一样，因为Context的类别不一样。 Context 能力依赖于 Context的来源，你可以安全的对给予的 Context对象做一些共同的操作。下面的表格说明了应用在常用的地方收到一个 Context，在每个情况下， Context对象可以用来做什么 Application Activity Service ContentProvider BroadcastReceiver Show a Dialog NO YES NO NO NO Start an Activity NO[^1] YES NO[^1] NO[^1] NO[^1] Layout Inflation NO[^2] YES NO[^2] NO[^2] NO[^2] Start a Service YES YES YES YES YES Bind to a Service YES YES YES YES NO Send a Broadcast YES YES YES YES YES Register BroadcastReceiver YES YES YES YES NO[^3] Load Resource Values YES YES YES YES YES 在这里，一个Application的 Context 可以启动一个Activity，但是它需要创建一个新的任务栈。在某些情况下，这可能是很好的使用方式，但是，在你的应用中，这将会导致回退栈的行为不像标准的那样，同时一般来说它不会被推荐或者被认为是一个好习惯。 绘制布局(Inflation Layout，在本文中把Inflation翻译为绘制，下同)是合法的，但是绘制的时候会使用正在运行系统的默认主题，而不会使用在你应用中定义的主题(theme)。 当BroadcastReceiver是null的时候是允许的，在Android 4.2及以上版本，它被用于获取sticky 广播(broadcast)当前的值。 ​ 用户界面从上面的表格可以看出，对于Application的 Context，有一些方法并不适用；那些方法都是和UI相关的。实际上，唯一一个有能力处理所有和UI相关情况的组件是Activity，在其它的方法中，所有组件的功能基本都相同。 幸运的是，在整个应用了，除了Activity之外的领域基本不使用这三个方法，这个应该是Android系统的设计者刻意为之。尝试使用Application的 Context显示一个 Dialog 或者启动一个Activity，系统将会抛出一个异常同时你的应用将会崩溃——明确的提示你有些地方出现错误。 绘制布局的问题则不明显。如果你读过我上一篇文章layout inflation(翻译)， 你应该知道在一些隐藏的行为中会做一些神秘的处理；使用正确的 Context将会得到相同的行为(using the right Context is linked to another one of those behaviors 这句话自我感觉翻译不好，放原文在此)，使用Application的 Context创建LayoutInflater 对象然后Inflation Layout，对于这样调用此方法，虽然Android系统不会发出警告，而且这个方法将会完美返回正确的视图层级(view hierarchy)，但是在此过程中，你应用的主题(themes)和风格(styles)不会被使用。这是因为在你的清单文件中(manifest)，你定义的主题(themes)只会对Activity的 Context 起作用。任何其他的 Context 实例在绘制你的视图的时候将会使用系统默认主题，这将会导致最终的显示效果不如你期望那样。 这些规则的交集不变的是，有人会觉得这两个规则是冲突的。举个例子，你应用当前的设计是：必须保存一个长时间的 Context引用，同时它必须是Activity的 Context，因为我们要用它完成的任务包括操作UI。如果在那种情况，我强烈建议你重新思考你的设计。因为这将是教科书式的反系统设计。 经验之谈在大多数情况下，在你封闭的组件中可以直接使用可用的Context对象。你可以安全的保存它的引用只要那个组件在生命周期结束后不再存在。只要你的对象需要保存的Context引用，并且你的对象存活的时间超出了Activity或Service的生命周期，即使这种情况偶尔出现，请使用Application的 Context。]]></content>
      <tags>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndFix解析——(下)]]></title>
    <url>%2F2015%2F10%2F23%2FAndFix-%E8%A7%A3%E6%9E%90(%E4%B8%8B)%2F</url>
    <content type="text"><![CDATA[我们接着分析阿里开源的AndFix库，上一篇分析了Patch类，这个类相当于我们提供补丁的容器，容器里有了东西，我们要对容器进行操作了, 于是开始了我们这次的分析。 在第二篇里，我们添了Patch类的那个坑，那么这篇文章我们就把最后两个坑填一填，即loadPatch()方法和AndFixManager类。 在阿里给的Demo里，我们还有最后的loadPatch()方法没有深入，所以先从loadPatch()方法开始。 PatchManager loadPatch()public void loadPatch() { mLoaders.put("*", mContext.getClassLoader());// wildcard Set&lt;String&gt; patchNames; List&lt;String&gt; classes; for (Patch patch : mPatchs) { patchNames = patch.getPatchNames(); for (String patchName : patchNames) { classes = patch.getClasses(patchName); mAndFixManager.fix(patch.getFile(),mContext.getClassLoader(), classes); } } } 不知道大家是否还记得之前提到的mLoaders这个成员变量，隔了这么久，说实话我也忘记了，在这里我先带大家一起回忆一下，private final Map&lt;String, ClassLoader&gt; mLoaders;，mLoaders原来是储存不同ClassLoader的Map啊。好的，我们继续向下进行，在第一篇，通过private的initPatchs()方法，和public的addPatch()方法，将Patch加入了mPatchs这个List，所以，这里只要去遍历这个List，来获取不同的Patch，并对每个Patch做操作即可。每个Patch，代表了一个.apatch的文件，getClasses(patchName)代表着这个patch的patchName对应的所有需要修改的类。patchName从两方面而来，一个是你用apkpatch.jar的时候使用-n选项指定或者默认的，另外一个方面是写入Manifest的时候以-Classes结尾的key，这个我暂时还没有遇到过，遇到过的同学可以给我讲讲，抱歉博客暂时没有评论功能，可以发邮件给我,airzhaoyn@gmail.com。 好了，这里讲的差不多了，我们继续深入。可以看到，获取了一个patchName对应的所有的需要修改的类后，就会调用AndFixManager类的fix(File, ClassLoader,List&lt;String&gt;)方法，先来看看源码 AndFixManager fix(File, ClassLoader,List)/** * fix * * @param file * patch file * @param classLoader * classloader of class that will be fixed * @param classes * classes will be fixed */ public synchronized void fix(File file, ClassLoader classLoader, List&lt;String&gt; classes) { //是否是支持的Android版本(在AndFixManager类初始化的时候会修改mSupport变量) if (!mSupport) { return; } //验证这个文件的签名和此应用是否一致 if (!mSecurityChecker.verifyApk(file)) {// security check fail return; } //这段代码的源码中的注释很清楚，我就不写了 File optfile = new File(mOptDir, file.getName()); boolean saveFingerprint = true; if (optfile.exists()) { // need to verify fingerprint when the optimize file exist, // prevent someone attack on jailbreak device with // Vulnerability-Parasyte. // btw:exaggerated android Vulnerability-Parasyte // http://secauo.com/Exaggerated-Android-Vulnerability-Parasyte.html if (mSecurityChecker.verifyOpt(optfile)) { saveFingerprint = false; } else if (!optfile.delete()) { return; } } //start final DexFile dexFile = DexFile.loadDex(file.getAbsolutePath(), optfile.getAbsolutePath(), Context.MODE_PRIVATE); if (saveFingerprint) { mSecurityChecker.saveOptSig(optfile); } ClassLoader patchClassLoader = new ClassLoader(classLoader) { @Override protected Class&lt;?&gt; findClass(String className) throws ClassNotFoundException { Class&lt;?&gt; clazz = dexFile.loadClass(className, this); if (clazz == null &amp;&amp; className.startsWith("com.alipay.euler.andfix")) { return Class.forName(className);// annotation’s class // not found } if (clazz == null) { throw new ClassNotFoundException(className); } return clazz; } }; //Enumerate the names of the classes in this DEX file. Enumeration&lt;String&gt; entrys = dexFile.entries(); Class&lt;?&gt; clazz = null; while (entrys.hasMoreElements()) { String entry = entrys.nextElement(); if (classes != null &amp;&amp; !classes.contains(entry)) { continue;// skip, not need fix } clazz = dexFile.loadClass(entry, patchClassLoader); if (clazz != null) { fixClass(clazz, classLoader); } } } 对这部分的源码解析，从源码中标注//start开始。我们先看一下DexFile是什么，官方文档这样说：Manipulates DEX files. It is used primarily by class loaders.就是主要被类加载器使用的操作Dex文件的类。好了，我们可以继续看源码了，先获取一个DexFile对象的，然后通过匿名内部类实现了一个ClassLoaders的子类，遍历这个Dex文件中所有的类，如果需要修改的类集合(即从PatchManager loadPatch()方法中传过来的类集合)中在这个Dex文件中找到了一样的类，则使用loadClass(String, ClassLoader)加载这个类，然后调用fixClass(String, ClassLoader)修复这个类。 AndFixManager fixClass(Class&lt;?&gt;, ClassLoader)private void fixClass(Class&lt;?&gt; clazz, ClassLoader classLoader) { //使用反射获取这个类中所有的方法 Method[] methods = clazz.getDeclaredMethods(); //MethodReplace是这个库自定义的Annotation，标记哪个方法需要被替换 MethodReplace methodReplace; String clz; String meth; for (Method method : methods) { //找到被MethodReplace注解的方法 methodReplace = method.getAnnotation(MethodReplace.class); if (methodReplace == null) continue; clz = methodReplace.clazz(); meth = methodReplace.method(); if (!isEmpty(clz) &amp;&amp; !isEmpty(meth)) { replaceMethod(classLoader, clz, meth, method); } } } 在源码中基本把这个方法给解读完了，接下来就要看看它调用的replaceMethod(ClassLoader, String,String, Method)方法 AndFixManager replaceMethod(ClassLoader, String,String, Method)private void replaceMethod(ClassLoader classLoader, String clz, String meth, Method method) { //对每个类创建一个不会冲突的key String key = clz + "@" + classLoader.toString(); //mFixedClass是一个Map&lt;String, Class&lt;?&gt;&gt;，并被实例化为ConcurrentHashMap&lt;&gt;(); Class&lt;?&gt; clazz = mFixedClass.get(key); if (clazz == null) {// class not load Class&lt;?&gt; clzz = classLoader.loadClass(clz); // initialize target class and modify access flag of class’ fields to public clazz = AndFix.initTargetClass(clzz); } if (clazz != null) {// initialize class OK mFixedClass.put(key, clazz); //获取名为meth的方法 Method src = clazz.getDeclaredMethod(meth, method.getParameterTypes()); AndFix.addReplaceMethod(src, method); } } 这里源代码中的英文注释(作者注释)已经很清楚了，去看看调用的那个静态方法AndFix.addReplaceMethod(src, method); AndFix addReplaceMethod(Method, Method)public static void addReplaceMethod(Method src, Method dest) { replaceMethod(src, dest); initFields(dest.getDeclaringClass()); } replaceMethod是一个native方法，声明如下:private static native void replaceMethod(Method dest, Method src);由于暂时我对JNI不是很熟悉，所以这里就不分析了。看看另外一个方法initFields(Class&lt;?&gt;) /** * modify access flag of class’ fields to public * * @param clazz * class */ private static void initFields(Class&lt;?&gt; clazz) { Field[] srcFields = clazz.getDeclaredFields(); for (Field srcField : srcFields) { Log.d(TAG, "modify " + clazz.getName() + "." + srcField.getName() + " flag:"); setFieldFlag(srcField); } } 这里英文注释也很清楚了，只是其中调用了setFieldFlag(srcField);这个我们没见过的方法，声明为private static native void setFieldFlag(Field field);又是个JNI方法，暂时不进行分析。 到这里，对阿里AndFix库Java层面上的代码的分析就结束了，如果还想了解native层的代码，我将会放在下一篇，敬请等待。]]></content>
      <tags>
        <tag>AndFix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndFix解析——(中)]]></title>
    <url>%2F2015%2F10%2F10%2FAndFix-%E8%A7%A3%E6%9E%90(%E4%B8%AD)%2F</url>
    <content type="text"><![CDATA[我们接着分析阿里开源的AndFix库，上次留下了三个坑，一个方法，两个类，不知道你们是否想急切了解呢？loadPatch()方法和AndFixManager和Patch类。 分析loadPatch()方法的时候离不开AndFixManager这个类，所以，我会在分析loadPatch()方法的时候分析AndFixManager这个类。Patch类相当于一个容器，把修复bug所需的信息放在其中，Patch类相对来说比较独立，不需要牵扯到另外两个坑，所以，就先把这个坑埋了。 要分析Patch类，就不能不分析阿里提供的打包.apatch的工具apkpatch-1.0.2.jar，Patch获取的信息其实就是apkpatch打包时放入其中的信息。我下面对apkpatch.jar的分析以这个版本的源码为准。 分析源码，那些try-catch-finally和逻辑无关，所以，我会把这些代码从源码中删掉的，除非有提示用户的操作 我们先来看看Patch类 class Patch从前一篇的分析中，我们看到调用了Patch的构造函数，那我们就从构造函数开始看。 Patch Constructorpublic Patch(File file) throws IOException { this.mFile = file; this.init(); } Patch init()将传入的文件保存在类变量中，并调用init()函数，那么init()函数干什么呢？代码里异常和清理的代码我给删掉了，毕竟，这和我们对源码的分析关系不大，那么我们看一下剩下的代码 public void init(){ JarFile jarFile = new JarFile(this.mFile); JarEntry entry = jarFile.getJarEntry(ENTRY_NAME); InputStream inputStream = jarFile.getInputStream(entry); Manifest manifest = new Manifest(inputStream); Attributes main = manifest.getMainAttributes(); this.mName = main.getValue(PATCH_NAME); this.mTime = new Date(main.getValue(CREATED_TIME)); this.mClassesMap = new HashMap(); Iterator it = main.keySet().iterator(); while(it.hasNext()) { Name attrName = (Name)it.next(); String name = attrName.toString(); if(name.endsWith(CLASSES)) { List strings = Arrays.asList(main.getValue(attrName).split(",")); if(name.equalsIgnoreCase(PATCH_CLASSES)) { this.mClassesMap.put(this.mName, strings); } else { this.mClassesMap.put(name.trim().substring(0, name.length() - 8), strings); } } } } 先分析上面的代码，通过JarFile, JarEntry, Manifest, Attributes一层层的获取jar文件中值，并放入对应的类变量中这些值是从哪里来的呢？是从生成这个.apatch文件的时候写入的，即apkpatch.jar文件中写入的。虽然这个文件后缀名是apatch，不是jar，但是它生成的时候是使用Attributes，Manifest，jarEntry将数据写入的，其实依旧是jar格式，修改了扩展名而已 上面的那些常量都是什么呢，我们来看看这个类的类变量，就是一些对应的字符串。 private static final String ENTRY_NAME = "META-INF/PATCH.MF"; private static final String CLASSES = "-Classes"; private static final String PATCH_CLASSES = "Patch-Classes"; private static final String CREATED_TIME = "Created-Time"; private static final String PATCH_NAME = "Patch-Name"; private final File mFile; private String mName; private Date mTime; private Map&lt;String, List&lt;String&gt;&gt; mClassesMap; 看完了Patch类，是不是还一头雾水呢, 其他的好理解， mClassesMap里面的各种类名是从哪里来，里面的类作用又是什么呢？这里，我们就需要进入apkpatch.jar一探究竟。 apkpatch.jar对于Jar文件，我们可以使用jd-gui文件打开，阿里这里并没有对这个jar文件加密，所以我们可以直接看，对于Jar文件，我们从Main()方法开始看起。在package com.euler.patch;里面，有一个Main类，其中有那个我们常见的main()方法，那么我们就进入看一看。代码比较长，我们一段一段来看 Main Main()//CommandLineParser，CommandLine， Option, Options，OptionBuilder, PosixParser等等类都是 //org.apache.commons.cli这个包中的类，负责解析命令行传给程序的参数，所以下面的很多内容应该就不用我过多解释了 CommandLineParser parser = new PosixParser(); CommandLine commandLine = null; //option()方法就是将命令行需要解析的参数加入其中，有三种解析方式 //private static final Options allOptions = new Options(); //private static final Options patchOptions = new Options(); //private static final Options mergeOptions = new Options(); option(); try { commandLine = parser.parse(allOptions, args); } catch (ParseException e) { System.err.println(e.getMessage()); //提示用户如何使用这个jar包 usage(commandLine); return; } if ((!commandLine.hasOption('k')) &amp;&amp; (!commandLine.hasOption("keystore"))) { usage(commandLine); return; } if ((!commandLine.hasOption('p')) &amp;&amp; (!commandLine.hasOption("kpassword"))) { usage(commandLine); return; } if ((!commandLine.hasOption('a')) &amp;&amp; (!commandLine.hasOption("alias"))) { usage(commandLine); return; } if ((!commandLine.hasOption('e')) &amp;&amp; (!commandLine.hasOption("epassword"))) { usage(commandLine); return; } 这一部分主要是查看命令行是否有那些参数，如果没有要求的参数，则提示用户需要哪些参数。 接下来注意一下你下载apkpatch这个文件的时间，根据github的历史提交记录，如果你2015年10月以后下载的，可以忽视掉这个提醒，如果你是10月之前下载的那个工具，建议你更新一下这个工具，否则可能会导致-o所在的文件夹被清空。 好了，提醒完了，我们继续 String keystore = commandLine.getOptionValue('k'); String password = commandLine.getOptionValue('p'); String alias = commandLine.getOptionValue('a'); String entry = commandLine.getOptionValue('e'); String name = "main"; if ((commandLine.hasOption('n')) || (commandLine.hasOption("name"))){ name = commandLine.getOptionValue('n'); } 对于我们的release版应用来说，我们会指定storeFile， storePassword, keyAlias, keyPassword,这些即是上面keystore, password, alias, entry对应的值。至于name，这是最后生成的文件的名称，基本可以不用管。 下面，我们看一下main()函数中最后的一个if-else if ((commandLine.hasOption('m')) || (commandLine.hasOption("merge"))) { String[] merges = commandLine.getOptionValues('m'); File[] files = new File[merges.length]; for (int i = 0; i &lt; merges.length; i++) { files[i] = new File(merges[i]); } MergePatch mergePatch = new MergePatch(files, name, out, keystore, password, alias, entry); mergePatch.doMerge(); } else { if ((!commandLine.hasOption('f')) &amp;&amp; (!commandLine.hasOption("from"))) { usage(commandLine); return; } if ((!commandLine.hasOption('t')) &amp;&amp; (!commandLine.hasOption("to"))) { usage(commandLine); return; } File from = new File(commandLine.getOptionValue("f")); File to = new File(commandLine.getOptionValue('t')); if ((!commandLine.hasOption('n')) &amp;&amp; (!commandLine.hasOption("name"))) { name = from.getName().split("\\.")[0]; } 在此，我选择不分析MergePatch这个部分，毕竟，你只有先生成了，后面才可能需要做merge操作。from指修复bug后的apk，to指之前有bug的apk。所以这部分的分析就结束了。 main()函数里最后一部分内容 ApkPatch apkPatch = new ApkPatch(from, to, name, out, keystore, password, alias, entry); apkPatch.doPatch(); 将那些参数传给ApkPatch去初始化，然后调用doPatch()方法 ApkPatchApkPatch Constructor我们一步步来看，首先是调用构造函数 public ApkPatch(File from, File to, String name, File out, String keystore, String password, String alias, String entry){ super(name, out, keystore, password, alias, entry); this.from = from; this.to = to; } 这些代码大家都经常写了，我们跟着进入看看父类的构造函数做了什么， BuildBuild Constructorpublic class ApkPatch extends Build ApkPatch的函数头，说明它是Build类的子类 public Build(String name, File out, String keystore, String password, String alias, String entry) { this.name = name; this.out = out; this.keystore = keystore; this.password = password; this.alias = alias; this.entry = entry; if (!out.exists()) out.mkdirs(); else if (!out.isDirectory()) throw new RuntimeException("output path must be directory."); try{ FileUtils.cleanDirectory(out); } catch (IOException e) { throw new RuntimeException(e); } } 在这里，看到了我之前提到的-o操作的问题，会清空那个文件夹内的内容。 好了，我们接下来就可以看看最后一个方法，doPatch()方法了。 ApkPatch doPatch()public void doPatch() { File smaliDir = new File(this.out, "smali"); smaliDir.mkdir(); File dexFile = new File(this.out, "diff.dex"); File outFile = new File(this.out, "diff.apatch"); //DiffInfo是一个容器类，主要保存了新加的和修改的 类，方法和字段。 DiffInfo info = new DexDiffer().diff(this.from, this.to); this.classes = buildCode(smaliDir, dexFile, info); build(outFile, dexFile); release(this.out, dexFile, outFile); } 在out文件夹内生成了一个smali文件夹，还有diff.dex, diff.apatch文件。看到diff()方法，应该能想到就是比较两个文件的不同，所以DiffInfo就是储存两个文件不同的一个容器类，由于篇幅原因，这里就不深入其中了，有兴趣的同学可以深入其中看一下。 但是，在这个diff()方法中，有一个重要的问题需要大家注意，就是其中只针对classes.dex做了diff，如果你使用了Google的Multidex，那么结果就是你其它dex文件中的任何bug，依旧无法修复，因为这个生成的DiffInfo中没有其它dex的信息，这个时候就需要大家使用JavaAssist之类的工具修改阿里的这个jar文件，然后达到你自己的修复非classes.dex文件中bug的目的，问题出在DexFileFactory.class类中。 接下来，我们可以看到调用了三个方法，buildCode(smaliDir, dexFile, info);build(outFile, dexFile);``release(this.out, dexFile, outFile);一个个的跟进去看一看。 ApkPatch buildCode(smaliDir, dexFile, info)private static Set&lt;String&gt; buildCode(File smaliDir, File dexFile, DiffInfo info) throws IOException, RecognitionException, FileNotFoundException{ Set classes = new HashSet(); Set list = new HashSet(); //从这里可以看出，list保存了DiffInfo容器中的新添加的classes和被修改过的classes list.addAll(info.getAddedClasses()); list.addAll(info.getModifiedClasses()); baksmaliOptions options = new baksmaliOptions(); options.deodex = false; options.noParameterRegisters = false; options.useLocalsDirective = true; options.useSequentialLabels = true; options.outputDebugInfo = true; options.addCodeOffsets = false; options.jobs = -1; options.noAccessorComments = false; options.registerInfo = 0; options.ignoreErrors = false; options.inlineResolver = null; options.checkPackagePrivateAccess = false; if (!options.noAccessorComments) { options.syntheticAccessorResolver = new SyntheticAccessorResolver(list); } ClassFileNameHandler outFileNameHandler = new ClassFileNameHandler( smaliDir, ".smali"); ClassFileNameHandler inFileNameHandler = new ClassFileNameHandler( smaliDir, ".smali"); DexBuilder dexBuilder = DexBuilder.makeDexBuilder(); for (DexBackedClassDef classDef : list) { String className = classDef.getType(); //将相关的类信息写入outFileNameHandler baksmali.disassembleClass(classDef, outFileNameHandler, options); File smaliFile = inFileNameHandler.getUniqueFilenameForClass( TypeGenUtil.newType(className)); classes.add(TypeGenUtil.newType(className) .substring(1, TypeGenUtil.newType(className).length() - 1) .replace('/', '.')); SmaliMod.assembleSmaliFile(smaliFile, dexBuilder, true, true); } dexBuilder.writeTo(new FileDataStore(dexFile)); return classes; } 看到baksmali，反编译过apk的同学一定不陌生，这就是dex的打包工具，还有对应的解包工具smali，就到这里，这方面不继续深入了。如果想深入了解dex打包解包工具的源码，参见This Blog 可以看到，这个方法的返回值将DiffInfo中新添加的classes和修改过的classes做了一个重命名，然后保存了起来，同时，将相关内容写入smali文件中。这个重命名是一个怎样的重命名呢，看一下生成的smali文件夹里任意一个smali文件，我就拿Demo里的MainActivity.smali来说明这个类在文件中的类名是Lcom/euler/andfix/MainActivity;，看到这个名字，再看下面这个方法就很清晰了 classes.add(TypeGenUtil.newType(className) .substring(1, TypeGenUtil.newType(className).length() - 1) .replace('/', '.')); 就是把Lcom/euler/andfix/MainActivity;替换成com.euler.andfix.MainActivity_CF;那个_CF哪里来的呢，就是那个TypeGenUtil类做的操作了。这个类就一个方法，该方法进对String进行了操作，我们来看一看源码 public static String newType(String type){ return type.substring(0, type.length() - 1) + "_CF;"; } 可以看到，去掉了类名多余的那个’;’，然后在后面加了个_CF后缀。重命名应该是为了不合之前安装的dex文件的名字冲突。 (new FileDataStore(file) 作用就是清空file里的内容)最后，将dexFile文件清空，把dexBuilder的内容写入其中。 到这里，buildCode(smaliDir, dexFile, info)方法就结束了, 看看下一个方法build(outFile, dexFile); ApkPatch build(outFile, dexFile)上一个方法已经把内容填充到dexFile内了，我们来看看它的源码。 protected void build(File outFile, File dexFile) throws KeyStoreException, FileNotFoundException, IOException, NoSuchAlgorithmException, CertificateException, UnrecoverableEntryException{ //获取应用签名相关信息 KeyStore keyStore = KeyStore.getInstance(KeyStore.getDefaultType()); KeyStore.PrivateKeyEntry privateKeyEntry = null; InputStream is = new FileInputStream(this.keystore); keyStore.load(is, this.password.toCharArray()); privateKeyEntry = (KeyStore.PrivateKeyEntry)keyStore.getEntry(this.alias, new KeyStore.PasswordProtection(this.entry.toCharArray())); PatchBuilder builder = new PatchBuilder(outFile, dexFile, privateKeyEntry, System.out); //将getMeta()中获取的Manifest内容写入"META-INF/PATCH.MF"文件中 builder.writeMeta(getMeta()); //单纯调用了close()命令, 将异常处理放在子函数中。 //这里做了一个异常分层，即不同抽象层次的子函数需要处理的异常不一样 //具体请参阅《Code Complete》(代码大全)在恰当的抽象层次抛出异常 builder.sealPatch(); } 要打包了，打包完是要签名的，所以需要获取签名的相关信息，这一部分就不详细讲解了。这里提一下getMeta()函数，因为开头我们提到的Patch init() 函数内这句List strings = Arrays.asList(main.getValue(attrName).split(&quot;,&quot;));中的那个strings就是从这里写入的 protected Manifest getMeta() { Manifest manifest = new Manifest(); Attributes main = manifest.getMainAttributes(); main.putValue("Manifest-Version", "1.0"); main.putValue("Created-By", "1.0 (ApkPatch)"); main.putValue("Created-Time", new Date(System.currentTimeMillis()).toGMTString()); main.putValue("From-File", this.from.getName()); main.putValue("To-File", this.to.getName()); main.putValue("Patch-Name", this.name); main.putValue("Patch-Classes", Formater.dotStringList(this.classes)); return manifest; } 那个classes就是我们那个将类名修改后保存起来的Set，Formater.dotStringList(this.classes));这个方法就是遍历Set，并将其中用&#39;,&#39;作为分隔符，将整个Set中保存的String拼接所以在Patch init()方法内，就可以反过来组成一个List。 那么，我们来看看中间那条没注释的语句，通过PatchBuilder()的构造函数生成PatchBuilder，我们来看看PatchBuilder的构造函数 PatchBuilder Constructorpublic PatchBuilder(File outFile, File dexFile, KeyStore.PrivateKeyEntry key, PrintStream verboseStream){ this.mBuilder = new SignedJarBuilder(new FileOutputStream(outFile, false), key.getPrivateKey(), (X509Certificate)key.getCertificate()); this.mBuilder.writeFile(dexFile, "classes.dex"); } 这个就是把dexFile里的内容，经过修改，加上签名，写入classes.dex文件中，但是这里实在看不出来其中的细节，所以，我们要进入SignedJarBuilder类一探究竟 先看它的构造函数。 SignedJarBuilder Constructorpublic SignedJarBuilder(OutputStream out, PrivateKey key, X509Certificate certificate) throws IOException, NoSuchAlgorithmException{ this.mOutputJar = new JarOutputStream(new BufferedOutputStream(out)); //设置压缩级别 this.mOutputJar.setLevel(9); this.mKey = key; this.mCertificate = certificate; if ((this.mKey != null) &amp;&amp; (this.mCertificate != null)) { this.mManifest = new Manifest(); Attributes main = this.mManifest.getMainAttributes(); main.putValue("Manifest-Version", "1.0"); main.putValue("Created-By", "1.0 (ApkPatch)"); this.mBase64Encoder = new BASE64Encoder(); this.mMessageDigest = MessageDigest.getInstance("SHA1"); } } 这个方法做了一些初始化，做了一些赋值操作，大家经常写类似的代码，就不进行分析了，只是为了让大家看writeFile(File, String)的时候容易理解一些。 SignedJarBuilder writeFile(File, String)writeFile(File, String)做了什么呢？ public void writeFile(File inputFile, String jarPath){ FileInputStream fis = new FileInputStream(inputFile); JarEntry entry = new JarEntry(jarPath); entry.setTime(inputFile.lastModified()); writeEntry(fis, entry); } 这个方法调用了writeEntry(InputStream, JarEntry)方法, 来看一看它的源码 SignedJarBuilder writeEntry(InputStream, JarEntry)private void writeEntry(InputStream input, JarEntry entry) throws IOException{ this.mOutputJar.putNextEntry(entry); int count; while ((count = input.read(this.mBuffer)) != -1) { int count; this.mOutputJar.write(this.mBuffer, 0, count); if (this.mMessageDigest != null) { //将mBuffer中的内容放入mMessageDigest内部数组 this.mMessageDigest.update(this.mBuffer, 0, count); } } this.mOutputJar.closeEntry(); if (this.mManifest != null) { Attributes attr = this.mManifest.getAttributes(entry.getName()); if (attr == null) { attr = new Attributes(); this.mManifest.getEntries().put(entry.getName(), attr); } attr.putValue("SHA1-Digest", this.mBase64Encoder.encode(this.mMessageDigest.digest())); } } mBuffer是4096 bytes的数组。这段代码主要从input中读取一个buffer的数据，然后写入entry中，这里应该就可以理解我上面说的dexFile里的内容，写入classes.dex文件中了吧。 build(outFile, dexFile);结束了，看看最后一个方法release(this.out, dexFile, outFile) ApkPatch release(this.out, dexFile, outFile)protected void release(File outDir, File dexFile, File outFile) throws NoSuchAlgorithmException, FileNotFoundException, IOException { MessageDigest messageDigest = MessageDigest.getInstance("md5"); FileInputStream fileInputStream = new FileInputStream(dexFile); byte[] buffer = new byte[8192]; int len = 0; while ((len = fileInputStream.read(buffer)) &gt; 0) { messageDigest.update(buffer, 0, len); } String md5 = HexUtil.hex(messageDigest.digest()); fileInputStream.close(); outFile.renameTo(new File(outDir, this.name + "-" + md5 + ".apatch")); } 最后就是把dexFile进行了md5加密，并把build(outFile, dexFile);函数中生成的outFile重命名。这样，AndFix框架所需要的补丁文件就生成了。 还记得上面提到的Patch类中读取Manifest的那些属性吗？在build(outFile, dexFile);函数中，那个getMeta()函数把它读取的属性写到了文件中。 到这里，第二篇分析也结束了，下一篇将会进入Android代码中一探它做了什么的究竟。]]></content>
      <tags>
        <tag>AndFix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AndFix解析——(上)]]></title>
    <url>%2F2015%2F09%2F25%2FAndFix-%E8%A7%A3%E6%9E%90(%E4%B8%8A)%2F</url>
    <content type="text"><![CDATA[阿里巴巴前一段时间开源了他们用来解决线上紧急bug的一款Android库——AndFix 对Android开发者来说真是一个很好的消息。 基于自己的经验，太长的文字很少有人可以一口气看下来的，所以我打算分成多篇来分析这是这个库解析的第一篇， 我们先看一下其中的Demo代码，其中调用加载库的代码如下所示: 12345678910111213141516171819202122232425262728293031323334353637383940/** * sample application * * @author sanping.li@alipay.com * */public class MainApplication extends Application &#123; private static final String TAG = "euler"; private static final String APATCH_PATH = "/out.apatch"; /** * patch manager */ private PatchManager mPatchManager; @Override public void onCreate() &#123; super.onCreate(); // initialize mPatchManager = new PatchManager(this); mPatchManager.init("1.0"); Log.d(TAG, "inited."); // load patch mPatchManager.loadPatch(); Log.d(TAG, "apatch loaded."); // add patch at runtime try &#123; // .apatch file path String patchFileString = Environment.getExternalStorageDirectory() .getAbsolutePath() + APATCH_PATH; mPatchManager.addPatch(patchFileString); Log.d(TAG, "apatch:" + patchFileString + " added."); &#125; catch (IOException e) &#123; Log.e(TAG, "", e); &#125; &#125;&#125; 可以看到代码中首先通过PatchManager的构造函数初始化了PatchManager对象， PatchManager构造函数那么PatchManager对象里面都有什么呢，我们深入其中了解一下。 1234567public PatchManager(Context context) &#123; this.mContext = context; this.mAndFixManager = new AndFixManager(this.mContext); this.mPatchDir = new File(this.mContext.getFilesDir(), "apatch"); this.mPatchs = new ConcurrentSkipListSet(); this.mLoaders = new ConcurrentHashMap();&#125; 原来维持了一个Context对象的引用，初始化了AndFixManager对象，mPatchDir对象为存放Patch文件的文件夹，初始化了Patch的集合，还有持有ClassLoader的Map 其中一些内容的声明如下: 12345private final Context mContext;private final AndFixManager mAndFixManager;private final File mPatchDir;private final SortedSet&lt;Patch&gt; mPatchs;private final Map&lt;String, ClassLoader&gt; mLoaders; 我们对构造函数的分析在这里就结束了，我们先不深入的跟进Patch和AndFixManager这两个类了。 PatchManager init(String version)接下来分析PatchManager类中的init(String version)函数，先来看代码 12345678910111213141516171819public void init(String appVersion) &#123; //如果mPatchDir不存在，则创建文件夹，如果创建失败，则打印Log if(!this.mPatchDir.exists() &amp;&amp; !this.mPatchDir.mkdirs()) &#123; Log.e("PatchManager", "patch dir create error."); &#125; else if(!this.mPatchDir.isDirectory()) &#123; //如果遇到同名的文件，则将该同名文件删除 this.mPatchDir.delete(); &#125; else &#123; //在该文件下放入一个名为_andfix_的SharedPreferences文件， SharedPreferences sp = this.mContext.getSharedPreferences("_andfix_", 0); String ver = sp.getString("version", (String)null); if(ver != null &amp;&amp; ver.equalsIgnoreCase(appVersion)) &#123; this.initPatchs(); &#125; else &#123; this.cleanPatch(); sp.edit().putString("version", appVersion).commit(); &#125; &#125;&#125; 接下来我们分析上面代码中的如下代码 1234567//如果从_andfix_这个文件获取的ver不是null，而且这个ver和外部初始化时传进来的版本号一致if(ver != null &amp;&amp; ver.equalsIgnoreCase(appVersion)) &#123; this.initPatchs();&#125; else &#123; this.cleanPatch(); sp.edit().putString("version", appVersion).commit();&#125; 先看else内的内容，else里执行力cleanPatch()和把外部初始化的时候传进来的版本号放入SharedPreferences里。cleanPatch()做了什么操作呢，我们跟进去看一看 12345678910111213141516private void cleanPatch() &#123; //获取mPatchDir目录下所有文件 File[] files = this.mPatchDir.listFiles(); File[] arr$ = files; int len$ = files.length; for(int i$ = 0; i$ &lt; len$; ++i$) &#123; File file = arr$[i$]; //将此文件从OptFile文件夹删除 this.mAndFixManager.removeOptFile(file); //这个方法的作用就是如果file是文件，则删除它，如果file是文件夹，则将它和它里面的文件都删除 if(!FileUtil.deleteFile(file)) &#123; Log.e("PatchManager", file.getName() + " delete error."); &#125; &#125;&#125; 如源码中的注释，就是删除了之前在那两个文件夹下的所有的补丁文件。 现在来分析一下this.initPatchs()做了什么事 12345678910private void initPatchs() &#123; File[] files = this.mPatchDir.listFiles(); File[] arr$ = files; int len$ = files.length; for(int i$ = 0; i$ &lt; len$; ++i$) &#123; File file = arr$[i$]; this.addPatch(file); &#125;&#125; 代码很简单，就是把mPatchDir文件夹下的文件作为参数传给了addPatch(File)方法那this.addPatch(file)做了什么呢 123456789101112131415//把扩展名为.apatch的文件传给Patch做参数，初始化对应的Patch，//并把刚初始化的Patch加入到我们之前看到的Patch集合mPatchs中private Patch addPatch(File file) &#123; Patch patch = null; //扩展名是否为".apatch" if(file.getName().endsWith(".apatch")) &#123; try &#123; patch = new Patch(file); this.mPatchs.add(patch); &#125; catch (IOException var4) &#123; Log.e("PatchManager", "addPatch", var4); &#125; &#125; return patch;&#125; 上面的代码很好理解，此时，我们已经完整的走下来了init(String version)这个方法。再次出现了Patch这个类，但是我们依然要把它放在一边，因为由于篇幅限制，第一篇不会分析这个类。 接下来，我们继续跟着demo走，会执行两个方法，一个mPatchManager.loadPatch()，一个mPatchManager.addPatch(patchFileString)，loadPatch()方法是这个库执行替换的核心方法，我会在以后单独写一篇文章来分析，所以，在这篇文章的最后，我们跟进addPatch(String)这个方法一看究竟 1234567891011121314151617public void addPatch(String path) throws IOException &#123; File src = new File(path); File dest = new File(this.mPatchDir, src.getName()); if(dest.exists()) &#123; //在mPatchDir文件夹下存在该文件，则AndFixManager移除该文件 this.mAndFixManager.removeOptFile(dest); &#125; //将文件从src复制到dest，只不过阿里用了NIO来复制文件 FileUtil.copyFile(src, dest); //调用了另外一个addPatch方法，以文件作为参数 Patch patch = this.addPatch(dest); if(patch != null) &#123; //同样调用了loadPatch(Patch)方法 this.loadPatch(patch); &#125;&#125; 简单来说，上面的方法就是将补丁文件复制到/data/data/{包名}/apatch 目录内，如果在OptFile文件夹中存在，则删除。然后调用另外一个addPatch(File)方法，然后loadPatch()下面，我们来看一下重载的addPatch(File)方法 1234567891011121314private Patch addPatch(File file) &#123; Patch patch = null; if(file.getName().endsWith(".apatch")) &#123; try &#123; patch = new Patch(file); //把从file文件生成的patch加入到mPatchs这个Set中 this.mPatchs.add(patch); &#125; catch (IOException var4) &#123; Log.e("PatchManager", "addPatch", var4); &#125; &#125; return patch;&#125; 该方法主要做的事情在注释中即可了解，到这里，第一篇分析就结束了。]]></content>
      <tags>
        <tag>AndFix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins_email_failed]]></title>
    <url>%2F2015%2F09%2F24%2FJenkins_Email_Failed%2F</url>
    <content type="text"><![CDATA[报错信息： Failed to send out e-mailcom.sun.mail.smtp.SMTPSendFailedException: 501 mail from address must be same as authorization user; nested exception is: com.sun.mail.smtp.SMTPSenderFailedException:501 mail from address must be same as authorization user 解决方法：在设置Jenkins URL底下有一个文本框System Admin e-mail address， 这里要设置发送者的邮箱地址。]]></content>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
</search>